<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>决策树</title>
      <link href="2021/12/24/datawhale%20sklearn%204/"/>
      <url>2021/12/24/datawhale%20sklearn%204/</url>
      
        <content type="html"><![CDATA[<h2 id="Task04-决策树"><a href="#Task04-决策树" class="headerlink" title="Task04 决策树"></a>Task04 决策树</h2><p><a href="https://github.com/datawhalechina/machine-learning-toy-code/tree/main/ml-with-sklearn/DecisionTree">datawhale学习资料链接</a></p><p>代码主要内容加载sklearn中的鸢尾花数据集，画出violinplot，pointplot，andrew图，然后用sklearn的决策树DecisionTreeClassifier进行分类 以文字图和图片的形式来画出构造出的树</p><p><strong>决策树模型</strong></p><p>决策树模型就是数据结构中的树，根据<strong>特征选择依据</strong>(信息熵)等划分特征，生成决策树，然后<strong>剪枝</strong>提高泛化能力，可分类可回归，代表算法有ID3 信息熵，C4.5 信息增益比和CART 基尼系数</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。缺点：可能会产生过度匹配问题<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>PS</strong> 我用服务器开一个jupyter服务，然后网络连接 第一次显示出要密码</p><blockquote><h3 id="Token-authentication-is-enabled"><a href="#Token-authentication-is-enabled" class="headerlink" title="Token authentication is enabled"></a>Token authentication is enabled</h3><p>If no password has been configured, you need to open the notebook server with its login token in the URL, or paste it above. This requirement will be lifted if you <strong><a href="https://jupyter-notebook.readthedocs.io/en/stable/public_server.html">enable a password</a></strong>.</p></blockquote><p><a href="https://jupyter-notebook.readthedocs.io/en/stable/public_server.html">相关信息</a></p><p>总的来说就是  使用jupyter lab password 然后对于Enter password 使用空格</p><p>对于Verify password 使用空格，然后就会Wrote hashed password to /home/myalos/.jupyter/jupyter_server_config.json</p><p><strong>小提琴图</strong></p><p><a href="https://zhuanlan.zhihu.com/p/376055263">关于小提琴图的博客链接</a></p><p>总的来说就是箱型图和密度图的结合，中间的黑色粗条表示四分位数范围，从其延伸的幼细黑线代表 95% 置信区间，而白点则为中位数。</p><p><a href="https://seaborn.pydata.org/tutorial/categorical.html#categorical-tutorial">关于point plot的内容</a></p><p>上面链接里面给的点图 可以比较清晰的看出不同class survive的情况，图中的bar能显示出均值也能显示吃confidence interval</p><p><a href="https://en.wikipedia.org/wiki/Andrews_plot">andrews plot的wiki</a></p><p>安德鲁斯图是一种可视化高维数据结构的方法</p><p>对于一个d维的数据$x$，安德鲁斯图画出来的就是一个finite Fourier series</p><script type="math/tex; mode=display">f_x(t) = \frac{x_1}{\sqrt{2}} + x_2sin(t) + x_3cos(t) + x_4sin(2t) + x_5cos(2t) + \cdots</script><p>这个函数的自变量取值范围是-pi 到 pi</p><p><strong>If there is structure in the data, it may be visible in the Andrews curves of the data.</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns<span class="token keyword">from</span> pandas <span class="token keyword">import</span> plotting<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifier<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> tree<span class="token comment"># 加载数据集</span>data <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 转换成.DataFrame形式</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token punctuation">.</span>data<span class="token punctuation">,</span> columns <span class="token operator">=</span> data<span class="token punctuation">.</span>feature_names<span class="token punctuation">)</span><span class="token comment"># 添加品种列</span>df<span class="token punctuation">[</span><span class="token string">'Species'</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">.</span>target<span class="token comment"># 查看数据集信息</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"数据集信息：\n</span><span class="token interpolation"><span class="token punctuation">&#123;</span>df<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token comment"># 查看前5条数据</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"前5条数据：\n</span><span class="token interpolation"><span class="token punctuation">&#123;</span>df<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token comment"># 查看各特征列的摘要信息</span>df<span class="token punctuation">.</span>describe<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 设置颜色主题</span>antV <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'#1890FF'</span><span class="token punctuation">,</span> <span class="token string">'#2FC25B'</span><span class="token punctuation">,</span> <span class="token string">'#FACC14'</span><span class="token punctuation">,</span> <span class="token string">'#223273'</span><span class="token punctuation">,</span> <span class="token string">'#8543E0'</span><span class="token punctuation">,</span> <span class="token string">'#13C2C2'</span><span class="token punctuation">,</span> <span class="token string">'#3436c7'</span><span class="token punctuation">,</span> <span class="token string">'#F04864'</span><span class="token punctuation">]</span> <span class="token comment"># 绘制violinplot</span>f<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span> sharex<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>sns<span class="token punctuation">.</span>despine<span class="token punctuation">(</span>left<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment"># 删除上方和右方坐标轴上不需要的边框，这在matplotlib中是无法通过参数实现的</span>sns<span class="token punctuation">.</span>violinplot<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token string">'Species'</span><span class="token punctuation">,</span> y<span class="token operator">=</span>df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token operator">=</span>df<span class="token punctuation">,</span> palette<span class="token operator">=</span>antV<span class="token punctuation">,</span> ax<span class="token operator">=</span>axes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>sns<span class="token punctuation">.</span>violinplot<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token string">'Species'</span><span class="token punctuation">,</span> y<span class="token operator">=</span>df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token operator">=</span>df<span class="token punctuation">,</span> palette<span class="token operator">=</span>antV<span class="token punctuation">,</span> ax<span class="token operator">=</span>axes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>sns<span class="token punctuation">.</span>violinplot<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token string">'Species'</span><span class="token punctuation">,</span> y<span class="token operator">=</span>df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token operator">=</span>df<span class="token punctuation">,</span> palette<span class="token operator">=</span>antV<span class="token punctuation">,</span> ax<span class="token operator">=</span>axes<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>sns<span class="token punctuation">.</span>violinplot<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token string">'Species'</span><span class="token punctuation">,</span> y<span class="token operator">=</span>df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token operator">=</span>df<span class="token punctuation">,</span> palette<span class="token operator">=</span>antV<span class="token punctuation">,</span> ax<span class="token operator">=</span>axes<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 绘制pointplot</span>f<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> sharex<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>sns<span class="token punctuation">.</span>despine<span class="token punctuation">(</span>left<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>sns<span class="token punctuation">.</span>pointplot<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token string">'Species'</span><span class="token punctuation">,</span> y<span class="token operator">=</span>df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token operator">=</span>df<span class="token punctuation">,</span> color<span class="token operator">=</span>antV<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>axes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>sns<span class="token punctuation">.</span>pointplot<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token string">'Species'</span><span class="token punctuation">,</span> y<span class="token operator">=</span>df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token operator">=</span>df<span class="token punctuation">,</span> color<span class="token operator">=</span>antV<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>axes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>sns<span class="token punctuation">.</span>pointplot<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token string">'Species'</span><span class="token punctuation">,</span> y<span class="token operator">=</span>df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token operator">=</span>df<span class="token punctuation">,</span> color<span class="token operator">=</span>antV<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>axes<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>sns<span class="token punctuation">.</span>pointplot<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token string">'Species'</span><span class="token punctuation">,</span> y<span class="token operator">=</span>df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token operator">=</span>df<span class="token punctuation">,</span> color<span class="token operator">=</span>antV<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>axes<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># g = sns.pairplot(data=df, palette=antV, hue= 'Species')</span>plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>figsize <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plotting<span class="token punctuation">.</span>andrews_curves<span class="token punctuation">(</span>df<span class="token punctuation">,</span> <span class="token string">'Species'</span><span class="token punctuation">,</span> colormap<span class="token operator">=</span><span class="token string">'cool'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 加载数据集</span>data <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 转换成.DataFrame形式</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token punctuation">.</span>data<span class="token punctuation">,</span> columns <span class="token operator">=</span> data<span class="token punctuation">.</span>feature_names<span class="token punctuation">)</span><span class="token comment"># 添加品种列</span>df<span class="token punctuation">[</span><span class="token string">'Species'</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">.</span>target<span class="token comment"># 用数值替代品种名作为标签</span>target <span class="token operator">=</span> np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>data<span class="token punctuation">.</span>target<span class="token punctuation">)</span>target_names <span class="token operator">=</span> np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>data<span class="token punctuation">.</span>target_names<span class="token punctuation">)</span>targets <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>target<span class="token punctuation">,</span> target_names<span class="token punctuation">)</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">'Species'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Species'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span>targets<span class="token punctuation">)</span><span class="token comment"># 提取数据和标签</span>X <span class="token operator">=</span> df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token string">"Species"</span><span class="token punctuation">)</span>y <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"Species"</span><span class="token punctuation">]</span>feature_names <span class="token operator">=</span> X<span class="token punctuation">.</span>columnslabels <span class="token operator">=</span> y<span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span>X_train<span class="token punctuation">,</span> test_x<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> test_lab <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>                                                 test_size <span class="token operator">=</span> <span class="token number">0.4</span><span class="token punctuation">,</span>                                                 random_state <span class="token operator">=</span> <span class="token number">42</span><span class="token punctuation">)</span>model <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>max_depth <span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">42</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span> <span class="token comment"># 以文字形式输出树     </span>text_representation <span class="token operator">=</span> tree<span class="token punctuation">.</span>export_text<span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>text_representation<span class="token punctuation">)</span><span class="token comment"># 用图片画出</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> facecolor <span class="token operator">=</span><span class="token string">'g'</span><span class="token punctuation">)</span> <span class="token comment">#</span>a <span class="token operator">=</span> tree<span class="token punctuation">.</span>plot_tree<span class="token punctuation">(</span>model<span class="token punctuation">,</span>                   feature_names <span class="token operator">=</span> feature_names<span class="token punctuation">,</span>                   class_names <span class="token operator">=</span> labels<span class="token punctuation">,</span>                   rounded <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token comment"># 图片的方框周边是圆角</span>                   filled <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token comment"># 是将图片填充颜色</span>                   fontsize<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>                                 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>训练出来的决策树的准确率维98.3%</p><h3 id="我学到了什么"><a href="#我学到了什么" class="headerlink" title="我学到了什么"></a>我学到了什么</h3><ul><li>小提琴图，点图，安德鲁斯图来可视化数据</li><li>sklearn的决策树用法 以及用两种方式来可视化决策树</li></ul>]]></content>
      
      
      <categories>
          
          <category> sklearn </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> sklearn </tag>
            
            <tag> datawhale </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>朴素贝叶斯</title>
      <link href="2021/12/21/datawhale%20sklearn%203/"/>
      <url>2021/12/21/datawhale%20sklearn%203/</url>
      
        <content type="html"><![CDATA[<h2 id="Task03-朴素贝叶斯"><a href="#Task03-朴素贝叶斯" class="headerlink" title="Task03 朴素贝叶斯"></a>Task03 朴素贝叶斯</h2><p><a href="https://github.com/datawhalechina/machine-learning-toy-code/blob/main/ml-with-sklearn/Bayes/NBayes.ipynb">datawhale学习资料链接</a></p><p>感觉这次的学习内容比较少，所以就学的细一点，主要的内容就是用make blobs生成两类数据集，然后用sklearn.naive_bayes中的GaussianNB来进行分类</p><p><strong>sklearn的make_blobs产生数据</strong> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html">make blobs的文档</a></p><p>Generate isotropic Gaussian blobs for clustering</p><ul><li><p>n_samples 要么是int 要么是array-like的，对于int 就是make blobs要生成的样本点总数，然后会平均分给每个类。如果是array-like的话 那么列表的每个元素就代表相应类的sample数</p></li><li><p>n_features 每个样本的feature的数目</p></li><li><p>centers  整型或者是形状为(n_centers, n_features)，ndarray</p><p>The number of centers to generate, or the fixed center locations.  代码中用的是2</p><p>！！经测试 这个参数就是指定类别的个数</p></li><li><p>cluster_std</p><p>就是每个类的std</p></li></ul><p>返回值是X和y  还有centers 如果参数中有return_centers 是 True 这个是在0.23版本之后</p><p><strong>sns.set()</strong> 是seaborn设置风格的函数</p><p>！！！ vscode的jupyter 中反撤销的按键是Ctrl z</p><p>对于sklearn中的estimator 除了predict函数以外还有predict_proba 这个会返回每个样本分类到不同类的概率</p><p><strong>下面是完整代码</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_blobs<span class="token comment"># make_blobs：为聚类产生数据集</span><span class="token comment"># n_samples：样本点数，n_features：数据的维度，centers:产生数据的中心点，默认值3</span><span class="token comment"># cluster_std：数据集的标准差，浮点数或者浮点数序列，默认值1.0，random_state：随机种子</span>X<span class="token punctuation">,</span> y <span class="token operator">=</span> make_blobs<span class="token punctuation">(</span>n_samples <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">,</span> n_features<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> centers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> cluster_std<span class="token operator">=</span><span class="token number">1.5</span><span class="token punctuation">)</span> plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'RdBu'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>naive_bayes <span class="token keyword">import</span> GaussianNBmodel <span class="token operator">=</span> GaussianNB<span class="token punctuation">(</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>rng <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>RandomState<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>X_test <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">14</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">]</span> <span class="token operator">*</span> rng<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2000</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>y_pred <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'RdBu'</span><span class="token punctuation">)</span>lim <span class="token operator">=</span> plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y_pred<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'RdBu'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span>lim<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="我学到什么"><a href="#我学到什么" class="headerlink" title="我学到什么"></a>我学到什么</h3><ul><li>感觉到seaborn这个库的牛逼，以后有时间就去学一下</li><li>sklearn的make blobs函数</li><li>sklearn的朴素贝叶斯分类器 使用</li></ul>]]></content>
      
      
      <categories>
          
          <category> sklearn </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> sklearn </tag>
            
            <tag> datawhale </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SVM</title>
      <link href="2021/12/18/datawhale%20sklearn%202/"/>
      <url>2021/12/18/datawhale%20sklearn%202/</url>
      
        <content type="html"><![CDATA[<h2 id="Task02-SVM"><a href="#Task02-SVM" class="headerlink" title="Task02 SVM"></a>Task02 SVM</h2><p><a href="https://github.com/datawhalechina/machine-learning-toy-code/blob/main/ml-with-sklearn/SVM/SVM.ipynb">datawhale 学习资料链接</a></p><p>这次学习的内容包括了两个部分，一个部分是在自定义数据集上面分别用线性SVM，多项式SVM，高斯核SVM进行分类，并将分类的结果进行可视化，另一个部分是把这次SVM用在Mnist数据集上面</p><h3 id="线性SVM"><a href="#线性SVM" class="headerlink" title="线性SVM"></a>线性SVM</h3><p><strong>meshgrid函数，<a href="https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html">文档链接</a></strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 主要功能就是 根据两个一维向量来构造出一个网格</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>xx<span class="token punctuation">,</span> yy <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token comment"># 结果是, 对应位置的两个数拼起来就是一个坐标 </span><span class="token comment"># [array([[1, 2, 3],</span><span class="token comment">#         [1, 2, 3],</span><span class="token comment">#         [1, 2, 3]]),</span><span class="token comment">#  array([[2, 2, 2],</span><span class="token comment">#         [3, 3, 3],</span><span class="token comment">#         [4, 4, 4]])]</span><span class="token comment"># 代码中</span><span class="token comment"># xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.002),</span><span class="token comment">#                     np.arange(y_min, y_max, 0.002)) # meshgrid如何生成网格</span><span class="token comment"># 就是将从x_min 到 x_max 和 y_min 到 y_max 组成一个网格</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>np.c_</strong>  是把两个向量按列拼起来， <strong>np.r_</strong>是把两个向量按行进行拼接</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 值得注意的是，下面这个1维的向量 会被当做是列向量</span>a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>a<span class="token punctuation">,</span> b<span class="token punctuation">]</span> <span class="token comment"># 注意这不是调用的，而是用符号[]</span><span class="token comment"># 返回结果是[[1., 4.],[2., 5.],[3., 6.]]</span><span class="token comment"># 而np.r_ 返回的结果是[1., 2., 3., 4., 5., 6.] 相当于按行拼接</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>下面是完整代码</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>    <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">[</span><span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">[</span><span class="token number">0.8</span><span class="token punctuation">,</span> <span class="token number">0.04</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">[</span><span class="token number">0.42</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">[</span><span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">[</span><span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span> <span class="token number">0.67</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">[</span><span class="token number">0.27</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.72</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>label <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">6</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">6</span>x_min<span class="token punctuation">,</span> x_max <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">0.2</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.2</span>y_min<span class="token punctuation">,</span> y_max <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">0.2</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.2</span>xx<span class="token punctuation">,</span> yy <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>x_min<span class="token punctuation">,</span> x_max<span class="token punctuation">,</span> <span class="token number">0.002</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>y_min<span class="token punctuation">,</span> y_max<span class="token punctuation">,</span> <span class="token number">0.002</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># meshgrid如何生成网格</span>model_linear <span class="token operator">=</span> svm<span class="token punctuation">.</span>SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span> C <span class="token operator">=</span> <span class="token number">0.001</span><span class="token punctuation">)</span>model_linear<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token comment"># 训练</span>Z <span class="token operator">=</span> model_linear<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>xx<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> yy<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 预测</span><span class="token comment"># 上面这个就是把x坐标在x_min 到 x_max, y坐标在y_min 到 y_max 所有点形成一个网格</span><span class="token comment"># 然后用np.c_ ravel() 将网格中所有点变成[点数，2]的ndarray</span><span class="token comment"># 用data label训练出来的SVM 对网格中所有点进行预测</span>Z <span class="token operator">=</span> Z<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>xx<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>contourf<span class="token punctuation">(</span>xx<span class="token punctuation">,</span> yy<span class="token punctuation">,</span> Z<span class="token punctuation">,</span> cmap <span class="token operator">=</span> plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>ocean<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span><span class="token comment"># 然后把点画出来 xx yy Z 同等大小 相同位置对应x坐标y坐标 高度</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span> plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'x'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Linear SVM'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>PS</strong> contour 与 contourf的区别， contourf会填充线等高线之间的轮廓而contour不会</p><h3 id="多项式SVM"><a href="#多项式SVM" class="headerlink" title="多项式SVM"></a>多项式SVM</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span> degree <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># C: 惩罚系数，gamma: 高斯核的系数</span>    model_poly <span class="token operator">=</span> svm<span class="token punctuation">.</span>SVC<span class="token punctuation">(</span>C<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">,</span> kernel<span class="token operator">=</span><span class="token string">'poly'</span><span class="token punctuation">,</span> degree<span class="token operator">=</span>degree<span class="token punctuation">)</span> <span class="token comment"># 多项式核</span>    model_poly<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data<span class="token punctuation">,</span> label<span class="token punctuation">)</span>    <span class="token comment"># ravel - flatten</span>    <span class="token comment"># c_ - vstack</span>    <span class="token comment"># 把后面两个压扁之后变成了x1和x2，然后进行判断，得到结果在压缩成一个矩形</span>    Z <span class="token operator">=</span> model_poly<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>xx<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> yy<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    Z <span class="token operator">=</span> Z<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>xx<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>subplots_adjust<span class="token punctuation">(</span>wspace<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">,</span> hspace<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>contourf<span class="token punctuation">(</span>xx<span class="token punctuation">,</span> yy<span class="token punctuation">,</span> Z<span class="token punctuation">,</span> cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>ocean<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span>     <span class="token comment"># 画出训练点</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'x'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Poly SVM with $\degree=$'</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>degree<span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>subplots_adjust的作用就是设置多个子图时间的间距，这个语句可以放在plt.show上面，效果一样</p><p><strong>我跑这个代码会出现一个warning，就是要我手动设置gamma</strong> 如果我的gamma设置成scale，那么生成的图就和github链接里面的图一样，如果设成auto的话，图就如下面这个样子</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">FutureWarning: The default value of gamma will change from &#39;auto&#39; to &#39;scale&#39; in version 0.22 to account better for unscaled features. Set gamma explicitly to &#39;auto&#39; or &#39;scale&#39; to avoid this warning<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://s4.ax1x.com/2021/12/18/TVkIsS.png" alt="TVkIsS.png"></p><p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html">sklearn SVC文档</a></p><p>如果gamma是scale的话  那么gamma的值是 $\frac{1}{n_features \times X.var()}$</p><p>如果设置为auto的话 那么gamma就是 $\frac{1}{n_features}$</p><p>对于gamma的含义 <a href="https://scikit-learn.org/stable/modules/svm.html#svm-kernels">参考链接 kernel 1.4.6</a></p><p>我把代码中的gamma 设成 <code>1 / 2 / data.var()</code> 画出来的效果和GitHub上的一样，我print出data.var 发现 值是0.05491388888888888，也就是说gamma变大了，我的理解就是gamma大了，非线性就变强了； <strong>ps 这个var的计算是计算所有元素的，然后取平均</strong> </p><pre class="line-numbers language-text" data-language="text"><code class="language-text">var &#x3D; mean(abs(x-x.mean())** 2)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下图是github上面的图，也就是gamma是scale的时候</p><p><img src="https://s4.ax1x.com/2021/12/18/TVeSpR.png" alt="TVeSpR.png"></p><h3 id="高斯核SVM"><a href="#高斯核SVM" class="headerlink" title="高斯核SVM"></a>高斯核SVM</h3><p>把kernel从poly 换成 rbf 就是高斯核了，从github上面的图可以看出对于rbf 非线性的程度更强了 </p><h3 id="测试不同SVM在mnist-数据集上的分类情况"><a href="#测试不同SVM在mnist-数据集上的分类情况" class="headerlink" title="测试不同SVM在mnist 数据集上的分类情况"></a>测试不同SVM在mnist 数据集上的分类情况</h3><p>github上面代码 是用了mnist训练集中前2000个样本作为训练集，测试集中前200个样本作为测试</p><p>线性核 C设为100  准确率是0.88 </p><p>多项式核 C设为100 然后degree 1 3 5 7 9 准确率最高的是3 0.935</p><p>高斯核 C为100 然后gamma 0.01 0.03 0.05 0.07 0.09 准确率最高的是</p><blockquote><p>关于SVC中 C的取值</p><p>C越大，相当于惩罚松弛变量，希望松弛变量接近0，即对误分类的惩罚增大，趋向于对训练集全分对的情况，这样对训练集测试时准确率很高，但泛化能力弱。C值小，对误分类的惩罚减小，允许容错，将他们当成噪声点，泛化能力较强。</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> fetch_openmlmnist <span class="token operator">=</span> fetch_openml<span class="token punctuation">(</span><span class="token string">'mnist_784'</span><span class="token punctuation">)</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_splitXtrain<span class="token punctuation">,</span> Ytrain<span class="token punctuation">,</span> Xtest<span class="token punctuation">,</span> Ytest <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>mnist<span class="token punctuation">.</span>data<span class="token punctuation">,</span> mnist<span class="token punctuation">.</span>target<span class="token punctuation">,</span> test_size <span class="token operator">=</span> <span class="token number">0.15</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">215</span><span class="token punctuation">)</span><span class="token comment"># 线性核 </span><span class="token comment"># 先取个默认的</span>model <span class="token operator">=</span> svm<span class="token punctuation">.</span>SVC<span class="token punctuation">(</span>kernel <span class="token operator">=</span> <span class="token string">'linear'</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>Xtrain<span class="token punctuation">,</span>Ytrain<span class="token punctuation">)</span>model<span class="token punctuation">.</span>score<span class="token punctuation">(</span>Xtest<span class="token punctuation">,</span> Ytest<span class="token punctuation">)</span><span class="token comment"># 运行时间太长了 改天用我实验室闲置的电脑去跑</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>补充</strong></p><p>后来发现这个代码的运行时间出奇的慢，我感觉可能代码写的有问题， 网上一搜发现这个代码 可能收敛速度极其之慢，于是我给他设置了一个max_iter = 10000 然后运行 忘记记录时间了 运行出来的准确率是0.80</p><p>不过他提示要我把数据scale一下 我看了一下原数据，发现原数据是0到255的 那我就scale一下 再跑</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 改</span><span class="token operator">%</span><span class="token operator">%</span>time <span class="token comment"># 用这个可以看下面statement的运行时间</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> Pipeline<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScalerpipe <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'s'</span><span class="token punctuation">,</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'svc'</span><span class="token punctuation">,</span> svm<span class="token punctuation">.</span>SVC<span class="token punctuation">(</span>kernel <span class="token operator">=</span> <span class="token string">'linear'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>pipe<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>Xtrain<span class="token punctuation">,</span> Ytrain<span class="token punctuation">)</span><span class="token comment"># 运行时间7m31s</span><span class="token comment"># 准确率91.57%</span><span class="token comment"># 使用confusion_matrix</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> confusion_matrixmat <span class="token operator">=</span> confusion_matrix<span class="token punctuation">(</span>Ytest<span class="token punctuation">,</span> pipe<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>Xtest<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># array([[ 973,    0,    2,    2,    0,   11,    6,    0,    4,    0],</span><span class="token comment">#       [   0, 1088,    8,    4,    2,    1,    1,    6,   11,    2],</span><span class="token comment">#       [   8,   19,  969,   23,   13,    6,   13,   14,   25,    3],</span><span class="token comment">#       [   2,    4,   21,  979,    1,   30,    0,    5,   21,    9],</span><span class="token comment">#       [   2,    5,   16,    1,  993,    2,    6,    8,    4,   32],</span><span class="token comment">#       [  14,    4,   10,   49,    6,  808,   13,    1,   16,    4],</span><span class="token comment">#       [   9,    3,   21,    1,   11,   18,  934,    0,    3,    0],</span><span class="token comment">#       [   2,    3,   13,   11,   20,    2,    0, 1022,    5,   24],</span><span class="token comment">#       [  11,   17,   21,   27,    6,   30,    3,    7,  917,   12],</span><span class="token comment">#       [   8,    3,    7,   11,   45,    4,    1,   51,    5,  932]],</span><span class="token comment">#      dtype=int64)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">%</span><span class="token operator">%</span>timeresult <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> c <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token number">0.001</span><span class="token punctuation">,</span> <span class="token number">0.003</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token number">0.03</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">3.0</span><span class="token punctuation">,</span> <span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token number">30.0</span><span class="token punctuation">,</span> <span class="token number">100.0</span><span class="token punctuation">,</span> <span class="token number">300.0</span><span class="token punctuation">,</span> <span class="token number">1000.0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    pipe <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'s'</span><span class="token punctuation">,</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'svc'</span><span class="token punctuation">,</span> svm<span class="token punctuation">.</span>SVC<span class="token punctuation">(</span>kernel <span class="token operator">=</span> <span class="token string">'linear'</span><span class="token punctuation">,</span>C <span class="token operator">=</span> c<span class="token punctuation">,</span> max_iter <span class="token operator">=</span> <span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    pipe<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>Xtrain<span class="token punctuation">,</span> Ytrain<span class="token punctuation">)</span>    result<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pipe<span class="token punctuation">.</span>score<span class="token punctuation">(</span>Xtest<span class="token punctuation">,</span> Ytest<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 这个代码我从某一天下午开始运行，运行到第二天早上还没有运行完。。。</span><span class="token comment"># 我把程序改成max_iter为10000</span><span class="token comment"># 运行时间维1h 39min 56s</span><span class="token comment"># 运行结果</span><span class="token comment"># [0.937047619047619,</span><span class="token comment"># 0.9383809523809524,</span><span class="token comment"># 0.9407619047619048,</span><span class="token comment"># 0.9365714285714286,</span><span class="token comment"># 0.9284761904761905,</span><span class="token comment"># 0.9122857142857143,</span><span class="token comment"># 0.8566666666666667,</span><span class="token comment"># 0.813047619047619,</span><span class="token comment"># 0.8131428571428572,</span><span class="token comment"># 0.8131428571428572,</span><span class="token comment"># 0.8131428571428572,</span><span class="token comment"># 0.8131428571428572,</span><span class="token comment"># 0.8131428571428572]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="我学到了什么"><a href="#我学到了什么" class="headerlink" title="我学到了什么"></a>我学到了什么</h3><ul><li>用plt画多张图，subplot 前两个参数指定行和列 最后一个指定第几张图，索引从1开始</li><li>np.meshgrid  np.c_   np.r_ 函数</li><li>SVC gamma参数的含义，gamma越大 非线性能力越强，C的含义，C越大对松弛变量的惩罚越大</li></ul>]]></content>
      
      
      <categories>
          
          <category> sklearn </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> sklearn </tag>
            
            <tag> datawhale </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>datawhale组队学习 sklearn task01</title>
      <link href="2021/12/15/datawhale%20sklearn%201/"/>
      <url>2021/12/15/datawhale%20sklearn%201/</url>
      
        <content type="html"><![CDATA[<h2 id="Task01-线性回归与逻辑回归"><a href="#Task01-线性回归与逻辑回归" class="headerlink" title="Task01 线性回归与逻辑回归"></a>Task01 线性回归与逻辑回归</h2><p>线性回归的学习链接 <a href="https://github.com/datawhalechina/machine-learning-toy-code/tree/main/ml-with-sklearn/LinearRegression">github链接</a></p><h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>线性回归主要是用于 预测连续值问题的</p><p>线性归回里面的代码主要是用线性回归的方法来预测自定义的曲线</p><p><strong>数据是从自定义曲线加上噪声形成的曲线中30个采样点</strong></p><p>模型预测的效果是通过将采样点 和 自定义曲线 和 预测的曲线 放在一张图中进行显示</p><blockquote><p>关于PolynomialFeatures的用法 <a href="https://www.cnblogs.com/liweiwei1419/p/9715702.html">参考链接</a></p></blockquote><p>核心在于PolynomialFeatures是一个预处理 对应的接口是 fit  transform</p><p><strong>值得注意的是</strong>  对于两个以上的特征 例如 a b， degree是2的话 新的特征会包含交叉项ab，即特征变成a b ab $a^2$ $b^2$ 1 如果include_bias设置为False 那么1就没有了</p><blockquote><p>关于Pipeline的文档 <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline">文档链接</a></p></blockquote><p>Pipeline是将多个estimators连接起来，除了最后一个estimator，其余的estimator都要实现transform的方法</p><p>Pipeline是由一个由key value的元组构成的列表来初始化的，其中key的名字是自定义的，可以通过下标或者key来索引到相应的value</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">pipeline <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"polynomial_features"</span><span class="token punctuation">,</span> polynomial_features<span class="token punctuation">)</span><span class="token punctuation">,</span>                         <span class="token punctuation">(</span><span class="token string">"linear_regression"</span><span class="token punctuation">,</span> linear_regression<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><blockquote><p>关于线性回归的评价指标 neg_mean_squared_error</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">scores <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>pipeline<span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">,</span> scoring<span class="token operator">=</span><span class="token string">"neg_mean_squared_error"</span><span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Degree &#123;&#125;\nMSE = &#123;:.2e&#125;(+/- &#123;:.2e&#125;)"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>degrees<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span>scores<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> scores<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>交叉验证 <strong>通过均值和方差来从数值上比较效果</strong></p><h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><p>逻辑回归主要是用于二分类的</p><p>这个于线性回归的区别是 loss函数不同，预测的形式不同，本质上是一样的都是根据loss算梯度更新参数</p><p>逻辑回归sklearn 部分的代码是用sklearn的LogisticRegression 来预测手写字符，其中数据集是train的前2000，test是测试集的前200</p><p>逻辑回归numpy 部分的代码是用的全数据，分类目标是针对是否是数字0来进行分类</p><p><a href="https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a">sklearn部分代码上面提供的博客链接</a></p><blockquote><p>首先用sklearn 里面的load_digits 数据集</p></blockquote><p>这个数据集是8 * 8的灰度图像，1797个训练样本，每个样本64个特征</p><p>首先将这个数据集可视化一下 </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">digits <span class="token operator">=</span> load_digits<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># digits.target 是一个ndarray</span>unique<span class="token punctuation">,</span> counts <span class="token operator">=</span> np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>digits<span class="token punctuation">.</span>target<span class="token punctuation">,</span> return_counts <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>count<span class="token punctuation">)</span> <span class="token comment"># 输出是178 182 177 183 181 182 181 179 174 180</span><span class="token comment"># 可以用plt.bar来可视化一下</span>plt<span class="token punctuation">.</span>bar<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> counts<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>用sklearn里面的logisticregression来训练 load_digits</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>digits<span class="token punctuation">.</span>data<span class="token punctuation">,</span> digits<span class="token punctuation">.</span>target<span class="token punctuation">,</span> test_size <span class="token operator">=</span> <span class="token number">0.25</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegressionlogistic <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>max_iter <span class="token operator">=</span> <span class="token number">10000</span><span class="token punctuation">,</span> multi_class <span class="token operator">=</span> <span class="token string">'ovr'</span><span class="token punctuation">)</span><span class="token comment"># 如果用默认的max iter的话 那么报错 lbfgs failed to converge</span>logistic<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>logistic<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>logistic<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token comment"># 返回0.951111 如果multi_class用multinomial的话就是0.95333 运行时间要长一些</span><span class="token comment"># 如果用cross_val_score</span>cross_val_score<span class="token punctuation">(</span>LogisticRegression<span class="token punctuation">(</span>max_iter <span class="token operator">=</span> <span class="token number">10000</span><span class="token punctuation">,</span> multi_class<span class="token operator">=</span><span class="token string">'multinomial'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> digits<span class="token punctuation">.</span>data<span class="token punctuation">,</span> digits<span class="token punctuation">.</span>target<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span> <span class="token punctuation">)</span><span class="token comment"># 输出是  array([0.90555556, 0.95555556, 0.88333333, 0.93333333, 0.93888889,</span><span class="token comment">#       0.95      , 0.95      , 0.93296089, 0.88268156, 0.94413408])</span><span class="token comment"># 平均 0.9276</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我发现这个里面的logisticregression 是可以处理多分类的，其中的multi_class 就是指定对分类的方法，ovr是one vs rest 一对多的，multinomial是一对一？ 这个知识点先放置</p><blockquote><p>使用confusion matrix 来可视化结果</p></blockquote><p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion\_matrix.html">sklearn中confusion_matrix的文档链接</a></p><p>第i行 第j列的元素 表示 真值为i 预测为j的个  <strong>这个函数第一个参数是真值 第二个是预测值，都是array_like的，且形状是n_samples, </strong></p><p><strong>666！！！</strong>  confusion_matrix 可以使用 torch的tensor作为输入</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">metrics<span class="token punctuation">.</span>confusion_matrix<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>使用sns.heatmap 可以很漂亮的显示出heatmap Pastel1颜色挺好看的</p><blockquote><p>使用mnist数据集</p></blockquote><p>给的链接里面用的是</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> fetch_mldatamnist <span class="token operator">=</span> fetch_mldata<span class="token punctuation">(</span><span class="token string">"MNIST original"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>报错cannot import， 网上搜了一下，sklearn 0.20版本之后用的是下面的代码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> fetch_openmlmnist <span class="token operator">=</span> fetch_openml<span class="token punctuation">(</span><span class="token string">'mnist_784'</span><span class="token punctuation">)</span><span class="token comment"># type(mnist.data) 是pandas的DataFrame</span><span class="token comment"># 如果要转成numpy的话</span><span class="token comment"># mnist.data.values</span><span class="token comment">#对于DataFrame也可以直接split</span>train_img<span class="token punctuation">,</span> test_img<span class="token punctuation">,</span> train_lbl<span class="token punctuation">,</span> test_lbl <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>mnist<span class="token punctuation">.</span>data<span class="token punctuation">,</span> mnist<span class="token punctuation">.</span>target<span class="token punctuation">,</span> test_size <span class="token operator">=</span> <span class="token number">0.25</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>ll <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>max_iter <span class="token operator">=</span> <span class="token number">10000</span><span class="token punctuation">)</span>ll<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_img<span class="token punctuation">,</span> train_lbl<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>ll<span class="token punctuation">.</span>score<span class="token punctuation">(</span>test_img<span class="token punctuation">,</span> test_lbl<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行时间 18分26秒 lbfgs没有converge</p><h3 id="我学到了什么"><a href="#我学到了什么" class="headerlink" title="我学到了什么"></a>我学到了什么</h3><ul><li><p>preprocess里面的PolynomialFeatures的用法</p></li><li><p>sklearn的fit函数中 X的shape要大于1  y的shape可以为1</p><p> 如果要把X额外增加一个维度 可以<code>X[:, np.newaxis]</code></p></li><li><p>Pipeline的用法</p></li><li><p>了解了sklearn中load_digits数据集 和 如何使用sklearn的mnist数据集</p></li><li><p>对分类问题 使用confusion matrix来显示出结果，confusion matrix的输入可以是torch的tensor</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> sklearn </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> sklearn </tag>
            
            <tag> datawhale </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DIY主机安装log</title>
      <link href="2021/12/09/computer/"/>
      <url>2021/12/09/computer/</url>
      
        <content type="html"><![CDATA[<h2 id="DIY主机安装log"><a href="#DIY主机安装log" class="headerlink" title="DIY主机安装log"></a>DIY主机安装log</h2><h3 id="买主机的经历"><a href="#买主机的经历" class="headerlink" title="买主机的经历"></a>买主机的经历</h3><p>由于要使用显卡去炼丹，我在淘宝上面买了一台DIY的机器，买的时候没有做多少功课，也没有问别人就自己直接买了，选了一个丐版的机器买了。由于现在是一个显卡溢价，超多矿卡不知纵向的时代，由于担心GPU质量于是买的是散装发货，我以为是GPU散 主机不散，结果是全散。邮寄是用德邦快递，大概2天就到了，送过来的箱子很大也比较重，基本上零件都是盒装的，CPU和硬盘是散装的，我买的GPU没有塑封，问了店家，我这个牌子的GPU都是没有塑封的，拆开看了以后感觉像全新的，我也就不折腾了。我买的店家在宣传上面说发转机视频，结果店家发的是其他的主机加其他配件的视频，让我类比去装。</p><p>有两个负责售后的客服指导我装机，主要是后面的那个客服比较给力，省了我不少时间，第一个客服感觉还行 但没有后面那个给力，装机花了差不多一整天，9小时+ 终于装好了。装完之后想写个log来记录一下，并且分享一下自己在经历之后的一些经验，闭门造车经验有限。</p><h3 id="买主机的经验"><a href="#买主机的经验" class="headerlink" title="买主机的经验"></a>买主机的经验</h3><p>一些卖DIY主机的店卖主机的时候会有相应的主机配置介绍，如下图（我随便在网上找的一张图）</p><p><img src="https://s1.ax1x.com/2021/12/09/o4AzvV.md.png" alt="随便找的一张图"></p><p><strong>我买的店家没有任何设备是自己产的， 也就是说这些零件可以完全自己买，自己装，DIY主机的店家起的是一个帮你选零件和买零件的</strong></p><p>我自己搜在淘宝上面搜了一下这些零件的价格，发现加起来要比DIY店家给的价格要高（双11和双12店家的价格），这是对于我买的主机来说。不过我感觉应该DIY店家的主机价格肯定要低于自己买这些零件的价格，不然肯定卖不出去啊！如果自己要装机的话，可以买一些非热门的零件，或者一些二手的零件（要注意适配）</p><h3 id="装机的过程"><a href="#装机的过程" class="headerlink" title="装机的过程"></a>装机的过程</h3><p>这个过程只针对我的主机，不一定适用于其他主机，不过应该时类似的。</p><p>1、首先装CPU 内存 固态硬盘（这一步最简单），装CPU的时候找准对齐的位置，我的主板上面有四个内存槽，有两个内存槽是一个类型，另外两个内存槽是另一个类型。如果遇到这个情况，可以问一下客服优先装哪个槽。装固态的时候，我装的是M2接口的硬盘，有一个螺丝A，一个六边形的可以转的别的螺丝可以插上去的零件B（不好描述，不知道这个叫什么） ，我把固态要拧螺丝的一端用硬盘 B A（从下到上）的方式装上去了，发现硬盘不是水平的，后来发现要用B 硬盘 A的方式装！！ <strong>主板里面带的零件中我只用了上面说的A和B</strong></p><p>2、安装水冷风扇，我是根据b站视频安装的。水冷里面的附带的零件比较多，因为是要针对不同架构的主板的，不同架构的主板装水冷是不一样的，所以水冷给的零件有多余的。安装时要注意冷管相对于CPU的位置，风扇相对于冷管的位置（这个我装错了，重新装了一遍）</p><p>3、拆开机箱，机箱附带的零件有固定主板到机箱的螺丝，固定电源到机箱的螺丝，这里面的螺丝不是全部都要用上的，有一部分是多出来备用的。机箱自己有一套线，这些线是对应机箱上面的一些接口或者按键，比如电源键就有一条PowerSW的线。</p><p>4、安装电源，电源附带的零件有输出电源线，电源延长线。输出电源线就是插在这个电源上面 然后给相应的装置供电的这样的东西。<strong>装电源之前先把需要用到的所有电源输出线给装上！！</strong> 不是所有的线都要装，我有点后悔之前都装上去了，对于我的机器需要的是一个主板供电的电源线，2个CPU供电的电源线，一个PCIe接口的电源线（给GPU用的）剩下的线有风扇的线，SATA硬盘的线（这个我没有用上），我的电源是通过螺丝固定到机箱上面的。</p><p>5、 螺丝固定主板，螺丝固定风扇</p><p>6、 安装GPU，GPU里面附带的零件我一个都没有用</p><p>7、把电源输出线插到相应位置，把机箱附带的线插到主板上面相应位置</p><h3 id="装机经验"><a href="#装机经验" class="headerlink" title="装机经验"></a>装机经验</h3><p>可以通过以下渠道来得知装机的方法</p><ul><li><p>直接问客服</p></li><li><p>阅读零件的说明书</p></li><li><p>b站上面搜相应零件的安装视频，像我的水冷堡垒360rgbv2就是按着b站上面堡垒240rgb的视频去装的，<strong>每个机箱对应的零件安装是不一样的，可以把机箱作为关键字在b站上搜</strong></p></li><li><p>网上搜文章</p></li></ul><h3 id="安装操作系统"><a href="#安装操作系统" class="headerlink" title="安装操作系统"></a>安装操作系统</h3><p>我用的是ubuntu20.0.4 用rufus写到U盘上面的，过程大概是，网上下好ubuntu的镜像，然后插上U盘，将U盘格式化，然后点开rufus 设置成如下：</p><p><img src="https://s1.ax1x.com/2021/12/09/o4Qk5T.png" alt="rufus配置"> </p><p>然后点开始，U盘就制作完成了。然后设置主机BIOS，我的主机BIOS要先delete boot security key，每个主机设置不一样，我之前搜装操作系统文章的时候，发现有些主机是要禁掉boot security 然后enable usb之类的。BIOS设置完后，重启电脑就进入到操作系统安装程序了，对于ubuntu的安装 顺着点就完事了，要注意的是分区，**我的分区方案是 /boot ext4 300mb, 100mb efi, 8192mb swap, 其余全是根目录。安装完后，拔掉U盘重启就能进系统了。</p>]]></content>
      
      
      <categories>
          
          <category> 日常 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 认真系列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据预处理和特征选择</title>
      <link href="2021/11/01/feature%20engineer/"/>
      <url>2021/11/01/feature%20engineer/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.bilibili.com/video/BV1MA411J7wm?p=29">视频链接</a></p><h3 id="数据预处理和特征工程的简介"><a href="#数据预处理和特征工程的简介" class="headerlink" title="数据预处理和特征工程的简介"></a>数据预处理和特征工程的简介</h3><ul><li>数据预处理是从数据中检测，纠正或删除损坏，不准确或不适用于模型的记录的过程，其目的是让数据适应模型，匹配模型的需求</li><li>特征工程是将原始数据转换为更能代表预测模型的潜在问题的特征的过程，可以通过挑选最相关的特征，提取特征以及创造特征来实现。其中创造特征又进场以降维算法的方式实现。其目的是降低计算成本，提升模型上线</li></ul><h3 id="数据无量纲化"><a href="#数据无量纲化" class="headerlink" title="数据无量纲化"></a>数据无量纲化</h3><p>将不同规格的数据转换到统一规格，或不同分布的数据转换到某个指定的分布的需求，这种需求统称为将数据无量纲化。在逻辑回归，SVM，NN，无量纲化可以加快求解速度；在距离类模型，KNN，KMeans，无量纲化可以提升模型精度，避免某一个取值范围特别大的特征对距离计算的影响</p><ul><li><p>preprocessing.MinMaxScaler</p><script type="math/tex; mode=display">x^* = \frac{x - min(x)}{max(x) - min(x)}</script><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 这个操作叫归一化 Normalization</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScalerdata <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdpd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token punctuation">)</span>scaler <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>scaler <span class="token operator">=</span> scaler<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data<span class="token punctuation">)</span>result <span class="token operator">=</span> scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>resultresult_ <span class="token operator">=</span> scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>scaler<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token comment">#使用feature_range来指定输出范围</span>data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span>scaler <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span>feature_range<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>result <span class="token operator">=</span> scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>preprocessing.StandardScaler<script type="math/tex; mode=display">x^* = \frac{x - \mu}{\sigma}</script></li></ul>  <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 这个操作叫数据标准化</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScalerdata <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span>scaler <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>scaler<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data<span class="token punctuation">)</span>scaler<span class="token punctuation">.</span>mean_<span class="token punctuation">,</span> scaler<span class="token punctuation">.</span>var_x_std <span class="token operator">=</span> scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token comment"># 转换完之后 查看均值和标准差</span>x_std<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x_std<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于StandardScaler 和 MinMaxScaler来说，空值NaN会被当做是缺失值</p><p>大多数机器学习算法中，会选择StandardScaler来进行特征缩放，<strong>因为MinMaxScaler对异常值非常敏感。</strong>在PCA，聚类，逻辑回归，SVM，NN中StandardScaler往往是最好的</p><p>MaxAbsScaler  通过让每一个特征里的数据，除以该特征中绝对值最大的数值的绝对值，将数据压缩到-1，1之间。压缩了数据，却不影响数据的稀疏性</p><p>RobustScaler  在异常值多，噪声非常大的时候，我们可能会选用分位数来无量纲化</p><p><strong>缺失值</strong></p><p>PS：  pandas的read_csv 中的index_col参数 设置为0 会让第1列的数据变成索引 </p><p><strong>impute.SimpleImputer</strong></p><ul><li><p>missing_values  数据中的缺失值长什么样</p></li><li><p>strategy 填补缺失值的策略 <strong>默认是均值</strong></p><p>mean 均值， median 中值， most_frequent 众数， constant  常数， 后面两个可以针对字符型</p></li><li><p>copy 默认是True， 将创建特征矩阵的副本，反之则会将缺失值填补到原来的特征矩阵中去</p></li></ul><h3 id="处理离散型特征"><a href="#处理离散型特征" class="headerlink" title="处理离散型特征"></a>处理离散型特征</h3><p>preprocessing.LabelEncoder 标签专用，能够将分类标签转换为分类数值</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelEncodery <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token comment"># 要输入的是标签，不是特征矩阵，维数要为1维</span>le <span class="token operator">=</span> labelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>le <span class="token operator">=</span> le<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>y<span class="token punctuation">)</span>label <span class="token operator">=</span> le<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>y<span class="token punctuation">)</span>le<span class="token punctuation">.</span>classes_ <span class="token comment">#属性.classes_查看标签中究竟有多少类别</span><span class="token comment"># data.iloc[:, -1] = LabelEncoder().fit_transform(data, iloc[:, -1])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>preprocessing.OrdinalEncoder 特征专用，能够将分类特征转换维分类数值</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> OrdinalEncoder<span class="token comment"># 对于OrdinalEncoder的输入要为2维的</span>OrdinalEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>categories_<span class="token comment"># 其返回的数据中，数据类型为numpy.float64</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>preprocessing.OneHotEncoder 独热编码</p><p>下面的是三种不同性质的数据</p><ul><li>三种取值S, C, Q 相互独立，彼此之间完全没有联系，表达的是$S\neq Q \neq C$的概念，名义变量</li><li>学历：小学，初中，高中，三种取值不是完全独立的，性质上有高中$&gt;$初中$&gt;$小学这样的联系，学历取值之间却是不可以计算的，有序变量</li><li>体重  各个取值之间有联系 而且是可以相互计算的 120kg - 45kg  = 90kg  有距变量</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> OneHotEncoderX <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>enc <span class="token operator">=</span> OneHotEncoder<span class="token punctuation">(</span>categories<span class="token operator">=</span><span class="token string">'auto'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token comment"># categories='auto'是必须的</span>result <span class="token operator">=</span> enc<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#如果没有toarray的话 那么只是得到一个对象</span>resultenc<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 将编码完的数据和原来的数据合并</span>newdata <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>data<span class="token punctuation">,</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>newdata<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"Sex"</span><span class="token punctuation">,</span> <span class="token string">"Embarked"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>newdata<span class="token punctuation">.</span>columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"Age"</span><span class="token punctuation">,</span> <span class="token string">"Survived"</span><span class="token punctuation">,</span> <span class="token string">"Female"</span><span class="token punctuation">,</span> <span class="token string">"Male"</span><span class="token punctuation">,</span> <span class="token string">"Embarked_C"</span><span class="token punctuation">,</span> <span class="token string">"Embarked_Q"</span><span class="token punctuation">,</span> <span class="token string">"Embarked_S"</span><span class="token punctuation">]</span>newdata<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="处理连续型特征"><a href="#处理连续型特征" class="headerlink" title="处理连续型特征"></a>处理连续型特征</h3><p>preprocessing.Binarizer</p><p>根据阈值将数据二值化，用于处理连续型变量。大于阈值的值映射为1，小于等于阈值的映射为0</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> BinarizerX <span class="token operator">=</span> data_2<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 输入要为2维数组</span>transformer <span class="token operator">=</span> Binarizer<span class="token punctuation">(</span>threshold <span class="token operator">=</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>preprocessing.KBinsDiscretizer</p><p>将连续型变量划分为分类变量的类，能够将连续型变量排序后按顺序分箱后编码。</p><ul><li>n_bins  每个特征中分箱的个数</li><li>encode 编码的方式 默认onehot，还有ordinal和onehot-dense</li><li>strategy 用来定义箱宽的方式 默认quantile, 还有uniform，kmeans</li></ul><h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><ul><li>特征提取 feature extraction</li><li>特征创造 feature creation</li><li>特征选择 feature selection</li></ul><p>最重要的是要理解业务！</p><p>用kaggle上的手写数字识别来理解特征工程</p><h4 id="方差过滤"><a href="#方差过滤" class="headerlink" title="方差过滤"></a>方差过滤</h4><p>通过特征本身的方差来筛选特征的类。比如一个特征本身的方差很小，就表示样本在这个特征基本上没有什么差异，可能特征中大多数值都一样，甚至整个特征的取值都相同，那这个特征对于样本的区分没有太大的作用，<strong>无论接下来特征工程要做什么</strong>，都要优先消除方差为0的特征，VarianceThreshold里面有一个threshold的参数，sklearn会删除所有方差小于threshold的特征</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selction <span class="token keyword">import</span> VarianceThresholdselector <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span><span class="token punctuation">)</span>X_var0 <span class="token operator">=</span> selector<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>感觉对图像使用方差过滤过滤掉0的特征 挺没有意义的</p><p><strong>根据方差的中位数来进行过滤</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X_fsvar <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span>np<span class="token punctuation">.</span>median<span class="token punctuation">(</span>X<span class="token punctuation">.</span>var<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token comment">#这样做可以去除一半的特征</span>X_fsvar<span class="token punctuation">.</span>shape <span class="token comment"># 变成了42000, 392</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>当特征是二分类时，特征的取值就是伯努利随机变量，这些变量的方差可以计算为</p><script type="math/tex; mode=display">Var[x] = p(1 - p)</script><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 若特征时伯努利随机变量，假设p = 0.8，即二分类特征中某种分类占到80%以上的时候删除特征</span><span class="token comment"># 因为对于手写数字的数据 每个特征取值只能是0或者1 所以可以看作是伯努利</span>X_bvar <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span><span class="token number">.8</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> <span class="token number">.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>X_bvar<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>过滤掉一些特征对随机森林的影响不大，因为随机森林时随机选取特征进行分枝，本身运算就非常快速，因此特征选择对他们来说就效果平平。对于像KNN这样的算法 是需要遍历所有特征的，所以过滤特征对他们来说就尤为重要</p><h4 id="相关性过滤"><a href="#相关性过滤" class="headerlink" title="相关性过滤"></a>相关性过滤</h4><p>我们希望挑选出与标签相关且有意义的特征。如果特征与模型无关，那只会白白浪费我们的计算内存，可能还会给模型带来噪音</p><p><strong>卡方过滤</strong></p><p>卡方过滤式专门针对离散型标签的相关性过滤。卡方检验类feature_selection.chi2 计算每个非负特征和标签之间的卡方统计量，并依照卡方统计量由高到低为特征排名。再结合feature_selection.SelectKBest。这个可以输入“评分标准”来选出前K个分数最高的特征的类，我们可以借此出去最可能独立于标签，与我们分类目的无关的特征</p><p>如果用方差过滤后的模型，要看方差过滤模型的表现是否有提升，如果没有提升 就不要用方差过滤，如果卡方检验检测到某个特征中所有的值都相同，会提示我们使用方差先进行方差过滤</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> SelectKBest<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> chi2X_fschi <span class="token operator">=</span> SelectKBest<span class="token punctuation">(</span>chi2<span class="token punctuation">,</span> k <span class="token operator">=</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_fsvar<span class="token punctuation">,</span> y<span class="token punctuation">)</span>X<span class="token punctuation">.</span>fschi<span class="token punctuation">.</span>shape<span class="token comment"># 验证模型</span>cross_val_score<span class="token punctuation">(</span>RFC<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X_fschi<span class="token punctuation">,</span> y<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 选k值 可以画图选k</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>另一种更好的方法 看p值选择k:</p><p>卡方检验的本质是推测两组数据之间的差异，其检验的原假设是 两组数据是相互独立的。卡方检验返回卡方值和P值两个统计量，其中卡方值很难界定有效的范围，而p值，我们一般使用0.01或0.05作为显著性水平。我们希望选择卡方值很大，p小于0.05的特征</p><p><code>chivalue, pvalues_chi = chi2(X_fsvar, y)</code></p><p>对于k取多少， 我们想要消除所有p值大于设定值</p><p><code>k = chivalue.shape[0] - (pvalues_chi &gt; 0.05).sum()</code></p><p><strong>F检验</strong></p><p>F检验，又称ANOVA，方差齐性检验，是用来捕捉每个特征与标签之间的线性关系的过滤方法，即可以用作分类也可以回归 feature_selection.f_classif 和 feature_selection.f_regression</p><p>要注意 F检验在数据服从正态分布时效果会非常稳定，因此如果使用F检验过滤 那么先将数据转换成服从正态分布的方式；<strong>F检验的原假设是数据 不存在显著的线性关系</strong></p><p>和卡方一样 返回值 是F值和p值</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> f_classifF<span class="token punctuation">,</span> pvalues_f <span class="token operator">=</span> f_classif<span class="token punctuation">(</span>X_fsvar<span class="token punctuation">,</span> y<span class="token punctuation">)</span>k <span class="token operator">=</span> F<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token punctuation">(</span>pvalues_f <span class="token operator">></span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>互信息法</strong></p><p>互信息法使用来捕捉每个特征与标签之间的任意关系的过滤方法，可以用作分类也可以用作回归</p><p>互信息法返回的是一个0到1的值 0表示两个变量独立， 1表示两个变量完全相关</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span>  sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> mutual_info_classif <span class="token keyword">as</span> MICresult <span class="token operator">=</span> MIC<span class="token punctuation">(</span>X_fsvar<span class="token punctuation">,</span> y<span class="token punctuation">)</span>resultk <span class="token operator">=</span> X_fsvar<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token punctuation">(</span>result <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Embedded-嵌入法"><a href="#Embedded-嵌入法" class="headerlink" title="Embedded 嵌入法"></a>Embedded 嵌入法</h4><p>嵌入法是一个让算法自己决定使用哪些特征的方法，即特征选择和算法训练同时进行。使用嵌入法时，先使用某些机器学习的算法和模型进行训练 得到各个权值系数，根据权值系数从大到小选择特征子集，嵌入法的结果会更加精确到模型的效用本身。模型权值系数是我们的超参数。嵌入发引入了算法来挑选特征，并且每次挑选都会使用全部特征，因此其计算速度也会和应用的算法有很大的关系。</p><p>sklearn.feature_selection.SelectFromModel 这是一个元变换器，可以与任何在拟合后具有coef_ 或 feature_importances_属性或者有惩罚项的评估器一起使用</p><p>对于使用惩罚项的模型的嵌入法</p><p>当正则化惩罚项大到一定的程度的时候，部分特征系数会变成0，当正则化惩罚项继续增大到一定程度时，所有的特征系数都会趋于0。但是我们会发现一部分特征系数会更容易先变成0，<strong>这部分系数就是可以筛掉的</strong> SVM和逻辑回归使用参数C来控制返回特征矩阵的稀疏性，参数C越小，返回的特征越少。Lasso回归，用alpha参数来控制返回的特征矩阵，alpha越大，返回的特征越少。</p><ul><li>estimator</li><li>threshold</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> SelectFromModelRFC_ <span class="token operator">=</span> RFC<span class="token punctuation">(</span>n_estimators <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>X_embedded <span class="token operator">=</span> SelectFromModel<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span> threshold<span class="token operator">=</span><span class="token number">0.005</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>X_embedded<span class="token punctuation">.</span>shape<span class="token comment"># 对于用780个特征来说 每个特征的平均重要性是 1 / 780</span><span class="token comment"># 选取threshold 可以使用学习曲线</span>threshold <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>RFC_<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span>feature_importances_<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>score <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> threshold<span class="token punctuation">:</span>    X_embedded <span class="token operator">=</span> SelectFromModel<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span> threshold<span class="token operator">=</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>    once <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span> X_embedded<span class="token punctuation">,</span> y<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>    score<span class="token punctuation">.</span>append<span class="token punctuation">(</span>once<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>threshold<span class="token punctuation">,</span> score<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="包装法Wrapper"><a href="#包装法Wrapper" class="headerlink" title="包装法Wrapper"></a>包装法Wrapper</h4><p>也是一个特征选择和算法训练同时进行的方法，与嵌入法十分相似，它也是依赖于算法自身的选择，coef_属性或feature_importances_属性来完成特征选择。但不同的是，我们往往使用一个目标函数作为黑盒来帮助我们选取特征，而不是自己输入某个评估指标或者统计量的阈值。包装法需要的计算成本位于嵌入法和过滤法中间。最典型的目标函数是递归特征消除法RFE。是一种贪婪的优化算法，旨在找到性能最佳的特征子集。它反复创建模型，并在每次迭代时保留最佳特征或剔除最差特征，下次迭代会使用上一次建模中没有被选中的特征来构建下一个模型，直到所有特征都耗尽为止。然后 根据自己保留 或者剔除特征的顺序来对特征进行排名，最终选出一个最佳子集。</p><p><strong>包装法的效果是所有特征选择方法中最利于提升模型表现的，它可以使用很少的特征达到很优秀的效果。</strong></p><ul><li>n_features_to_select 是想要选择的特征个数</li><li>step 是每次迭代中希望移除的特征个数</li></ul><p>sklearn.feature_selection.RFE 中有两个很重要的属性，support_ 返回所有的特征最后是否被选中的布尔矩阵，以及ranking_ 返回特征的按数次迭代中综合重要性的排名。</p><p>类feature_selection.RFECV会在交叉验证循环中执行RFE以找到最佳数量的特征，增加参数cv，其他用法都和RFE一模一样</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> RFERFC_ <span class="token operator">=</span> RFC<span class="token punctuation">(</span>n_estimators <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>selector <span class="token operator">=</span> RFE<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span> n_features_to_select <span class="token operator">=</span> <span class="token number">340</span><span class="token punctuation">,</span> step <span class="token operator">=</span> <span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>selector<span class="token punctuation">.</span>support_<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 因为support是布尔值，sum就是选取特征的个数</span>selector<span class="token punctuation">.</span>ranking_X_wrapper <span class="token operator">=</span> selector<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>cross_val_score<span class="token punctuation">(</span>RFC_<span class="token punctuation">,</span> X_wrapper<span class="token punctuation">,</span> y<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h3><p>PCA是一种降维的算法，降维的目的是为了让算法运算更快，效果更好；也可以进行数据可视化</p><p>sklearn中降维算法都被包括在模块decomposition中，这个模块本质是一个矩阵分解模块</p><ul><li>decomposition.PCA</li><li>decomposition.LatentDirichletAllocation 具有在线变分贝叶斯算法的隐含狄利克雷分布</li></ul><p>之前的方差过滤中就能直到 对于某个特征，其大量取值都相同，那么这一个特征的取值就对样本没有区分度，这种特征就不带有有效信息。从此可以想到，如果一个特征的方差很大，则这个特征很可能带有有大量的信息。在PCA中，<strong>PCA使用的信息量衡量指标就是样本方差。</strong></p><script type="math/tex; mode=display">Var = \frac{1}{n - 1}\sum_{i = 1}^n(x_i - \hat{x})^2</script><p>其中$x_i$代表一个特征中的每个样本取值，$\hat{x}$代表这一列样本的均值</p><p>PCA和SVD是两种不同的降维算法，他们对于信息量的衡量指标不同，PCA使用方差作为信息量的衡量指标，通过特征分解来找出空间V。而SVD使用奇异值分解来找V</p><p><strong>与之前的特征工程相比，PCA降维完毕后的特征不是原本的特征矩阵中的任何一个特征，而是通过某些方式组合起来的新特征。新特征矩阵生成之后 不具有可读性</strong>，我们无法知晓PCA都建立了怎样的新特征向量，新特征矩阵生成之后也不具有可读性，我们无法判断新特征矩阵的特征是从原数据中的什么特征组合而来，新特征虽然带有原始数据的信息，却已经不是原数据上代表着的含义了。PCA可以算是特征创造</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 用PCA 对iris数据集进行可视化</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCAdataset <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>dataset<span class="token punctuation">.</span>data<span class="token punctuation">.</span>shape <span class="token comment"># 返回的值为(150, 4)</span>pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>X <span class="token operator">=</span> pca<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>data<span class="token punctuation">)</span>y <span class="token operator">=</span> dataset<span class="token punctuation">.</span>targetX<span class="token punctuation">.</span>shape <span class="token comment"># 返回的值为(150, 2)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span>y <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span>y <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  c<span class="token operator">=</span><span class="token string">"red"</span><span class="token punctuation">,</span> label <span class="token operator">=</span> dataset<span class="token punctuation">.</span>target_names<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> alpha <span class="token operator">=</span> <span class="token number">.7</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span>y <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span>y <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  c<span class="token operator">=</span><span class="token string">"black"</span><span class="token punctuation">,</span> label <span class="token operator">=</span> dataset<span class="token punctuation">.</span>target_names<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> alpha <span class="token operator">=</span> <span class="token number">.7</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span>y <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span>y <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  c<span class="token operator">=</span><span class="token string">"orange"</span><span class="token punctuation">,</span> label <span class="token operator">=</span> dataset<span class="token punctuation">.</span>target_names<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> alpha <span class="token operator">=</span> <span class="token number">.7</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://z3.ax1x.com/2021/10/01/4TIl9J.png" alt="4TIl9J.png"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># explained_variance 降维后每个新特征向量上所带的信息量的大小</span>pca<span class="token punctuation">.</span>explained_variance_<span class="token comment"># expained_variance_ratio_ 查看降维后每个新特征向量所占信息量占原始数据总信息量的百分比</span>pca<span class="token punctuation">.</span>explained_variance_ratio_pca<span class="token punctuation">.</span>explained_variance_ratio_<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 就可以查看信息保留的程度</span><span class="token comment">#可以把k作为横坐标pca.explained_variance_ratio_.sum()作为纵坐标来选取最好的k</span>pca_line <span class="token operator">=</span> PCA<span class="token punctuation">(</span><span class="token punctuation">)</span>_fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>np<span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span>pca_line<span class="token punctuation">.</span>explained_variance_ratio_<span class="token punctuation">)</span><span class="token comment"># 选n_components 还可以有mle参数 让PCA用最大似然估计自选超参数n_components</span><span class="token comment"># n_components 还可以输入[0, 1]的浮点数 表示希望降维后的总解释性方差占比要大于的值，必须要写上另一个参数svd_solver='full'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>PCA中的SVD</strong></p><script type="math/tex; mode=display">X  = U\Sigma V^T \\X_{dr} = X * V[:k]</script><p>k就是n_components 是降维后希望得到的维度。若X为(m, n)的特征矩阵 那么$V^T$ 就是(n,n)的矩阵，取这个矩阵的前k行，将$V$转换为结构为(k, n)的矩阵 会保存在components_当中</p><p>奇异值分解可以不计算协方差矩阵等等结构复杂计算冗长的矩阵，就直接求出新特征空间和降维后的特征矩阵，但是SVD中的衡量指标奇异值 远不如 方差容易理解，所以</p><p>sklearn 将降维流程拆分成了两部分：一部分是计算特征空间V，由奇异值分解完成，另一部分是映射数据和求解新特征矩阵，由主成分分析完成，实现了用SVD的性质减少计算量，让信息量的评估指标是方差</p><p>参数svd_solver是在降维过程中，用来控制矩阵分解的一些细节的参数</p><ul><li><p>full 从scipy.linalg.svd 中调用标准为LAPACK分解器来生成精确完整的SVD</p></li><li><p>arpack 从scipy.sparse.linalg.svds调用ARPACK分解其来运行截断奇异值分解，分解时就将特征数量降到n_components中输入的数值k，<strong>可以加快运算速度，适合特征矩阵很大的时候，但一般用于特征矩阵为稀疏矩阵的情况，此过程包含一定的随机性</strong></p></li><li><p>randomized 分解器会先生成多个随机向量，然后去检测这些随机向量中是否有任何一个符合我们的分解需求，如果符合，就保留这个随机向量；并基于这个随机向量来构建后续的向量空间，适合特征矩阵特别大，计算量庞大的时候</p><p><strong>Halko    Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decomposition</strong></p></li><li><p>auto 数据小的时候full，数据大的时候选randomized；咱们一般选这个</p></li></ul><h3 id="components-的使用"><a href="#components-的使用" class="headerlink" title="components_ 的使用"></a>components_ 的使用</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> fetch_lfw_people <span class="token comment"># 这个数据集是7个人的人脸，1000多张图</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npfaces <span class="token operator">=</span> fetch_lfw_people<span class="token punctuation">(</span>min_faces_per_person <span class="token operator">=</span> <span class="token number">60</span><span class="token punctuation">)</span>faces<span class="token punctuation">.</span>image<span class="token punctuation">.</span>shape <span class="token comment"># 1277, 62, 47</span>X <span class="token operator">=</span> faces<span class="token punctuation">.</span>data <span class="token comment"># 是 1277，62*47</span><span class="token comment"># 画出来</span>fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> figsize <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> subplot_kw <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'xtikcs'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'yticks'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token comment"># fig是整张图 axes是每个子图组成的4*5的列表</span><span class="token punctuation">[</span><span class="token operator">*</span>axes<span class="token punctuation">.</span>flat<span class="token punctuation">]</span><span class="token keyword">for</span> i<span class="token punctuation">,</span> ax <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>axes<span class="token punctuation">.</span>flat<span class="token punctuation">)</span><span class="token punctuation">:</span>    ax<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>faces<span class="token punctuation">.</span>images<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cmap <span class="token operator">=</span> <span class="token string">'gray'</span><span class="token punctuation">)</span>pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span><span class="token number">150</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>X_dr <span class="token operator">=</span> pca<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>V <span class="token operator">=</span> pca<span class="token punctuation">.</span>components_<span class="token comment"># 可视化V</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>inverse_transform</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X_inverse <span class="token operator">=</span> pca<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>X_dr<span class="token punctuation">)</span> <span class="token comment">#降维不是完全可逆的</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>人为给load_digits添加噪音</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> nprng <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>RandomState<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>noisy <span class="token operator">=</span> rng<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>digits<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token comment"># 去噪</span>pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> svd_solver <span class="token operator">=</span> <span class="token string">"full"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>noisy<span class="token punctuation">)</span>X_dr <span class="token operator">=</span> pca<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>noisy<span class="token punctuation">)</span>X_dr<span class="token punctuation">.</span>shape <span class="token comment"># 1797, 6</span>without_noise <span class="token operator">=</span> pca<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>X_dr<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>针对MNIST手写数据集，画累计方差贡献率曲线，找最佳降维后维度的范围</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">pca_line <span class="token operator">=</span> PCA<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token comment"># 相当于PCA全部</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span>pca_line<span class="token punctuation">.</span>explained_variance_ratio_<span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"number of components after dimension reduction"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"cumulative explained variance"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 发现100前面方差贡献率增加的很快</span>score <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    X_dir <span class="token operator">=</span> PCA<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>    once <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>RFC<span class="token punctuation">(</span>n_estimators <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X_dr<span class="token punctuation">,</span> y<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>    score<span class="token punctuation">.</span>append<span class="token punctuation">(</span>once<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> score<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 找到准确增长 速度变慢的区间</span>score <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    X_dr <span class="token operator">=</span> PCA<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>    once <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>RFC<span class="token punctuation">(</span>n_estimators <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X_dr<span class="token punctuation">,</span> y<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>    score<span class="token punctuation">.</span>append<span class="token punctuation">(</span>once<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">)</span><span class="token punctuation">,</span> score<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>X_dr <span class="token operator">=</span> PCA<span class="token punctuation">(</span><span class="token number">21</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>X_dr<span class="token punctuation">.</span>shape  <span class="token comment"># (42000, 21)</span>cross_val_score<span class="token punctuation">(</span>RFC<span class="token punctuation">(</span>n_estimators <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X_dr<span class="token punctuation">,</span> y<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 0.917</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier <span class="token keyword">as</span> KNNcross_val_score<span class="token punctuation">(</span>KNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X_dr<span class="token punctuation">,</span> y<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#0.9676</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>sklearn非常有名，感觉看这个视频 学这些东西 会对学sklearn有帮助</p><p>但是感觉这里面的东西比较难落地 学得就有点难受</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> sklearn </tag>
            
            <tag> 菜菜 </tag>
            
            <tag> 数据预处理 </tag>
            
            <tag> PCA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习框架pytorch入门与实践 七章</title>
      <link href="2021/10/13/ch7/"/>
      <url>2021/10/13/ch7/</url>
      
        <content type="html"><![CDATA[<p><strong>这是深度学习框架pytorch入门与实践的第七章的内容</strong></p><p>首先看了一眼main.py 的代码，和猫狗数据集相比，这个代码把config.py放到了main.py中，也不单独一个utils的目录，直接把visualize.py的文件拿出来</p><p>来来来，是时候读一波经典论文了</p><h3 id="Generative-Adversarial-Nets"><a href="#Generative-Adversarial-Nets" class="headerlink" title="Generative Adversarial Nets"></a>Generative Adversarial Nets</h3><p><a href="https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf">论文链接</a></p><p><a href="https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py">github上面 pytorch复现GAN的代码</a></p><p>用代码来帮助阅读论文</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 这个代码完全不复杂 重要的两个components Generator 和 Discriminator</span><span class="token keyword">class</span> <span class="token class-name">Generator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 这个block是函数中的函数</span>        <span class="token keyword">def</span> <span class="token function">block</span><span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            layers <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>                <span class="token comment"># 代码这里有问题，这里的0.8不会是eps，而是momentum，应该改成momentum = 0.8</span>                layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>out_feat<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># momentum默认值是0.1</span>            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> layers<span class="token comment"># 把一个很长的网络用block进行分组，使得代码量变少</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            <span class="token comment"># 输入层不加BN层，所以normalize的值为True</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token comment"># 最后的tanh 会输出范围是[-1, 1]的值</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>        img <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>z<span class="token punctuation">)</span>        <span class="token comment"># 会将nums, features 变成 nums, channels, width, height</span>        img <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">*</span>img_shape<span class="token punctuation">)</span>        <span class="token keyword">return</span> img<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>上面这个Generator的作用就是将一个opt.latent_dim的向量变成一张图片</strong></p><p>在block函数里面出现的BatchNorm1d，是BN层 </p><p>关于 BN层的知识  <a href="https://blog.csdn.net/qq_25737169/article/details/79048516">推荐链接</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># img_flag 就是将图片拉平成向量</span>        img_flat <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        validity <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>img_flat<span class="token punctuation">)</span>        <span class="token keyword">return</span> validity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>这边的discriminator 就是输入一张图片 然后判断这个图片是真实的还是假的，最后输出的是一个概率 用nn.Sigmoid 没有毛病</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Loss function</span>adversarial_loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># Sigmoid 配套 BCELoss</span><span class="token comment"># Initialize generator and discriminator</span>generator <span class="token operator">=</span> Generator<span class="token punctuation">(</span><span class="token punctuation">)</span>discriminator <span class="token operator">=</span> Discriminator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> cuda<span class="token punctuation">:</span>    generator<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    discriminator<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    adversarial_loss<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># Configure data loader</span>os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">"../../data/mnist"</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>    datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>        <span class="token string">"../../data/mnist"</span><span class="token punctuation">,</span>        train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>        transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>            <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>img_size<span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span><span class="token punctuation">,</span>    batch_size<span class="token operator">=</span>opt<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span>    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token comment"># Optimizers</span>optimizer_G <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>generator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span>optimizer_D <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>discriminator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># opt.b1 为0.5 loss一开始就会比较低</span><span class="token comment"># 我感觉实例化Adam的时候 optimizer_D 应该只更新discriminator 而optimizer_G 应该只更新generator</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor</code></p><p>代码定义这个Tensor 来将数据从cpu 转到 GPU</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.2</span><span class="token punctuation">,</span> <span class="token number">1.3</span><span class="token punctuation">,</span> <span class="token number">2.1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cuda:0</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span> <span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cpu</span>c <span class="token operator">=</span> b<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cuda:0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>下面是训练的部分</strong></p><p>这个代码并没有使用 model.train 或者 model.eval</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>imgs<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># Adversarial ground truths</span>        <span class="token comment"># valid 就是全1的标签</span>        valid <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        <span class="token comment"># fake 就是全0的标签</span>        fake <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        <span class="token comment"># Configure input</span>        real_imgs <span class="token operator">=</span> Variable<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># -----------------</span>        <span class="token comment">#  Train Generator</span>        <span class="token comment"># -----------------</span>        optimizer_G<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># Sample noise as generator input</span>        z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># Generate a batch of images</span>        gen_imgs <span class="token operator">=</span> generator<span class="token punctuation">(</span>z<span class="token punctuation">)</span>        <span class="token comment"># Loss measures generator's ability to fool the discriminator</span>        g_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span>        g_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer_G<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># ---------------------</span>        <span class="token comment">#  Train Discriminator</span>        <span class="token comment"># ---------------------</span>        optimizer_D<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># Measure discriminator's ability to classify real from generated samples</span>        real_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span> <span class="token comment"># 区分正确的例子</span>        fake_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fake<span class="token punctuation">)</span> <span class="token comment"># 区分错误的例子</span>        <span class="token comment"># 为什么fake_loss 这里要detach啊</span>        <span class="token comment"># 感觉是要不影响gen_imgs 这边的梯度吧</span>        <span class="token comment"># 同时训练两个网络的代码 还是第一次见</span>        d_loss <span class="token operator">=</span> <span class="token punctuation">(</span>real_loss <span class="token operator">+</span> fake_loss<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>        d_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer_D<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        batches_done <span class="token operator">=</span> epoch <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span> <span class="token operator">+</span> i        <span class="token keyword">if</span> batches_done <span class="token operator">%</span> opt<span class="token punctuation">.</span>sample_interval <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            save_image<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"images/%d.png"</span> <span class="token operator">%</span> batches_done<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我在代码每个epoch之后 print了generator的loss和discriminator的loss 发现loss并不是会缩小的0的， 感觉是位置在一个范围内变化的， 但是生成的结果却是非常不错，有点看不懂loss，下次运行试着用一个epoch的平均loss来，运行了200个epoch</p><p>[Epoch 199/200] [D loss: 0.414886] [G loss: 1.490868]  <strong>generator的loss要高于discriminator的loss</strong></p><p><strong>对于torchvision.utils.save_image的理解</strong></p><p>下面是输出的图像的结果</p><center>    <img src="https://z3.ax1x.com/2021/10/03/4qbgc8.png" width="23%"/>    <img src="https://z3.ax1x.com/2021/10/03/4qb69P.png" width="23%"/>    <img src="https://z3.ax1x.com/2021/10/03/4qbc1f.png" width="23%"/>    <img src="https://z3.ax1x.com/2021/10/03/4qbrtI.png" width="23%"/></center><br/><center>    <img src="https://z3.ax1x.com/2021/10/03/4qbsht.png" width="23%"/>    <img src="https://z3.ax1x.com/2021/10/03/4qbfBQ.png" width="23%"/>    <img src="https://z3.ax1x.com/2021/10/03/4qbWng.png" width="23%"/>    <img src="https://z3.ax1x.com/2021/10/03/4qb2jS.png" width="23%"/></center><br/><center>    <img src="https://z3.ax1x.com/2021/10/03/4qbh7j.png" width="23%"/>    <img src="https://z3.ax1x.com/2021/10/03/4qbINn.png" width="23%"/>    <img src="https://z3.ax1x.com/2021/10/03/4qbohq.png" width="23%"/>    <img src="https://z3.ax1x.com/2021/10/03/4qb790.png" width="23%"/></center><p><br/></p><center>    <img src="https://z3.ax1x.com/2021/10/03/4qbqjU.png" width="23%"/>    <img src="https://z3.ax1x.com/2021/10/03/4qbOuF.png" width="23%"/>    <img src="https://z3.ax1x.com/2021/10/03/4qbXB4.png" width="23%"/>    <img src="https://z3.ax1x.com/2021/10/03/4qbjHJ.png" width="23%"/></center><p>其实训练到30000个batch的时候 图像就比较逼真了</p><p>每个数字所占的比例有明显差别 其中1的数目是最多的， 输出的数字类型是不可控的。</p><p>下面的这张图 蓝色线是generator的loss曲线，看了<a href="https://github.com/znxlwm/pytorch-generative-model-collections">链接</a> 感觉别人跑的GAN， 其中的generator loss的确是在增加</p><p><img src="https://z3.ax1x.com/2021/10/03/4LU1lF.jpg" alt="4LU1lF.jpg"></p><p>这个loss有点奇怪，可能是超参数的问题，b1=0.5, b2=0.999, batch_size=64, channels=1, img_size=28, latent_dim=100, lr=0.0002, n_cpu=8, n_epochs=600, sample_interval=2000 上面是我的超参数，由于不知道正确的GAN的loss函数应该长什么样子，所以也不好说</p><p><img src="https://z3.ax1x.com/2021/10/03/4LUUFx.png" alt="4LUUFx.png"></p><p>上面这张图是最后的显示结果，感觉效果还是可以的 不过就是1的个数太多了点。。。</p><p>理想状态是discriminator的输出是0.5，那么0.5和1的BCELoss就应该是0.69，我之前用了个AverageValueMeter 我在optimizer 和 backward 之间用了 gmeter.add(loss.item())， 换下顺序再试试， 并且加上</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 这个previous_loss的初始化 一定要放在for epoch 的前面！！！</span>reserve <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">if</span> epoch <span class="token operator">></span> <span class="token number">100</span> <span class="token operator">+</span> reserve <span class="token keyword">and</span> gmeter<span class="token punctuation">.</span>value<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> previous_loss<span class="token punctuation">:</span>    reserve <span class="token operator">+=</span> <span class="token number">5</span>    lr <span class="token operator">=</span> lr <span class="token operator">*</span> <span class="token number">0.95</span>    <span class="token keyword">for</span> param_group <span class="token keyword">in</span> optimizer_G<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>        param_group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span> <span class="token operator">=</span> lrprvious_loss <span class="token operator">=</span> gmeter<span class="token punctuation">.</span>value<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>好像没啥效果，再给Adam加上weight_decay 5e-4</p><p><strong>PS 我发现设不设置Adam的betas属性 generator的初始loss会非常不一样</strong></p><p>batch_size 64 epoch 1500 weight_decay 5e-4 再加上控制learning rate</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 这个previous_loss的初始化 一定要放在for epoch 的前面！！！</span>reserve <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">if</span> epoch <span class="token operator">></span> <span class="token number">80</span> <span class="token operator">+</span> reserve <span class="token keyword">and</span> gmeter<span class="token punctuation">.</span>value<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> previous_loss<span class="token punctuation">:</span>    reserve <span class="token operator">+=</span> <span class="token number">10</span>    lr <span class="token operator">=</span> lr <span class="token operator">*</span> <span class="token number">0.97</span>    <span class="token keyword">for</span> param_group <span class="token keyword">in</span> optimizer_G<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>        param_group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span> <span class="token operator">=</span> lr    <span class="token keyword">for</span> param_group <span class="token keyword">in</span> optimizer_D<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>        param_group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span> <span class="token operator">=</span> lrprvious_loss <span class="token operator">=</span> gmeter<span class="token punctuation">.</span>value<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://z3.ax1x.com/2021/10/04/4OEJW6.jpg" alt="4OEJW6.jpg"></p><p>loss很好看，但是生成的图片效果不好  = = 这个我好像没有给Adam设置0.5的beta1</p><p><img src="https://z3.ax1x.com/2021/10/04/4OEaOe.png" alt="4OEaOe.png"></p><h3 id="Conditional-Generative-Adversarial-Nets"><a href="#Conditional-Generative-Adversarial-Nets" class="headerlink" title="Conditional Generative Adversarial Nets"></a>Conditional Generative Adversarial Nets</h3><p><a href="https://arxiv.org/pdf/1411.1784.pdf">论文链接</a></p><p>看了这篇文章，真心觉得这篇文章的文笔不咋滴。这篇文章只有两个作者 也是有点神奇的。</p><p>这篇文章里面用的maxout 和 momentum 感觉已经过时了</p><p><a href="https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/cgan/cgan.py">代码链接</a></p><p>论文中关于cGAN用于MNIST数据集时的一些超参数设置：</p><ul><li>batch_size 100</li><li>初始learning rate 0.1 指数级递减到0.000001 递减参数为1.00004</li><li>momentum 从0.5 到 0.7</li><li>generator 和 discriminator 都有概率为0.5的dropout</li><li>这个结果相对于文中提及的其他模型 效果并不是很好</li></ul><p>Generator里面和GAN代码里面的Generator基本相同，多了一个nn.Embedding，在 forward方法里面会把用nn.Embedding 转换完的label和 输入拼在一起 喂给Generator</p><p><strong>代码中cgan和gan的参数区别</strong> </p><ul><li>img_size的大小不一样</li><li>Discriminator结构不一样</li><li>loss的种类不一样，cgan是MSELoss，gan是BCELoss</li></ul><p><code>nn.Embedding</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token builtin">list</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 里面的Parameter 是一个10 x 10的tensor 里面的requires_grad 为 True</span><span class="token comment"># 如果x(torch.tensor([1])) 返回的就是10 x 10 tensor中的第2行的10个数</span><span class="token comment"># 感觉requires_grad 为True的话 就是可以参加梯度计算的啊</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>感觉训练了20多个epoch 就有效果了，像这种 我就不知道输出是否和训练集中某个图片是一样的，有些数字效果和不怎么好，我用默认的设置进行训练，下面是训练的loss</p><p><img src="https://z3.ax1x.com/2021/10/13/5ufJ7F.jpg" alt="5ufJ7F.jpg"></p><p>然后是20 40 60 80 final epoch的训练结果</p><p><img src="https://z3.ax1x.com/2021/10/13/5uhPN4.png" alt="5uhPN4.png"></p><p><img src="https://z3.ax1x.com/2021/10/13/5uhkC9.png" alt="5uhkC9.png"></p><p><img src="https://z3.ax1x.com/2021/10/13/5uhi4J.png" alt="5uhi4J.png"></p><p><img src="https://z3.ax1x.com/2021/10/13/5uhEg1.png" alt="5uhEg1.png"></p><p><img src="https://z3.ax1x.com/2021/10/13/5uhA3R.png" alt="5uhA3R.png"></p><p><img src="https://z3.ax1x.com/2021/10/13/5uhVjx.png" alt="5uhVjx.png"></p><p>gan的loss看不懂啊</p><p>有一个比较迷的地方 那就是D和G 都有一个nn.Embedding 而这个Embedding 两边是不一样的 初始值不一样，也就是说一开始0到9在两个网络中embedding的值是不一样的，这也能训练成功，说明embedding还要研究研究，贼奇怪的是两边的forward concat的顺序不一样，在G中是先标签，在D中式后标签，但是这个运行对了 奇怪！！！！！！</p><p>我把D中也改成先标签 训练loss 第一个epoch 0.57 0.13</p><p>还是能达到想要的结果 amazing！！！</p><p>100维 拼上10维的表数字的 拼接顺序不影响  把100维变成200维 也是可以的</p><p>10维占比 0.05，200维的loss图的形状和100维的一样</p><p><strong>Q 如果我不用embedding 成10维 而是讲标签 / 10 贴到向量中 也就是100维变成101维</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>latent_dim <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> noise<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># Concatenate label embedding and image to produce input</span>        gen_input <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>labels <span class="token operator">/</span> <span class="token number">10.0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> noise<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        img <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>gen_input<span class="token punctuation">)</span>        img <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">*</span>img_shape<span class="token punctuation">)</span>        <span class="token keyword">return</span> img<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>没有condition的效果了 猜想如果原来的代码 将latent_dim设为1000可能也没有condition了</p><p>1000层学到了 奇了怪了 改10000层试一试 10000层是可以的</p><p>猜想因为feature 部分有10个神经元 将其看作一个整体 这就是一个大神经元</p><p>我就想不用labels / 10 而是用labels 看看效果</p><p>实验效果比之前的好，但是还是没有达到预期</p><p><img src="https://z3.ax1x.com/2021/10/13/5M0YY6.png" alt="5M0YY6.png"></p><p><strong>试一下one-hot的把</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 下面的代码是将label转化成one-hot编码</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>random_<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">10</span>y_onehot <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>y_onehot<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>y_onehot<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>onehot结果是ok的 论文里面原来用的也是onehot</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> pytorch </tag>
            
            <tag> GAN </tag>
            
            <tag> CGAN </tag>
            
            <tag> MNIST </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>random forest</title>
      <link href="2021/10/08/random%20forest/"/>
      <url>2021/10/08/random%20forest/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.bilibili.com/video/BV1MA411J7wm?p=17">视频链接</a></p><h3 id="集成算法概述"><a href="#集成算法概述" class="headerlink" title="集成算法概述"></a>集成算法概述</h3><p>随机森林是集成算法中容易入门的</p><p>多个模型集成成为的模型叫做集成评估器 ensemble estimator，组成集成评估器的每个模型都叫做基评估器 base estimator。通常来说  有Bagging，Boosting，Stacking</p><p>Bagging的核心思想是构建多个相互独立的评估器，然后对其预测取平均或者多数表决来决定最终结果</p><p>Boosting中，基评估器是相关的，是按顺序一一构建的。核心思想是结合弱评估器的力量一次次对难以评估的样本进行预测，从而构成一个强评估器，比如对于第一个分类器中分类错误的样本，提高这些样本的权重让第二个分类器进行分类</p><h3 id="RandomForestClassifier"><a href="#RandomForestClassifier" class="headerlink" title="RandomForestClassifier"></a>RandomForestClassifier</h3><p>它的所有基评估器都是决策树</p><p>所在的库 from  sklearn.ensemble import RandomForestClassifier</p><p><strong>n_estimators </strong></p><p>是森林中树木的数量，即基评估器的数量。这个参数对随机森林模型的精确性影响是单调的，n_estimators越大，模型的效果往往越好，n_estimator达到一定程度之后，随着其增大，模型的精确性往往不在上升或开始波动，并且n_estimators越大，需要的计算量和内存也越大，训练的时间也越长，在0.22版本默认值是100</p><p><strong>示例 ： </strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifier<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> cross_val_score<span class="token punctuation">,</span> train_test_split<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_winedtc <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>random_state <span class="token operator">=</span> <span class="token number">25</span><span class="token punctuation">)</span>dtc2 <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>criterion <span class="token operator">=</span> <span class="token string">'entropy'</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">27</span><span class="token punctuation">)</span>rfc <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>random_state <span class="token operator">=</span> <span class="token number">25</span><span class="token punctuation">)</span>wine <span class="token operator">=</span> load_wine<span class="token punctuation">(</span><span class="token punctuation">)</span>Xtrain<span class="token punctuation">,</span> Xtest<span class="token punctuation">,</span> Ytrain<span class="token punctuation">,</span> Ytest <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>wine<span class="token punctuation">.</span>data<span class="token punctuation">,</span> wine<span class="token punctuation">.</span>target<span class="token punctuation">,</span> test_size <span class="token operator">=</span> <span class="token number">0.3</span><span class="token punctuation">)</span>dtc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>Xtrain<span class="token punctuation">,</span> Ytrain<span class="token punctuation">)</span>dtc<span class="token punctuation">.</span>score<span class="token punctuation">(</span>Xtest<span class="token punctuation">,</span> Ytest<span class="token punctuation">)</span><span class="token comment"># 打印的值为0.85185</span>dtc2<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>Xtrain<span class="token punctuation">,</span> Ytrain<span class="token punctuation">)</span>dtc2<span class="token punctuation">.</span>score<span class="token punctuation">(</span>Xtest<span class="token punctuation">,</span> Ytest<span class="token punctuation">)</span><span class="token comment"># 打印的值为0.98148</span>rfc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>Xtrain<span class="token punctuation">,</span> Ytrain<span class="token punctuation">)</span>rfc<span class="token punctuation">.</span>score<span class="token punctuation">(</span>Xtest<span class="token punctuation">,</span> Ytest<span class="token punctuation">)</span><span class="token comment"># 打印的值为 1.0   unbelievable</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="下面比较一下dtc-和-rfc-两个分类器的"><a href="#下面比较一下dtc-和-rfc-两个分类器的" class="headerlink" title="下面比较一下dtc 和 rfc 两个分类器的"></a>下面比较一下dtc 和 rfc 两个分类器的</h5><p>用cross_val_score，10次输出用dtc和rfc进行比较，这么做的原因是为了减小训练集和测试集的划分对两者性能比较的影响</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">rfc_s <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>rfc<span class="token punctuation">,</span> wine<span class="token punctuation">.</span>data<span class="token punctuation">,</span> wine<span class="token punctuation">.</span>target<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span>dtc_s <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>dtc<span class="token punctuation">,</span> wine<span class="token punctuation">.</span>data<span class="token punctuation">,</span> wine<span class="token punctuation">.</span>target<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">,</span> rfc_s<span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">"Random Forest"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtc_s<span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">"Decision Tree"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://z3.ax1x.com/2021/09/18/4QYzI1.png" alt="4QYzI1.png"></p><p>由上图可见，随机森林的效果要比决策树要好</p><h5 id="下面不设置random-state-来看-两个分类器性能的差异"><a href="#下面不设置random-state-来看-两个分类器性能的差异" class="headerlink" title="下面不设置random_state 来看 两个分类器性能的差异"></a>下面不设置random_state 来看 两个分类器性能的差异</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python">rfc_l <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>clf_l <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    rfc <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>n_estimators <span class="token operator">=</span> <span class="token number">25</span><span class="token punctuation">)</span>    rfc_s <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>rfc<span class="token punctuation">,</span> wine<span class="token punctuation">.</span>data<span class="token punctuation">,</span> wine<span class="token punctuation">.</span>target<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>    rfc_l<span class="token punctuation">.</span>append<span class="token punctuation">(</span>rfc_s<span class="token punctuation">)</span>    clf <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>    clf_s <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>clf<span class="token punctuation">,</span> wine<span class="token punctuation">.</span>data<span class="token punctuation">,</span> wine<span class="token punctuation">.</span>target<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>    clf_l<span class="token punctuation">.</span>append<span class="token punctuation">(</span>clf_s<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">,</span> rfc_l<span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">'Random Forest'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">,</span> clf_l<span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">'Decision Tree'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://z3.ax1x.com/2021/09/18/4QUAUA.png" alt="4QUAUA.png"></p><h5 id="下面是关于n-estimators的学习曲线"><a href="#下面是关于n-estimators的学习曲线" class="headerlink" title="下面是关于n_estimators的学习曲线"></a>下面是关于n_estimators的学习曲线</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python">content <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    rfc <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>n_estimators <span class="token operator">=</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> n_jobs <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">25</span><span class="token punctuation">)</span>    <span class="token comment"># 这里的参数n_jobs告诉引擎有多少处理器是它可以使用。 “-1”意味着没有限制，而“1”值意味着它只能使用一个处理器。</span>    rfc_s <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>rfc<span class="token punctuation">,</span> wine<span class="token punctuation">.</span>data<span class="token punctuation">,</span> wine<span class="token punctuation">.</span>target<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>    content<span class="token punctuation">.</span>append<span class="token punctuation">(</span>rfc_s<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token punctuation">,</span> content<span class="token punctuation">.</span>index<span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">201</span><span class="token punctuation">)</span><span class="token punctuation">,</span> content<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span><span class="token string">'result4.png'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 打印出来的值是0.983333  24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://z3.ax1x.com/2021/09/18/4QBp0U.png" alt="4QBp0U.png"></p><h5 id="随机森林的Bagging的体现"><a href="#随机森林的Bagging的体现" class="headerlink" title="随机森林的Bagging的体现"></a>随机森林的Bagging的体现</h5><p>在之前的红酒的例子中，我们建立了25棵树，对任何一个样本而言，平均或多数表决原则下，当且仅当有13棵以上的树判断错误的时候，随机森林才会判断错误。单独一棵决策树对红酒数据集的分类准确率在0.85上下浮动，假设一棵树判断错误的可能性为0.2 那么13棵树以上判断错误的可能性：</p><script type="math/tex; mode=display">e_{random\_forest} = \sum_{i = 13}^{25} \binom{25}{i}\epsilon^i(1-\epsilon)^{25 - i} = 0.000369</script><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 这是计算上面式子的代码</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>special <span class="token keyword">import</span> combnp<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>comb<span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">,</span> i<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">0.2</span> <span class="token operator">**</span> i<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> <span class="token number">0.2</span><span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token punctuation">(</span><span class="token number">25</span> <span class="token operator">-</span> i<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 打印出来的值是0.000369   六六六哇</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>RandomForestClassifier 中的random_state控制的是一片森林而非具体的一棵树</p><p>用rfc.estimators_来查看随机森林中的决策树，发现决策树的参数基本相同，唯一不同的是random_state</p><p>type(rfc.estimators_[0]) 返回的值是sklearn.tree.tree.DecisionTreeClassifier</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>rfc<span class="token punctuation">.</span>estimators_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>rfc<span class="token punctuation">.</span>estimators_<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>random_state<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这种很多相同的树 在成千上万棵的时候，数据不一定能够提供成千上万的特征来让我们构筑尽量多尽量不同的树，所以除了random_state 以外 我们还需要其他的随机性</p><p>bagging 是通过有放回的随机抽样技术来形成不同的训练数据，bootstrap就是用来控制抽样技术的参数</p><p><strong>有放回的采样n次，最终得到一个和原始训练集一样大的，n个样本组成的自助集，由于是随机采样，这样每次的自助集和原始数据集不同，和其他的采样集也是不同的，用这些基数据集来训练我们的基分类器，我们的基分类器自然也就各不相同了  boostrap默认为True 代表采用有放回的随机抽样技术</strong></p><p>有放回的抽样有自己的问题， 由于是有放回，一些样本可能在同一个自助集中出现多次，而其他一些可能被忽略，一般来说，自助集大约平均会包含63%的原始数据。<strong>因为每一个样本被抽到某个自助集的概率为</strong></p><script type="math/tex; mode=display">1 - (1 - \frac{1}{n})^n  收敛于 1 - \frac{1}{e} \approx0.632</script><p>假如原始数据有m个，这就是二项分布m, p  期望是m * p，也就是期望p的原始数据会被抽到</p><p>**会有约37%的训练数据被浪费掉 ，没有参与建模，这些数据被称为带外数据 out of bag data 简写为oob</p><p><strong>也就是说，在使用随机森林时，我们可以不划分测试集和训练集，只用袋外数据来测试我们的模型即可</strong></p><p>但是 这也不是绝对的，当n和n_estimators都不够大的是皇后，很可能就没有数据掉落在袋外 </p><p><strong>如果希望用袋外数据来测试，则 需要在实例化时就将oob_score这个参数调整为True</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">rfc <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">,</span> oob_score<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>rfc <span class="token operator">=</span> rfc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>wine<span class="token punctuation">.</span>data<span class="token punctuation">,</span> wine<span class="token punctuation">.</span>target<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>rfc<span class="token punctuation">.</span>oob_score_<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="重要属性和接口"><a href="#重要属性和接口" class="headerlink" title="重要属性和接口"></a>重要属性和接口</h5><p>属性.estimators_ .oob_score_ .feature_importances_</p><p>rfc.apply 返回 每一个样本在每一棵树所在的叶子节点的索引  rfc.predict_proba 返回每个样本在每个类的概率</p><p><strong>bagging的一个必要条件:  基分类器的误差率要小于0.5，也就是准确率要大于百分之50</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npx <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> epsilon <span class="token keyword">in</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    E <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>comb<span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">(</span>epsilon <span class="token operator">**</span> i<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> epsilon<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token punctuation">(</span><span class="token number">25</span> <span class="token operator">-</span> i<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    y<span class="token punctuation">.</span>append<span class="token punctuation">(</span>E<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token string">"o-"</span><span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">"when estimators are different"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> x<span class="token punctuation">,</span> <span class="token string">"--"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> color <span class="token operator">=</span> <span class="token string">"red"</span><span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">"if all estimators are same"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"individual estimator's error"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"RandomForest's error"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://z3.ax1x.com/2021/09/18/4Q2xXj.png" alt="4Q2xXj.png"></p><h3 id="RandomForestRegressor"><a href="#RandomForestRegressor" class="headerlink" title="RandomForestRegressor"></a>RandomForestRegressor</h3><p>sklearn的评分指标 import sklearn  sklearn.metrics</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token builtin">sorted</span><span class="token punctuation">(</span>sklearn<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>SCORERS<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="用随机森林回归来填补缺失值"><a href="#用随机森林回归来填补缺失值" class="headerlink" title="用随机森林回归来填补缺失值"></a>用随机森林回归来填补缺失值</h5><p>在sklearn中 可以使用sklearn.impute.SimpleImputer来填充缺失值，一般会用均值、中值、或者其他常用的数值填补到数据中</p><p><strong>PS 今天使用visdom的时候发现一个错误：ERROR:root:Error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777) while downloading <a href="https://unpkg.com/jquery@3.1.1/dist/jquery.min.js">https://unpkg.com/jquery@3.1.1/dist/jquery.min.js</a></strong></p><p><a href="https://blog.csdn.net/Chen_he_Zhang/article/details/105116273">解决方法</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">numpy<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>low<span class="token punctuation">,</span> high<span class="token punctuation">,</span> nums<span class="token punctuation">)</span> <span class="token comment">#在[low, high) 中随机生成nums个整数</span>missing_samples <span class="token operator">=</span> numpy<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>n_samples<span class="token punctuation">,</span> n_missing_samples<span class="token punctuation">,</span> replace <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment"># 在n_samples中不重复地随机抽取n_missing_samples个数据</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>将红酒数据集中随机50%的内容设置成缺失</strong> 这里的50%不是指的行，而是数字</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dataset <span class="token operator">=</span> load_boston<span class="token punctuation">(</span><span class="token punctuation">)</span>X_full<span class="token punctuation">,</span> Y_full <span class="token operator">=</span> dataset<span class="token punctuation">.</span>data<span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>targetn_samples <span class="token operator">=</span> X_full<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>n_features <span class="token operator">=</span> X_full<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>nums <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>n_samples <span class="token operator">*</span> n_features <span class="token operator">*</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>rng <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>RandomState<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>rows <span class="token operator">=</span> rng<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_samples<span class="token punctuation">,</span> nums<span class="token punctuation">)</span>cols <span class="token operator">=</span> rng<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_features<span class="token punctuation">,</span> nums<span class="token punctuation">)</span>X_missing<span class="token punctuation">,</span> Y_missing <span class="token operator">=</span> X_full<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Y_full<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>X_missing<span class="token punctuation">[</span>rows<span class="token punctuation">,</span> cols<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>nanX_missing <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>X_missing<span class="token punctuation">)</span>X_missing<span class="token comment"># 下面是用Imputer来对缺失值进行填补，一个是用均值来填补，另一个是用0来填补</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>impute <span class="token keyword">import</span> SimpleImputerimp_mean <span class="token operator">=</span> SimpleImputer<span class="token punctuation">(</span>missing_values <span class="token operator">=</span> np<span class="token punctuation">.</span>nan<span class="token punctuation">,</span> strategy <span class="token operator">=</span> <span class="token string">'mean'</span><span class="token punctuation">)</span>X_missing_mean <span class="token operator">=</span> imp_mean<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_missing<span class="token punctuation">)</span>imp_zero <span class="token operator">=</span> SimpleImputer<span class="token punctuation">(</span>missing_values <span class="token operator">=</span> np<span class="token punctuation">.</span>nan<span class="token punctuation">,</span> strategy <span class="token operator">=</span> <span class="token string">'constant'</span><span class="token punctuation">,</span> fill_value <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>X_missing_zero <span class="token operator">=</span> imp_zero<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_missing<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>用回归来填补缺失数据</strong></p><p>其核心思想是 将缺失的列，即要填补的列看作是标签，其余的特征看作是数据，用数据来预测缺失的标签，要填补的列中没有缺失的数据当作是训练集，另外的是测试集；如果有多列都存在缺失，那么依次填补每个列，先填缺失量最小的列，在填充是 将其余列的缺失值填成0  <strong>说实话 感觉这个方法不怎么好</strong></p><p><strong>PS： linux 中  sed -n 是安静模式 这个模式对于p很重要</strong></p><p><strong>pandas 里面 read_csv 的thousands的作用是防止1,000 被读成1 和 000 </strong></p><p>关于read_csv 的na_values的作用 <a href="https://blog.csdn.net/weixin_44520259/article/details/106053987">参考链接</a>  就是设置除了默认的样子以外 缺失值的样子，<code>na_values</code> = “n/a” 就是设置文件里面的”n/a”  代表的就是缺失值</p><p><strong>np.c_</strong>  就是将两个矩阵 按行进行拼接</p><p><strong>pandas.pivot 数据透视表</strong>   关于透视表，根据维基百科的定义，是用来汇总其它表的数据。首先把源表分组（grouping），然后对各组内数据做汇总操作如排序、平均、累加、计数或字符串连接等。<a href="https://zhuanlan.zhihu.com/p/267208129">例子链接</a></p><p><strong>PS: 要使用 sklearn.linear_model.LinearRegression 必须要 import sklearn.linear_model</strong></p><p>使用linear_model里面的LinearRegression 最后计算出来的参数是在model.coef_ 和 model.intercept_ 发现数据越多计算出来的参数越准确</p><p>对于简单的线性回归，除了用sklearn.linear_model 还可以用sklearn.neighbors.KNeighborsRegressor</p><p><strong>linear_model 里面还有Ridge 这个东西</strong></p><p><strong>PS</strong> 用sklearn进行画线的时候，viz.line(X=, Y=) 用这种方式，不要把X，Y给省略掉了；opts参数最好使用dict来写，放大发现viz.line 并非是一条线 而是非常多的点组成</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 关于pandas DataFrame 赋值操作的探索 </span>t1 <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># t1 就是一个3x3的DataFrame</span><span class="token comment"># t1.value就是3x3内容构成的ndarray, t1.index返回的是一个RangeIndex(start=0,stop=3,step=1)</span>t2 <span class="token operator">=</span> t1 <span class="token comment"># 如果用t2 = t1.copy() 就不会被修改</span>t2<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment"># t1 相应位置的数据也会被修改</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 下面的代码就是用随机森林回归来预测值</span>X_missing_reg <span class="token operator">=</span> X_missing<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>sortindex <span class="token operator">=</span> np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>X_missing_reg<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>valuesX_missing_reg<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> sortindex<span class="token punctuation">:</span>    df <span class="token operator">=</span> X_missing_reg<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>    fillc <span class="token operator">=</span> df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span>    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> df<span class="token punctuation">.</span>columns <span class="token operator">!=</span> i<span class="token punctuation">]</span><span class="token punctuation">,</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>Y_full<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># 这里的axis = 1不能省</span>    df_0 <span class="token operator">=</span> SimpleImputer<span class="token punctuation">(</span>missing_values <span class="token operator">=</span> np<span class="token punctuation">.</span>nan<span class="token punctuation">,</span> strategy <span class="token operator">=</span> <span class="token string">'constant'</span><span class="token punctuation">,</span> fill_value <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df<span class="token punctuation">)</span>    Ytrain <span class="token operator">=</span> fillc<span class="token punctuation">[</span>fillc<span class="token punctuation">.</span>notnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    Ytest  <span class="token operator">=</span> fillc<span class="token punctuation">[</span>fillc<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token comment"># 注意下面的索引方式</span>    Xtrain <span class="token operator">=</span> df_0<span class="token punctuation">[</span>Ytrain<span class="token punctuation">.</span>index<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    Xtest  <span class="token operator">=</span> df_0<span class="token punctuation">[</span>Ytest<span class="token punctuation">.</span>index<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>        rfc <span class="token operator">=</span> RandomForestRegressor<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>    rfc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>Xtrain<span class="token punctuation">,</span>Ytrain<span class="token punctuation">)</span>    Ypredict <span class="token operator">=</span> rfc<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>Xtest<span class="token punctuation">)</span>    X_missing_reg<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>X_missing_reg<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> YpredictX_missing_reg<span class="token comment"># 下面是进行测试</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> cross_val_scoreestimator <span class="token operator">=</span> RandomForestRegressor<span class="token punctuation">(</span>random_state <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> n_estimators <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">)</span>cross_val_score<span class="token punctuation">(</span>estimator<span class="token punctuation">,</span> X_missing_reg<span class="token punctuation">,</span> Y_full<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span> scoring<span class="token operator">=</span><span class="token string">'neg_mean_squared_error'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token operator">-</span><span class="token number">1</span><span class="token comment"># 随机森林回归得到的结果比原始数据训练出来的结果要好 一脸懵逼</span>cross_val_score<span class="token punctuation">(</span>estimator<span class="token punctuation">,</span> X_full<span class="token punctuation">,</span> Y_full<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span> scoring<span class="token operator">=</span><span class="token string">'neg_mean_squared_error'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token operator">-</span><span class="token number">1</span>cross_val_score<span class="token punctuation">(</span>estimator<span class="token punctuation">,</span> X_missing_zero<span class="token punctuation">,</span> Y_full<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span> scoring<span class="token operator">=</span><span class="token string">'neg_mean_squared_error'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token operator">-</span><span class="token number">1</span>cross_val_score<span class="token punctuation">(</span>estimator<span class="token punctuation">,</span> X_missing_mean<span class="token punctuation">,</span> Y_full<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span> scoring<span class="token operator">=</span><span class="token string">'neg_mean_squared_error'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token operator">-</span><span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我把缺失数据的比例从0.1 提升到 0.6</p><p>0.1 20.04837391426907 21.571667100368845 28.066649508250816 23.13211544581634</p><p>0.2 21.536820211842358 21.571667100368845 33.45558822704329 26.129517675402816</p><p>0.3 18.24671883651717 21.571667100368845 37.74378466449233 26.406473861638517</p><p>0.4 21.825224720442627 21.571667100368845 34.488255374005035 29.656734659037067</p><p>0.5 15.90757391170646 21.571667100368845 40.857401498854585 42.81797538114929</p><p>0.6 15.015489382488838 21.571667100368845 41.381264106891855 34.721690688817695</p><h3 id="机器学习中调参的基本思想"><a href="#机器学习中调参的基本思想" class="headerlink" title="机器学习中调参的基本思想"></a>机器学习中调参的基本思想</h3><p><img src="https://z3.ax1x.com/2021/09/21/4YXSt1.png" alt="4YXSt1.png"></p><p>模型太复杂，模型就会过拟合，模型太简单，就会欠拟合</p><p>很多情况树模型位于 上面图的右上角，也有出现在左上角的，调参之前，<strong>要先判断，模型在哪一边</strong></p><p>案例 乳腺癌数据</p><p>数据大小为569, 30，从这个数据个数和特征个数的比 可以看出这个容易过拟合</p><p><code>先调n\_estimators</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 先跑出一个区间， 然后再细化</span>dataset <span class="token operator">=</span> load_breast_cancer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">%</span><span class="token operator">%</span>timescorel <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">302</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    rfc <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>random_state <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> n_estimators <span class="token operator">=</span> i<span class="token punctuation">)</span>    scorel<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cross_val_score<span class="token punctuation">(</span>rfc<span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>data<span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>target<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>scorel<span class="token punctuation">)</span><span class="token punctuation">,</span> scorel<span class="token punctuation">.</span>index<span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>scorel<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">10</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>ax <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">111</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">202</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> scorel<span class="token punctuation">)</span>ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">"number of n_estimators"</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">%</span><span class="token operator">%</span>timescorel2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">121</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    rfc <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>random_state <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> n_estimators <span class="token operator">=</span> i<span class="token punctuation">)</span>    scorel2<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cross_val_score<span class="token punctuation">(</span>rfc<span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>data<span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>target<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>scorel2<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">*</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">121</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">[</span>scorel2<span class="token punctuation">.</span>index<span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>scorel2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>ax <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">111</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">121</span><span class="token punctuation">)</span><span class="token punctuation">,</span> scorel2<span class="token punctuation">)</span>ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">"number of n_estimators"</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> sklearn </tag>
            
            <tag> 菜菜 </tag>
            
            <tag> random forest </tag>
            
            <tag> kaggle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习框架pytorch入门与实践 五六章</title>
      <link href="2021/10/04/ch56/"/>
      <url>2021/10/04/ch56/</url>
      
        <content type="html"><![CDATA[<p>这本书的代码地址  <a href="https://www.github.com/chenyuntc/pytorch-book">链接</a></p><h3 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h3><ul><li><p>高负载的操作放在getitem中，如加载图片</p><p>因为多进程会并行地调用getitem</p></li><li><p>dataset中应尽量包含只读对象</p><p>因为dataloader使用多进程加载</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">BadDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>      self<span class="token punctuation">.</span>num <span class="token operator">=</span> <span class="token number">0</span>      self<span class="token punctuation">.</span>data <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>      self<span class="token punctuation">.</span>num <span class="token operator">+=</span> <span class="token number">1</span>      <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>下面是猫狗数据集 加载的例子</strong></p></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DogCat</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> root<span class="token punctuation">)</span><span class="token punctuation">:</span>      imgs <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>root<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>imgs <span class="token operator">=</span> <span class="token punctuation">[</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root<span class="token punctuation">,</span> img<span class="token punctuation">)</span> <span class="token keyword">for</span> img <span class="token keyword">in</span> imgs<span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>      img_path <span class="token operator">=</span> self<span class="token punctuation">.</span>image<span class="token punctuation">[</span>index<span class="token punctuation">]</span>        label <span class="token operator">=</span> <span class="token number">1</span> <span class="token keyword">if</span> <span class="token string">'dog'</span> <span class="token keyword">in</span> img_path<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">else</span> <span class="token number">0</span>        pil_img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>        array <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>pil_img<span class="token punctuation">)</span>        data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>array<span class="token punctuation">)</span>        <span class="token keyword">return</span> data<span class="token punctuation">,</span> label    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>imgs<span class="token punctuation">)</span><span class="token comment"># 数据没有归一化</span><span class="token comment"># 图像的大小不统一</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>使用torch vision.datasets 里面的ImageFolder来加载数据</strong></p><p><strong>ImageFolder 假设所有的文件按文件夹保存，每个文件夹下存储同一个类别的图片</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">normalize <span class="token operator">=</span> torch<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>transform  <span class="token operator">=</span> torch<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>         torch<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>         torch<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>         torch<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>         normalize<span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span>dataset <span class="token operator">=</span> ImageFolder<span class="token punctuation">(</span><span class="token string">'data/dogcat_2/'</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>to_img <span class="token operator">=</span> torch<span class="token punctuation">.</span>ToPILImage<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># !!! 这个函数很有用 !!!</span><span class="token comment"># 0.2和0.4是标准差和均值的近似</span>to_img<span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">0.2</span><span class="token operator">+</span><span class="token number">0.4</span><span class="token punctuation">)</span> <span class="token comment"># 相当于反Normalize</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h3><p><code>Dataset</code>只负责数据的抽象，一次调用<code>__getitem__</code>只返回一个样本。前面提到过，在训练神经网络时，最好是对一个batch的数据进行操作，同时还需要对数据进行shuffle和并行加速等。对此，PyTorch提供了<code>DataLoader</code>帮助我们实现这些功能。</p><p>DataLoader的函数定义如下：<br><code>DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, num_workers=0, collate_fn=default_collate, pin_memory=False, drop_last=False)</code></p><ul><li>dataset：加载的数据集(Dataset对象)</li><li>batch_size：batch size</li><li>shuffle:：是否将数据打乱</li><li>sampler： 样本抽样，后续会详细介绍</li><li>num_workers：使用多进程加载的进程数，0代表不使用多进程</li><li>collate_fn： 如何将多个样本数据拼接成一个batch，一般使用默认的拼接方式即可</li><li>pin_memory：是否将数据保存在pin memory区，pin memory中的数据转到GPU会快一些</li><li>drop_last：dataset中的数据个数可能不是batch_size的整数倍，drop_last为True会将多出来不足一个batch的数据丢弃</li></ul><p><strong>如果图片中有坏掉的图片</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 解决方法就是随机返回一张图片</span><span class="token keyword">class</span> <span class="token class-name">NewDogCat</span><span class="token punctuation">(</span>DogCat<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token builtin">super</span><span class="token punctuation">(</span>NewDogCat<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__getitem__<span class="token punctuation">(</span>index<span class="token punctuation">)</span>        <span class="token keyword">except</span><span class="token punctuation">:</span>            new_index <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> self<span class="token punctuation">[</span>new_index<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>根据权值来进行采样</strong></p><p>PyTorch中还单独提供了一个<code>sampler</code>模块，用来对数据进行采样。常用的有随机采样器：<code>RandomSampler</code>，当dataloader的<code>shuffle</code>参数为True时，系统会自动调用这个采样器，实现打乱数据。默认的是采用<code>SequentialSampler</code>，它会按顺序一个一个进行采样。这里介绍另外一个很有用的采样方法：<br><code>WeightedRandomSampler</code>，它会根据每个样本的权重选取数据，在样本比例不均衡的问题中，可用它来进行重采样。</p><p>构建<code>WeightedRandomSampler</code>时需提供两个参数：每个样本的权重<code>weights</code>、共选取的样本总数<code>num_samples</code>，以及一个可选参数<code>replacement</code>。权重越大的样本被选中的概率越大，待选取的样本数目一般小于全部的样本数目。<code>replacement</code>用于指定是否可以重复选取某一个样本，默认为True，即允许在一个epoch中重复采样某一个数据。如果设为False，则当某一类的样本被全部选取完，但其样本数目仍未达到num_samples时，sampler将不会再从该类中选择数据，此时可能导致<code>weights</code>参数失效。下面举例说明。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dataset <span class="token operator">=</span> DogCat<span class="token punctuation">(</span><span class="token string">'data/dogcat/'</span><span class="token punctuation">,</span> transforms<span class="token operator">=</span>transform<span class="token punctuation">)</span><span class="token comment"># 狗的图片被取出的概率是猫的概率的两倍</span><span class="token comment"># 两类图片被取出的概率与weights的绝对大小无关，只和比值有关</span>weights <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span> <span class="token keyword">if</span> label <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token number">1</span> <span class="token keyword">for</span> data<span class="token punctuation">,</span> label <span class="token keyword">in</span> dataset<span class="token punctuation">]</span>weights<span class="token comment"># 输出 [1, 2, 2, 1, 2, 1, 1, 2]</span><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>sampler <span class="token keyword">import</span>  WeightedRandomSamplersampler <span class="token operator">=</span> WeightedRandomSampler<span class="token punctuation">(</span>weights<span class="token punctuation">,</span>\                                num_samples<span class="token operator">=</span><span class="token number">9</span><span class="token punctuation">,</span>\                                replacement<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>                        batch_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>                        sampler<span class="token operator">=</span>sampler<span class="token punctuation">)</span><span class="token keyword">for</span> datas<span class="token punctuation">,</span> labels <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>labels<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 输出</span><span class="token comment">#[1, 0, 1]</span><span class="token comment">#[0, 0, 1]</span><span class="token comment">#[1, 0, 1]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在这种情况下，num_samples等于dataset的样本总数，为了不重复选取，sampler会将每个样本都返回，这样就失去weight参数的意义了。</p><p>从上面的例子可见sampler在样本采样中的作用：如果指定了sampler，shuffle将不再生效，并且sampler.num_samples会覆盖dataset的实际大小，即一个epoch返回的图片总数取决于<code>sampler.num_samples</code>。</p><p><strong>torchvision.utils 中的常用函数 make_grid </strong> 将多张图片拼成一个网络</p><h3 id="可视化工具"><a href="#可视化工具" class="headerlink" title="可视化工具"></a>可视化工具</h3><p><strong>visdom</strong></p><p>Visdom中有两个重要概念：</p><ul><li>env：环境。不同环境的可视化结果相互隔离，互不影响，在使用时如果不指定env，默认使用<code>main</code>。不同用户、不同程序一般使用不同的env。</li><li>pane：窗格。窗格可用于可视化图像、数值或打印文本等，其可以拖动、缩放、保存和关闭。一个程序中可使用同一个env中的不同pane，每个pane可视化或记录某一信息。<br>Visdom的安装可通过命令<code>pip install visdom</code>。安装完成后，需通过<code>python -m visdom.server</code>命令启动visdom服务，或通过<code>nohup python -m visdom.server &amp;</code>命令将服务放至后台运行。Visdom服务是一个web server服务，默认绑定8097端口，客户端与服务器间通过tornado进行非阻塞交互。</li></ul><p>Visdom的使用有两点需要注意的地方：</p><ul><li>需手动指定保存env，可在web界面点击save按钮或在程序中调用save方法，否则visdom服务重启后，env等信息会丢失。</li><li>客户端与服务器之间的交互采用tornado异步框架，可视化操作不会阻塞当前程序，网络异常也不会导致程序退出。</li></ul><p>Visdom以Plotly为基础，支持丰富的可视化操作，下面举例说明一些最常用的操作。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 启动visdom服务器</span><span class="token comment"># nohup python -m visdom.server &amp;</span><span class="token keyword">import</span> torch <span class="token keyword">as</span> t<span class="token keyword">import</span> visdom<span class="token comment"># 新建一个连接客户端</span><span class="token comment"># 指定env = u'test1'，默认端口为8097，host是‘localhost'</span>vis <span class="token operator">=</span> visdom<span class="token punctuation">.</span>Visdom<span class="token punctuation">(</span>env<span class="token operator">=</span><span class="token string">u'test1'</span><span class="token punctuation">,</span>use_incoming_socket<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>x <span class="token operator">=</span> t<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span>y <span class="token operator">=</span> t<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>x<span class="token punctuation">)</span>vis<span class="token punctuation">.</span>line<span class="token punctuation">(</span>X<span class="token operator">=</span>x<span class="token punctuation">,</span> Y<span class="token operator">=</span>y<span class="token punctuation">,</span> win<span class="token operator">=</span><span class="token string">'sinx'</span><span class="token punctuation">,</span> opts<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'title'</span><span class="token punctuation">:</span> <span class="token string">'y=sin(x)'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://z3.ax1x.com/2021/09/20/4JMzYq.png" alt="4JMzYq.png"></p><p>默认的pane没有这么大 可以用鼠标拖拽窗格的右下角进行放缩</p><ul><li>vis = visdom.Visdom(env=u’test1’)，用于构建一个客户端，客户端除指定env之外，还可以指定host、port等参数。</li><li><p>vis作为一个客户端对象，可以使用常见的画图函数，包括：</p><ul><li>line：类似Matlab中的<code>plot</code>操作，用于记录某些标量的变化，如损失、准确率等</li><li>image：可视化图片，可以是输入的图片，也可以是GAN生成的图片，还可以是卷积核的信息</li><li>text：用于记录日志等文字信息，支持html格式</li><li>histgram：可视化分布，主要是查看数据、参数的分布</li><li>scatter：绘制散点图</li><li>bar：绘制柱状图</li><li>pie：绘制饼状图</li><li>更多操作可参考visdom的github主页</li></ul></li></ul><p>这里主要介绍深度学习中常见的line、image和text操作。</p><p>Visdom同时支持PyTorch的tensor和Numpy的ndarray两种数据结构，但不支持Python的int、float等类型，因此每次传入时都需先将数据转成ndarray或tensor。上述操作的参数一般不同，但有两个参数是绝大多数操作都具备的：</p><ul><li>win：用于指定pane的名字，如果不指定，visdom将自动分配一个新的pane。如果两次操作指定的win名字一样，新的操作将覆盖当前pane的内容，因此建议每次操作都重新指定win。</li><li>opts：选项，接收一个字典，常见的option包括<code>title</code>、<code>xlabel</code>、<code>ylabel</code>、<code>width</code>等，主要用于设置pane的显示格式。</li></ul><p>之前提到过，每次操作都会覆盖之前的数值，但往往我们在训练网络的过程中需不断更新数值，如损失值等，这时就需要指定参数<code>update=&#39;append&#39;</code>来避免覆盖之前的数值。而除了使用update参数以外，还可以使用<code>vis.updateTrace</code>方法来更新图，但<code>updateTrace</code>不仅能在指定pane上新增一个和已有数据相互独立的Trace，还能像<code>update=&#39;append&#39;</code>那样在同一条trace上追加数据。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># append 追加数据</span><span class="token keyword">import</span> timetime<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">for</span> ii <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># y = x</span>    time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> t<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>ii<span class="token punctuation">]</span><span class="token punctuation">)</span>    y <span class="token operator">=</span> x    vis<span class="token punctuation">.</span>line<span class="token punctuation">(</span>X<span class="token operator">=</span>x<span class="token punctuation">,</span> Y<span class="token operator">=</span>y<span class="token punctuation">,</span> win<span class="token operator">=</span><span class="token string">'polynomial'</span><span class="token punctuation">,</span> update<span class="token operator">=</span><span class="token string">'append'</span> <span class="token keyword">if</span> ii<span class="token operator">></span><span class="token number">0</span> <span class="token keyword">else</span> <span class="token boolean">None</span><span class="token punctuation">)</span>    <span class="token comment"># updateTrace 新增一条线</span>x <span class="token operator">=</span> t<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>y <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">9</span>time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>vis<span class="token punctuation">.</span>line<span class="token punctuation">(</span>X<span class="token operator">=</span>x<span class="token punctuation">,</span> Y<span class="token operator">=</span>y<span class="token punctuation">,</span> win<span class="token operator">=</span><span class="token string">'polynomial'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'this is a new Trace'</span><span class="token punctuation">,</span>update<span class="token operator">=</span><span class="token string">'new'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>image的画图功能可分为如下两类：</p><ul><li><code>image</code>接收一个二维或三维向量，$H\times W$或$3 \times H\times W$，前者是黑白图像，后者是彩色图像。</li><li><code>images</code>接收一个四维向量$N\times C\times H\times W$，$C$可以是1或3，分别代表黑白和彩色图像。可实现类似torchvision中make_grid的功能，将多张图片拼接在一起。<code>images</code>也可以接收一个二维或三维的向量，此时它所实现的功能与image一致。</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 可视化一个随机的黑白图片</span>vis<span class="token punctuation">.</span>image<span class="token punctuation">(</span>t<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 随机可视化一张彩色图片</span>vis<span class="token punctuation">.</span>image<span class="token punctuation">(</span>t<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> win<span class="token operator">=</span><span class="token string">'random2'</span><span class="token punctuation">)</span><span class="token comment"># 可视化36张随机的彩色图片，每一行6张</span>vis<span class="token punctuation">.</span>images<span class="token punctuation">(</span>t<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">36</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> win<span class="token operator">=</span><span class="token string">'random3'</span><span class="token punctuation">,</span> opts<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'title'</span><span class="token punctuation">:</span><span class="token string">'random_imgs'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>vis.text</code>用于可视化文本，支持所有的html标签，同时也遵循着html的语法标准。例如，换行需使用<code>&lt;br&gt;</code>标签，<code>\r\n</code>无法实现换行。下面举例说明。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">vis<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token triple-quoted-string string">u'''&lt;h1>Hello Visdom&lt;/h1>&lt;br>Visdom是Facebook专门为&lt;b>PyTorch&lt;/b>开发的一个可视化工具，         在内部使用了很久，在2017年3月份开源了它。                  Visdom十分轻量级，但是却有十分强大的功能，支持几乎所有的科学运算可视化任务'''</span><span class="token punctuation">,</span>         win<span class="token operator">=</span><span class="token string">'visdom'</span><span class="token punctuation">,</span>         opts<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'title'</span><span class="token punctuation">:</span> <span class="token string">u'visdom简介'</span> <span class="token punctuation">&#125;</span>        <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="GPU加速-cuda"><a href="#GPU加速-cuda" class="headerlink" title="GPU加速 cuda"></a>GPU加速 cuda</h3><p>在PyTorch中以下数据结构分为CPU和GPU两个版本：</p><ul><li>Tensor</li><li>Variable</li><li>nn.Module（包括常用的layer、loss function，以及容器Sequential等）</li></ul><p>它们都带有一个<code>.cuda</code>方法，调用此方法即可将其转为对应的GPU对象。注意，<code>tensor.cuda</code>会返回一个新对象，这个新对象的数据已转移至GPU，而之前的tensor还在原来的设备上（CPU）。而<code>module.cuda</code>则会将所有的数据都迁移至GPU，并返回自己。所以<code>module = module.cuda()</code>和<code>module.cuda()</code>所起的作用一致。</p><p>nn.Module在GPU与CPU之间的转换，本质上还是利用了Tensor在GPU和CPU之间的转换。<code>nn.Module</code>的cuda方法是将nn.Module下的所有parameter（包括子module的parameter）都转移至GPU，而Parameter本质上也是tensor(Tensor的子类)。</p><p>下面将举例说明，这部分代码需要你具有两块GPU设备。</p><p>P.S. 为什么将数据转移至GPU的方法叫做<code>.cuda</code>而不是<code>.gpu</code>，就像将数据转移至CPU调用的方法是<code>.cpu</code>？这是因为GPU的编程接口采用CUDA，而目前并不是所有的GPU都支持CUDA，只有部分Nvidia的GPU才支持。PyTorch未来可能会支持AMD的GPU，而AMD GPU的编程接口采用OpenCL，因此PyTorch还预留着<code>.cl</code>方法，用于以后支持AMD等的GPU。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> t<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token comment"># 返回一个新的tensor，保存在第1块GPU上，但原来的tensor并没有改变</span>tensor<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>tensor<span class="token punctuation">.</span>is_cuda <span class="token comment"># False</span><span class="token comment"># 不指定所使用的GPU设备，将默认使用第1块GPU</span>tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor<span class="token punctuation">.</span>is_cuda <span class="token comment"># True</span><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nnmodule <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>module<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>device <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>module<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>is_cuda <span class="token comment"># True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h3><p>在PyTorch中，以下对象可以持久化到硬盘，并能通过相应的方法加载到内存中：</p><ul><li>Tensor</li><li>Variable</li><li>nn.Module</li><li>Optimizer</li></ul><p>本质上上述这些信息最终都是保存成Tensor。Tensor的保存和加载十分的简单，使用t.save和t.load即可完成相应的功能。在save/load时可指定使用的pickle模块，在load时还可将GPU tensor映射到CPU或其它GPU上。</p><p>我们可以通过<code>t.save(obj, file_name)</code>等方法保存任意可序列化的对象，然后通过<code>obj = t.load(file_name)</code>方法加载保存的数据。对于Module和Optimizer对象，这里建议保存对应的<code>state_dict</code>，而不是直接保存整个Module/Optimizer对象。Optimizer对象保存的主要是参数，以及动量信息，通过加载之前的动量信息，能够有效地减少模型震荡，下面举例说明。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Module对象的保存与加载</span>t<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'squeezenet.pth'</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>t<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'squeezenet.pth'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> t<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>t<span class="token punctuation">.</span>save<span class="token punctuation">(</span>optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'optimizer.pth'</span><span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>t<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'optimizer.pth'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>all_data <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    optimizer <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    model <span class="token operator">=</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    info <span class="token operator">=</span> <span class="token string">u'模型和优化器的所有参数'</span><span class="token punctuation">)</span>t<span class="token punctuation">.</span>save<span class="token punctuation">(</span>all_data<span class="token punctuation">,</span> <span class="token string">'all.pth'</span><span class="token punctuation">)</span>all_data <span class="token operator">=</span> t<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'all.pth'</span><span class="token punctuation">)</span>all_data<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="文件组织架构"><a href="#文件组织架构" class="headerlink" title="文件组织架构"></a>文件组织架构</h3><p>来看程序文件的组织结构：</p><pre class="line-numbers language-none"><code class="language-none">├── checkpoints&#x2F;├── data&#x2F;│   ├── __init__.py│   ├── dataset.py│   └── get_data.sh├── models&#x2F;│   ├── __init__.py│   ├── AlexNet.py│   ├── BasicModule.py│   └── ResNet34.py└── utils&#x2F;│   ├── __init__.py│   └── visualize.py├── config.py├── main.py├── requirements.txt├── README.md<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> 其中：</p><ul><li><code>checkpoints/</code>： 用于保存训练好的模型，可使程序在异常退出后仍能重新载入模型，恢复训练</li><li><code>data/</code>：数据相关操作，包括数据预处理、dataset实现等</li><li><code>models/</code>：模型定义，可以有多个模型，例如上面的AlexNet和ResNet34，一个模型对应一个文件</li><li><code>utils/</code>：可能用到的工具函数，在本次实验中主要是封装了可视化工具</li><li><code>config.py</code>：配置文件，所有可配置的变量都集中在此，并提供默认值</li><li><code>main.py</code>：主文件，训练和测试程序的入口，可通过不同的命令来指定不同的操作和参数</li><li><code>requirements.txt</code>：程序依赖的第三方库</li><li><code>README.md</code>：提供程序的必要说明</li></ul><p>可以看到，几乎每个文件夹下都有<code>__init__.py</code>，一个目录如果包含了<code>__init__.py</code> 文件，那么它就变成了一个包（package）。<code>__init__.py</code>可以为空，也可以定义包的属性和方法，但其必须存在，其它程序才能从这个目录中导入相应的模块或函数。例如在<code>data/</code>文件夹下有<code>__init__.py</code>，则在<code>main.py</code> 中就可以<code>from data.dataset import DogCat</code>。而如果在<code>__init__.py</code>中写入<code>from .dataset import DogCat</code>，则在main.py中就可以直接写为：<code>from data import DogCat</code>，或者<code>import data; dataset = data.DogCat</code>，相比于<code>from data.dataset import DogCat</code>更加便捷。</p><p>亲自测试：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># main.py</span><span class="token keyword">from</span> goon <span class="token keyword">import</span> Aa <span class="token operator">=</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span>a<span class="token punctuation">.</span>ccc<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># cjn.py</span><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">pass</span>  <span class="token keyword">def</span> <span class="token function">ccc</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'520'</span><span class="token punctuation">)</span>      <span class="token comment"># cjn.py</span><span class="token keyword">from</span> <span class="token punctuation">.</span>cjn <span class="token keyword">import</span> A<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在config.py中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DefaultConfig</span><span class="token punctuation">:</span>    <span class="token comment"># 一堆配置</span>    <span class="token keyword">def</span> <span class="token function">_parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> kwargs<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 类里面的方法和属性都属于attr</span>            warning<span class="token punctuation">.</span>warn<span class="token punctuation">(</span><span class="token string">"..."</span><span class="token punctuation">)</span>          <span class="token builtin">setattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> k<span class="token punctuation">,</span> v<span class="token punctuation">)</span>      <span class="token comment"># ...</span>            <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> self<span class="token punctuation">.</span>__class__<span class="token punctuation">.</span>__dict__<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token keyword">if</span> <span class="token keyword">not</span> k<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'_'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>              <span class="token keyword">print</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">)</span>              opt <span class="token operator">=</span> DefaultConfig<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>main.py的结构</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># ...</span>    <span class="token keyword">pass</span>  <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># ...</span>    <span class="token keyword">pass</span><span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">val</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># ...</span>    <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">help</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># ...</span>    <span class="token keyword">pass</span>        <span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token keyword">import</span> fire    fire<span class="token punctuation">.</span>Fire<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>学到的知识点：</p><ul><li><p>detach  <a href="https://blog.csdn.net/qq_27825451/article/details/95498211">参考链接</a></p><p>使用detach返回的<code>tensor</code>和原始的<code>tensor</code>共同一个<code>内存，即一个修改另一个也会跟着改变</code>。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>out <span class="token operator">=</span> a<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>c <span class="token operator">=</span> out<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>out<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 是正常求导 没问题</span>c<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 就有问题了</span><span class="token comment"># main.py中用到detach的地方</span>confusion_matrix<span class="token punctuation">.</span>add<span class="token punctuation">(</span>score<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><ul><li><p>meter</p><p>导入方式from torchnet import meter</p><p>一个使用meter的例子</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss_meter <span class="token operator">=</span> meter<span class="token punctuation">.</span>AverageValueMeter<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_meter<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  loss_meter<span class="token punctuation">.</span>add<span class="token punctuation">(</span>i<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>loss_meter<span class="token punctuation">.</span>value<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 输出 mean, std</span><span class="token comment"># 在main.py中</span>loss_meter<span class="token punctuation">.</span>add<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#不知道为什么要用loss_meter 感觉代码里面就用它来求均值了</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><ul><li><p>confusionmeter</p><p>导入方式 from torchnet import confusionmatrix</p><p>一个使用confusionmatrix的例子. <a href="https://tnt.readthedocs.io/en/latest/_modules/torchnet/meter/confusionmeter.html">confusionmatrix 源码链接</a></p></li></ul><h3 id="mini-dog-versus-cat"><a href="#mini-dog-versus-cat" class="headerlink" title="mini dog versus cat"></a>mini dog versus cat</h3><p>我的显卡比较老旧，整个数据集跑起来估计有点困难，我把数据集缩小成训练集4000 其中猫2000 狗2000，测试集1000</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 这个是 从全部图片中挑选部分数据集 的代码</span><span class="token comment"># 代码放在scripts文件夹下，scripts文件夹和data文件夹同层</span><span class="token comment"># data文件夹下的dogcat文件夹下 有train文件夹和test文件夹，train文件夹下图片的格式为cat.&lt;num>.jpg和dog.&lt;num>.jpg</span><span class="token comment"># test1文件夹下的图片格式为&lt;num>.jpg</span><span class="token comment"># 文件移动的函数为 shutil库中的copyfile  删除文件夹用的是shutil库中的rmtree</span><span class="token comment"># 后来发现test1里面没有标签 手动标签很麻烦，所以改成从训练集中取1000 作为测试集</span><span class="token keyword">import</span> shutil<span class="token keyword">import</span> os<span class="token keyword">import</span> random<span class="token keyword">import</span> timedirpath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span>datasetpath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dirpath<span class="token punctuation">,</span> <span class="token string">'..'</span><span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'dogcat'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>dstdirpath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dirpath<span class="token punctuation">,</span> <span class="token string">'..'</span><span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'minidogcat'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>dsttraindir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dstdirpath<span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">)</span>dsttestdir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dstdirpath<span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">)</span><span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>dsttraindir<span class="token punctuation">)</span><span class="token punctuation">:</span>os<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span>dsttraindir<span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"目标路径"</span><span class="token punctuation">,</span> dsttraindir<span class="token punctuation">)</span><span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">"confirm"</span><span class="token punctuation">)</span>shutil<span class="token punctuation">.</span>rmtree<span class="token punctuation">(</span>dsttraindir<span class="token punctuation">)</span>os<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span>dsttraindir<span class="token punctuation">)</span><span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>dsttestdir<span class="token punctuation">)</span><span class="token punctuation">:</span>os<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span>dsttestdir<span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"目标路径"</span><span class="token punctuation">,</span> dsttestdir<span class="token punctuation">)</span><span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">"confirm"</span><span class="token punctuation">)</span>shutil<span class="token punctuation">.</span>rmtree<span class="token punctuation">(</span>dsttestdir<span class="token punctuation">)</span>os<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span>dsttestdir<span class="token punctuation">)</span>trainpath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>datasetpath<span class="token punctuation">,</span> <span class="token string">"train"</span><span class="token punctuation">)</span>test1path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>datasetpath<span class="token punctuation">,</span> <span class="token string">"test1"</span><span class="token punctuation">)</span>traincat <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>traindog <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>train <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># 最终选出来的训练文件 从traincat中采样一部分加上从traindog中采样一部分</span>testcatdog <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>test <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># 最终选出来的测试文件</span><span class="token keyword">for</span> trainfile <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>trainpath<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token keyword">if</span> <span class="token string">'cat'</span> <span class="token keyword">in</span> trainfile<span class="token punctuation">:</span>traincat<span class="token punctuation">.</span>append<span class="token punctuation">(</span>trainfile<span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span>traindog<span class="token punctuation">.</span>append<span class="token punctuation">(</span>trainfile<span class="token punctuation">)</span><span class="token keyword">for</span> testfile <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>test1path<span class="token punctuation">)</span><span class="token punctuation">:</span>testcatdog<span class="token punctuation">.</span>append<span class="token punctuation">(</span>testfile<span class="token punctuation">)</span><span class="token comment">#train += random.sample(traincat, 2000)</span><span class="token comment">#train += random.sample(traindog, 2000)</span><span class="token comment">#test = random.sample(testcatdog, 1000)</span><span class="token comment"># 重新进行数据划分</span>temp <span class="token operator">=</span> random<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>traincat<span class="token punctuation">,</span> <span class="token number">3000</span><span class="token punctuation">)</span>temp2 <span class="token operator">=</span> random<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>traindog<span class="token punctuation">,</span> <span class="token number">3000</span><span class="token punctuation">)</span>train <span class="token operator">=</span> temp<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2500</span><span class="token punctuation">]</span> <span class="token operator">+</span> temp2<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2500</span><span class="token punctuation">]</span>test <span class="token operator">=</span> temp<span class="token punctuation">[</span><span class="token number">2500</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+</span> temp2<span class="token punctuation">[</span><span class="token number">2500</span><span class="token punctuation">:</span><span class="token punctuation">]</span>start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> <span class="token builtin">file</span> <span class="token keyword">in</span> train<span class="token punctuation">:</span>srcpath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>trainpath<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token punctuation">)</span>dstpath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dsttraindir<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token punctuation">)</span>shutil<span class="token punctuation">.</span>copyfile<span class="token punctuation">(</span>srcpath<span class="token punctuation">,</span> dstpath<span class="token punctuation">)</span>middle_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'COPY Train images cost '</span><span class="token punctuation">,</span> middle_time <span class="token operator">-</span> start_time<span class="token punctuation">)</span><span class="token keyword">for</span> <span class="token builtin">file</span> <span class="token keyword">in</span> test<span class="token punctuation">:</span>srcpath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>test1path<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token punctuation">)</span>dstpath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dsttestdir<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token punctuation">)</span>shutil<span class="token punctuation">.</span>copyfile<span class="token punctuation">(</span>srcpath<span class="token punctuation">,</span> dstpath<span class="token punctuation">)</span>end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'COPY test images cost '</span><span class="token punctuation">,</span> end_time <span class="token operator">-</span> middle_time<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下面的代码是写在服务器上面的：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 原始数据在 某个目录/data/dogcat/(train和test) 脚本在 某个目录/scripts/minidogcat.py</span><span class="token comment"># 比上面这个代码要写的好</span><span class="token keyword">import</span> shutil<span class="token keyword">import</span> os<span class="token keyword">import</span> randomdirpath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span>datapath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dirpath<span class="token punctuation">,</span> <span class="token string">'..'</span><span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>srctrainpath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>datapath<span class="token punctuation">,</span> <span class="token string">'dogcat'</span><span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">)</span>dstpath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>datapath<span class="token punctuation">,</span> <span class="token string">'minidogcat'</span><span class="token punctuation">)</span>dsttrainpath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dstpath<span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">)</span>dsttestpath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dstpath<span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">)</span><span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>dstpath<span class="token punctuation">)</span><span class="token punctuation">:</span>    shutil<span class="token punctuation">.</span>rmtree<span class="token punctuation">(</span>dstpath<span class="token punctuation">)</span>os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>dsttrainpath<span class="token punctuation">)</span>os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>dsttestpath<span class="token punctuation">)</span>img_list <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>srctrainpath<span class="token punctuation">)</span><span class="token punctuation">,</span> key <span class="token operator">=</span> <span class="token keyword">lambda</span> x <span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>train_list <span class="token operator">=</span> img_list<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.7</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>img_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>test_list <span class="token operator">=</span> img_list<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.7</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>img_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token keyword">for</span> _file <span class="token keyword">in</span> train_list<span class="token punctuation">:</span>    _from <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>srctrainpath<span class="token punctuation">,</span> _file<span class="token punctuation">)</span>    _to   <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dsttrainpath<span class="token punctuation">,</span> _file<span class="token punctuation">)</span>    shutil<span class="token punctuation">.</span>copyfile<span class="token punctuation">(</span>_from<span class="token punctuation">,</span> _to<span class="token punctuation">)</span><span class="token keyword">for</span> _file <span class="token keyword">in</span> test_list<span class="token punctuation">:</span>    _from <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>srctrainpath<span class="token punctuation">,</span> _file<span class="token punctuation">)</span>    _to   <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dsttestpath<span class="token punctuation">,</span> _file<span class="token punctuation">)</span>    shutil<span class="token punctuation">.</span>copyfile<span class="token punctuation">(</span>_from<span class="token punctuation">,</span> _to<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后猫狗分类器的代码如下， 第一次跑准确率100%，很明显 我代码里面有问题，我的标签全被我弄成全0了，改了之后 10个epoch batchsize512 lr=2e-3  准确率是58% 把模型在训练集上面跑了 准确率是75%</p><p><strong>然后把epoch 改成了50</strong>  发现test集的准确率到了77.4%</p><p><strong>然后把epoch 改成了 100</strong> 训练时间变成1个半小时了  eval avg_loss 0.003349 Acc 0.761524</p><p>train eval_loss 0.000029 Acc 99.57  test avg_loss 0.003035 Acc 0.776400 感觉到顶了</p><p>而且感觉我这个模型过拟合了，以后有时间就去调一调</p><p>用书上给的模型跑出来的eval准确率是97%，squeezenet收敛和训练速度都要比resnet34要快</p><p>resnet 我的超参数是batchsize 128, lr 0.002 weight_decay 5e-4 lr_decay 0.9 max_epoch 100</p><p><img src="https://z3.ax1x.com/2021/10/01/4Tx2VJ.jpg" alt="训练的loss"><br><img src="https://z3.ax1x.com/2021/10/01/4Tx7rD.jpg" alt="训练的acc"></p><p>eval上的准确大概是96%</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> pytorch </tag>
            
            <tag> MNIST </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>decision tree</title>
      <link href="2021/09/17/decision%20tree/"/>
      <url>2021/09/17/decision%20tree/</url>
      
        <content type="html"><![CDATA[<h2 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>决策树是一种非参数的有监督的学习方法，包含于sklearn.tree模块中</p><h3 id="DecisionTreeClassifier"><a href="#DecisionTreeClassifier" class="headerlink" title="DecisionTreeClassifier"></a>DecisionTreeClassifier</h3><p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontree%20classifier#sklearn.tree.DecisionTreeClassifier">sklearn文档链接</a></p><p><a href="https://scikit-learn.org/stable/modules/tree.html#tree">关于决策树算法的介绍链接</a></p><p><strong>criterion</strong> 有两种 一种是gini系数，一种是entropy，信息熵对不纯度更加敏感，对其惩罚最强，但是在实际使用中两者效果基本相同，gini算的更快，因为不用算log，<strong>对于高维数据或者噪音很多的数据，信息熵容易过拟合</strong></p><p><strong>决策树基本流程</strong></p><pre class="line-numbers language-mermaid" data-language="mermaid"><code class="language-mermaid">graph LR计算全部特征的不纯度指标--&gt;选取不纯度指标最优的特征来分支--&gt;递归前两步直到不纯度指标最优<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>决策树与红酒测试集</strong> 红酒测试集在  from sklearn.datasets import load_wine中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 加载数据集</span><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> tree<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_wine<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_splitwine <span class="token operator">=</span> load_wine<span class="token punctuation">(</span><span class="token punctuation">)</span>wine<span class="token punctuation">.</span>data <span class="token comment"># wine.data.shape 返回是 (178, 13) 178个数据，13个特征</span>wine<span class="token punctuation">.</span>target<span class="token comment"># 将数据以表的形式显示出来</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdpd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>wind<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>wine<span class="token punctuation">.</span>target<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># 将数据分成训练集和测试集</span>Xtrain<span class="token punctuation">,</span> Xtest<span class="token punctuation">,</span> Ytrain<span class="token punctuation">,</span> Ytest <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>wine<span class="token punctuation">.</span>data<span class="token punctuation">,</span> wine<span class="token punctuation">.</span>target<span class="token punctuation">,</span> test_size <span class="token operator">=</span> <span class="token number">0.3</span><span class="token punctuation">)</span><span class="token comment"># 经测试 这个是随机切分的，对同一个数据集 运行多次上面的代码 得到的切分后的数据集不一样</span><span class="token comment"># 三步走  第一步实例化决策树， 第二步训练， 第三步进行预测</span>clf <span class="token operator">=</span> tree<span class="token punctuation">.</span>DecisionTreeClassifier<span class="token punctuation">(</span>criterion<span class="token operator">=</span><span class="token string">"entropy"</span><span class="token punctuation">)</span>clf <span class="token operator">=</span>  clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>Xtrain<span class="token punctuation">,</span> Ytrain<span class="token punctuation">)</span>score <span class="token operator">=</span> clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>Xtest<span class="token punctuation">,</span> Ytest<span class="token punctuation">)</span><span class="token comment"># 可视化决策树</span><span class="token keyword">import</span> graphvizdot_data <span class="token operator">=</span> tree<span class="token punctuation">.</span>export_graphviz<span class="token punctuation">(</span>clf                               <span class="token punctuation">,</span>feature_names <span class="token operator">=</span> wine<span class="token punctuation">.</span>feature_names                                <span class="token punctuation">,</span>class_names <span class="token operator">=</span> wine<span class="token punctuation">.</span>target_names                                <span class="token punctuation">,</span>filled <span class="token operator">=</span> <span class="token boolean">True</span> <span class="token comment"># 结点是否有颜色</span>                                <span class="token punctuation">,</span>rounded <span class="token operator">=</span> <span class="token boolean">True</span> <span class="token comment"># 结点的边框是否是圆形</span>                               <span class="token punctuation">)</span>graph <span class="token operator">=</span> graphviz<span class="token punctuation">.</span>Source<span class="token punctuation">(</span>dot_data<span class="token punctuation">)</span>graph<span class="token comment"># 逗号打前面是 方便将这行注释， 如果逗号在上面 那么注释完一行还要把上面的逗号给去掉！！</span><span class="token comment"># 查看决策树中每个特征的重要性</span><span class="token punctuation">[</span><span class="token operator">*</span><span class="token builtin">zip</span><span class="token punctuation">(</span>wine<span class="token punctuation">.</span>feature_names<span class="token punctuation">,</span> clf<span class="token punctuation">.</span>feature_importances_<span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>每次运行三步走的时候结果都不一样，这是因为</p><p>sklearn用的是集成算法来算决策树的，即建了很多颗树然后选一个最好的返回，建树的方法是 每次分枝，不使用全部特征，而是随机选取一部分特征，从中选取不纯度相关指标最优的作为分枝用的节点。这样每次生成的树也就不同了 要用random_state参数来保证每次运行的结果一样</p><p>random_state默认值是None，在高维度时随机性会表现的明显，低维度的时候表现的不明显</p><p>splitter 用来控制决策树中的随机选项，可选best或者random，random分枝时会更加随机，树会更深，这可以用作防止过拟合</p><h5 id="剪枝参数"><a href="#剪枝参数" class="headerlink" title="剪枝参数"></a>剪枝参数</h5><p>在不加限制的情况下，一棵决策树会生长到衡量不纯度最优，或者没有可用的特征为止，这样的决策树往往会过拟合，为了更好的泛化性，要对决策树进行剪枝。</p><ul><li><p>max_depth</p><p>限制树的最大深度，超过设定深度的树枝全部剪掉，一般从3开始，这个使用最广泛，在高维度低样本量时非常有效</p></li><li><p>min_samples_leaf &amp; min_samples_split</p><p>一个节点在分枝后的每个子节点都必须包含至少min_samples_leaf个训练样本 否则分枝就不会发生</p><p>一个节点必须要包含min_samples_split个训练样本，这个节点才允许被分枝</p><p>min_samples_leaf 一般从5开始，也可以输入浮点数作为样本量的百分比来使用</p></li><li><p>max_features &amp; min_impurity_decrease</p><p>max_features限制分枝时考虑的特征个数，超过限制个数的特征都会被舍弃，这个比较暴力，建议用PCA代替</p><p>min_impurity_decrease限制信息增益的大小，信息增益小于设定数值的分枝不会发生</p></li><li><p>class_weight &amp; min_weight_fraction_leaf</p><p>这两个是完成样本标签平衡的参数，使用class_weight参数对样本标签进行一定的均衡，给少量的标签更多的权重，让模型更偏向少数类，剪枝时会搭配min_weight_fraction_leaf</p></li></ul><h5 id="重要属性和接口"><a href="#重要属性和接口" class="headerlink" title="重要属性和接口"></a>重要属性和接口</h5><p>clf.apply  返回每个测试样本所在的叶子节点的索引</p><p>clf.predict 返回每个测试样本的分类/回归结果</p><p><strong>PS： 环形数据对决策树天生是一个难点 </strong></p><ul><li>最擅长月亮型数据的是KNN，RBFSVM，高斯过程</li><li>最擅长环形数据的是KNN和高斯过程</li><li>最擅长对半分的数据是朴素贝叶斯，NN，RF</li></ul><h3 id="DecisionTreeRegression"><a href="#DecisionTreeRegression" class="headerlink" title="DecisionTreeRegression"></a>DecisionTreeRegression</h3><p>与分类树不同的是，回归树没有标签分布是否均衡的问题，没有class_weight这样的参数</p><p>回归树衡量分枝质量指标，支持的标准 mse, friedman__mse, mae</p><p><strong>在回归树中，MSE不只是我们的分枝质量衡量指标 ，也是我们最常用的衡量回归树回归质量的指标</strong></p><p>不过 <strong>回归树的接口score返回的是R平方，不是MSE</strong></p><script type="math/tex; mode=display">R^2 = 1 - \frac{u}{v} \\u = \sum_{i = 1}^N (f_i - y_i)^2 \quad \quad  v = \sum_{i = 1}^N(y_i - \hat{y})^2</script><p>其中$\hat{y}$是真实数值标签的平均数。R平方可以为正为负</p><p>虽然均方误差永远为正，但是sklearn当中使用均方误差作为评判标准时，却计算的时负均方误差</p><h5 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h5><p> 之前的train_test_split(wine.data, wine.target, test_size = 0.3) 是随机划分训练集和测试集，模型是在训练集上训练然后在测试集上测试，不同的划分会导致结果的不同，为了测试模型的稳定性，可以多次划分然后取平均</p><p><strong>使用的是from  sklearn.model_selection  import  cross_val_score</strong>,   下面是一个示例</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">boston  <span class="token operator">=</span> load_boston<span class="token punctuation">(</span><span class="token punctuation">)</span>regressor <span class="token operator">=</span> DecisionTreeRegressor<span class="token punctuation">(</span>random_state <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>cross_val_score<span class="token punctuation">(</span>regressor<span class="token punctuation">,</span> boston<span class="token punctuation">.</span>data<span class="token punctuation">,</span> boston<span class="token punctuation">.</span>target<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">10</span>               <span class="token punctuation">,</span>scoring <span class="token operator">=</span> <span class="token string">"neg_mean_squared_error"</span><span class="token punctuation">)</span> <span class="token comment"># scoring用来设置衡量模型的标准</span><span class="token comment">#scoring 默认是R平方</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="用回归树来拟合正弦曲线"><a href="#用回归树来拟合正弦曲线" class="headerlink" title="用回归树来拟合正弦曲线"></a>用回归树来拟合正弦曲线</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 创建一条含有噪声的正弦曲线</span>rng  <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>RandomState<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>X <span class="token operator">=</span> np<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token number">5</span> <span class="token operator">*</span> rng<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># 这个可以的鸭</span>y <span class="token operator">=</span> np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 生成正弦曲线</span>y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">3</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">0.5</span> <span class="token operator">-</span> rng<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 在正弦曲线上加噪声</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token comment"># np.sort 默认axis = 1 按行排序，axis = 0按列排序</span><span class="token comment"># np.random.rand生成[0,1)的均匀分布</span><span class="token comment"># np.ravel()和np.flatten()都是将多维数组降为一维 flatten是返回的一个全新的</span><span class="token comment"># 准备测试集</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span> <span class="token comment"># 后面的方括号是升维的作用</span><span class="token comment"># 准备模型</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeRegressorreg1 <span class="token operator">=</span> DecisionTreeRegressor<span class="token punctuation">(</span>max_depth <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>reg2 <span class="token operator">=</span> DecisionTreeRegressor<span class="token punctuation">(</span>max_depth <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token comment"># 训练</span>reg1<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>reg2<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token comment">#预测</span>y1 <span class="token operator">=</span> reg1<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span><span class="token punctuation">)</span>y2 <span class="token operator">=</span> reg2<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 画图</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> edgecolor <span class="token operator">=</span> <span class="token string">'black'</span><span class="token punctuation">,</span> c <span class="token operator">=</span> <span class="token string">'darkorange'</span><span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">'data'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y1<span class="token punctuation">,</span> c <span class="token operator">=</span> <span class="token string">'blue'</span><span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">'max_depth = 2'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y2<span class="token punctuation">,</span> c <span class="token operator">=</span> <span class="token string">'red'</span><span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">'max_depth = 5'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Decision Tree Classifier'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'X'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'SIN X'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://z3.ax1x.com/2021/09/16/4e7Kc4.png" alt="4e7Kc4.png"></p><h3 id="泰坦尼克号生存者预测"><a href="#泰坦尼克号生存者预测" class="headerlink" title="泰坦尼克号生存者预测"></a>泰坦尼克号生存者预测</h3><p>这个数据集挺有名的，<a href="https://www.kaggle.com/c/titanic">数据集的下载链接</a></p><ul><li><p>首先进行数据加载，使用pd.read_csv</p></li><li><p>接着对数据进行查看，使用<strong>info函数</strong> 和<strong>head 函数</strong></p></li><li><p>根据观察发现有些特征提供不了什么信息 比如说人名，Cabin，Ticket 因为这些相当于一个编号，Cabin是座舱 不过这一列的数据只有200多个 缺失值很多，直接删掉。通过<strong>data.loc[:, ‘Ticket’].unique().shape 发现这一列的数据有681的不同的值 这个和ID差不多了 信息量很少 直接删掉</strong></p><p>使用<code>data.drop(&#39;Name&#39;, &#39;Ticket&#39;, &#39;Cabin&#39;], inplace = True, axis = 1)</code></p></li><li><p>接着 <strong>处理缺失值</strong> 缺失值有两个一个是Age 一个是Embarked，对于Age缺失的数量是20%左右，而Embarked的缺失量是2个，Age是一个非常重要的特征，因为可能会有老幼先行，对于Embarked 缺两个可以直接把这两行给删掉</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Age'</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>data <span class="token operator">=</span> data<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>接着将分类变量转换为数值类型，<strong>PS 要注意对待有序分类变量和无序分类变量是不一样的 </strong> </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Sex'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Sex'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'male'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'int'</span><span class="token punctuation">)</span>labels <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'Embarked'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Embarked'</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Embarked'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x <span class="token punctuation">:</span> labels<span class="token punctuation">.</span>index<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># index是list的一个方法 </span><span class="token comment"># 对于 yyy = [1, 2, 3];  print(yyy.index(3)) 会输出2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>接着把table 分成数据和标签 使用train_test_split</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>columns <span class="token operator">!=</span> <span class="token string">'Survived'</span><span class="token punctuation">]</span>y <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>columns <span class="token operator">!=</span> <span class="token string">'Survived'</span><span class="token punctuation">]</span>Xtrain<span class="token punctuation">,</span> Xtest<span class="token punctuation">,</span> Ytrain<span class="token punctuation">,</span> Ytest <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size <span class="token operator">=</span> <span class="token number">0.3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ul><p><strong>PS  根据菜菜所说 这个数据跑到0.85就很厉害了，我看了一下leaderboard 一堆1.0的。。</strong></p><p><strong>PS2  [*range(10)] 会产生一个包含0到9的列表  这个简介的写法厉害了 </strong></p><p>跑模型的过程：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">clf <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>random_state <span class="token operator">=</span> <span class="token number">25</span><span class="token punctuation">)</span>clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>Xtrain<span class="token punctuation">,</span> Ytrain<span class="token punctuation">)</span>score <span class="token operator">=</span> clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>Xtest<span class="token punctuation">,</span> Ytest<span class="token punctuation">)</span><span class="token comment"># 我的这个结果是0.7265</span><span class="token comment"># 用交叉验证来进行测试</span>score <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>clf<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>score<span class="token punctuation">)</span>clf <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>random_state <span class="token operator">=</span> <span class="token number">25</span><span class="token punctuation">)</span>score <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>clf<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token comment"># 两种方法的结果是一样的</span><span class="token comment"># 参数搜索</span>tr<span class="token punctuation">,</span> te <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    clf <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>random_state <span class="token operator">=</span> <span class="token number">25</span><span class="token punctuation">,</span> max_depth <span class="token operator">=</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>    clf <span class="token operator">=</span> clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>Xtrain<span class="token punctuation">,</span> Ytrain<span class="token punctuation">)</span>    score_tr <span class="token operator">=</span> clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>Xtrain<span class="token punctuation">,</span> Ytrain<span class="token punctuation">)</span>    score_te <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>clf<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>    tr<span class="token punctuation">.</span>append<span class="token punctuation">(</span>score_tr<span class="token punctuation">)</span>    te<span class="token punctuation">.</span>append<span class="token punctuation">(</span>score_te<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>te<span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tr<span class="token punctuation">,</span> color <span class="token operator">=</span> <span class="token string">'red'</span><span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">'train'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">,</span> te<span class="token punctuation">,</span> color <span class="token operator">=</span> <span class="token string">'blue'</span><span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">'test'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果如下：</p><p><img src="https://z3.ax1x.com/2021/09/16/4m3WrV.png" alt="4m3WrV.png"></p><p>最好的准确率是0.81左右</p><h5 id="使用网格搜索"><a href="#使用网格搜索" class="headerlink" title="使用网格搜索"></a>使用网格搜索</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python">parameters <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">'criterion'</span>  <span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token string">'gini'</span><span class="token punctuation">,</span> <span class="token string">'entropy'</span><span class="token punctuation">)</span>    <span class="token punctuation">,</span><span class="token string">'splitter'</span>  <span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token string">'best'</span><span class="token punctuation">,</span> <span class="token string">'random'</span><span class="token punctuation">)</span>    <span class="token punctuation">,</span><span class="token string">'max_depth'</span> <span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token operator">*</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token punctuation">,</span><span class="token string">'min_samples_leaf'</span> <span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token operator">*</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token punctuation">,</span><span class="token string">'min_impurity_decrease'</span> <span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token operator">*</span>np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span>clf <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>random_state <span class="token operator">=</span> <span class="token number">25</span><span class="token punctuation">)</span>GS <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>clf<span class="token punctuation">,</span> parameters<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span>GS<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>Xtrain<span class="token punctuation">,</span> Ytrain<span class="token punctuation">)</span>GS<span class="token punctuation">.</span>best_params_ <span class="token comment"># 从我们输入的参数和参数取值的列表中，返回最佳组合</span>GS<span class="token punctuation">.</span>best_score_ <span class="token comment"># 网格搜索后的模型的评判标准</span><span class="token comment"># 有个问题 那就是random_state 能纳入到GridSearchCV中吗</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>网格搜索的一个缺点就是 我设置了’min_samples_leaf’的搜索范围 那么它就不会搜索没有’min_samples_leaf’的情况</p><h3 id="Kaggle上提交titanic结果"><a href="#Kaggle上提交titanic结果" class="headerlink" title="Kaggle上提交titanic结果"></a>Kaggle上提交titanic结果</h3><p><img src="https://z3.ax1x.com/2021/09/17/4MTdPI.png" alt="4MTdPI.png"></p><p>百分之76.8， 第一次提交 撒花~~~</p><p>其实就是要交个CSV上面去</p><p>下面是我的代码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifier<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> GridSearchCV<span class="token punctuation">,</span> train_test_split<span class="token punctuation">,</span> cross_val_scoredata <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">r'F:\sjtu\pytorch study\data\titanic\train.csv'</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'PassengerId'</span><span class="token punctuation">,</span><span class="token string">'Name'</span><span class="token punctuation">,</span> <span class="token string">'Cabin'</span><span class="token punctuation">,</span> <span class="token string">'Ticket'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Age'</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>data <span class="token operator">=</span> data<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Sex'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Sex'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'male'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'int'</span><span class="token punctuation">)</span>labels <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Embarked'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Embarked'</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Embarked'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> labels<span class="token punctuation">.</span>index<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>X <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>columns <span class="token operator">!=</span> <span class="token string">'Survived'</span><span class="token punctuation">]</span>y <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>columns <span class="token operator">==</span> <span class="token string">'Survived'</span><span class="token punctuation">]</span>Xtrain<span class="token punctuation">,</span> Xtest<span class="token punctuation">,</span> Ytrain<span class="token punctuation">,</span> Ytest <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size <span class="token operator">=</span> <span class="token number">0.3</span><span class="token punctuation">)</span>parameters <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">'criterion'</span>  <span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token string">'gini'</span><span class="token punctuation">,</span> <span class="token string">'entropy'</span><span class="token punctuation">)</span>    <span class="token punctuation">,</span><span class="token string">'splitter'</span>  <span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token string">'best'</span><span class="token punctuation">,</span> <span class="token string">'random'</span><span class="token punctuation">)</span>    <span class="token punctuation">,</span><span class="token string">'max_depth'</span> <span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token operator">*</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token punctuation">,</span><span class="token string">'min_samples_leaf'</span> <span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token operator">*</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span>clf <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>random_state <span class="token operator">=</span> <span class="token number">25</span><span class="token punctuation">)</span>GS <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>clf<span class="token punctuation">,</span> parameters<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span>GS<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>Xtrain<span class="token punctuation">,</span> Ytrain<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>GS<span class="token punctuation">.</span>best_params_ <span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>GS<span class="token punctuation">.</span>best_score_<span class="token punctuation">)</span>clf <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>random_state <span class="token operator">=</span> <span class="token number">25</span><span class="token punctuation">,</span> criterion <span class="token operator">=</span> <span class="token string">'entropy'</span><span class="token punctuation">,</span> max_depth <span class="token operator">=</span> <span class="token number">6</span><span class="token punctuation">,</span> min_samples_leaf <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> splitter <span class="token operator">=</span> <span class="token string">'random'</span><span class="token punctuation">)</span>clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>Xtrain<span class="token punctuation">,</span>Ytrain<span class="token punctuation">)</span>cross_val_score<span class="token punctuation">(</span>clf<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> cv <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>myalos <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">r'F:\sjtu\pytorch study\data\titanic\test.csv'</span><span class="token punctuation">)</span><span class="token builtin">id</span> <span class="token operator">=</span> myalos<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">'PassengerId'</span><span class="token punctuation">]</span>myalos<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'PassengerId'</span><span class="token punctuation">,</span> <span class="token string">'Name'</span><span class="token punctuation">,</span> <span class="token string">'Ticket'</span><span class="token punctuation">,</span> <span class="token string">'Cabin'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>myalos<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Age'</span><span class="token punctuation">]</span> <span class="token operator">=</span> myalos<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>myalos<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>myalos<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Fare'</span><span class="token punctuation">]</span> <span class="token operator">=</span> myalos<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Fare'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>myalos<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Fare'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>myalos<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span>myalos<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>myalos<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Sex'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>myalos<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Sex'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'male'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'int'</span><span class="token punctuation">)</span>labels <span class="token operator">=</span> myalos<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Embarked'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>myalos<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Embarked'</span><span class="token punctuation">]</span> <span class="token operator">=</span> myalos<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token string">'Embarked'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> labels<span class="token punctuation">.</span>index<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>myalos<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>myalos<span class="token punctuation">)</span><span class="token punctuation">.</span>shapepd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">id</span><span class="token punctuation">,</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>myalos<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>result <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">id</span><span class="token punctuation">,</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>myalos<span class="token punctuation">)</span><span class="token punctuation">,</span> index <span class="token operator">=</span> <span class="token builtin">id</span><span class="token punctuation">.</span>index<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>result<span class="token punctuation">.</span>columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'PassengerId'</span><span class="token punctuation">,</span> <span class="token string">'Survived'</span><span class="token punctuation">]</span>result<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">r'F:\sjtu\pytorch study\data\titanic\result.csv'</span><span class="token punctuation">,</span> index <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> sklearn </tag>
            
            <tag> 菜菜 </tag>
            
            <tag> decision tree </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nn.Module和LeNet的创建</title>
      <link href="2021/09/17/week3/"/>
      <url>2021/09/17/week3/</url>
      
        <content type="html"><![CDATA[<h3 id="模型创建步骤"><a href="#模型创建步骤" class="headerlink" title="模型创建步骤"></a>模型创建步骤</h3><ul><li>构建网络层   在init函数里面构造子模块</li><li>拼接网络层</li><li>权值初始化 Xavier， Kaming，均匀分布，正态分布等</li></ul><h3 id="nn-Module"><a href="#nn-Module" class="headerlink" title="nn.Module"></a>nn.Module</h3><p>与其相关的四个模块<strong>nn.Parameter，nn.Module，nn.functional，nn.init</strong></p><ul><li>nn.Parameter 张量子类，表示可学习参数，如 weight，bias</li><li>所有网络层基类，管理网络属性</li><li>函数具体实现，如卷积、池化、激活函数等</li><li>参数初始化方法</li></ul><p><strong>8个重要的有序字典</strong></p><p>在nn.Module的init中 调用了self._construct 在其之中，一个module相当于一个运算，必须实现forward函数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>_backend <span class="token operator">=</span> thnn_backendself<span class="token punctuation">.</span>_parameters <span class="token operator">=</span> OrderedDict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>self<span class="token punctuation">.</span>_modules <span class="token operator">=</span> OrderedDict<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>Conv2d也是nn.Module的子类，也有8个OrderedDict，其中_modules是空的，因为没有子模块，而_parameters里面有着Conv2d的参数 weight 和 bias</p><p>代码中self.conv2 = nn.Conv2d 的执行会调用到module.py中nn.Module的setattr函数，在函数中依次用isinstance方法来判断类型，然后存储到相应的OrderedDict中    </p><h3 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h3><p>pytorch里面有三个重要容器 nn.Sequential 按顺序包装module  nn.ModuleList 像List包装 nn.ModuleDict 像dict一样包装，下面是用nn.Sequential来构建LeNet</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">*</span><span class="token number">5</span><span class="token operator">*</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> classes<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Sequential 在 contain.py里面，Sequential继承自Module，在其init中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> idx<span class="token punctuation">,</span> module <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>    self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">,</span> module<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>Sequential的forward函数是</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> module <span class="token keyword">in</span> self<span class="token punctuation">.</span>_modules<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">input</span> <span class="token operator">=</span> module<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token builtin">input</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>上面这样的Sequential每个子网络是用数字来命名的，如果想要自定义名字 那么就要用上OrderedDict</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>    <span class="token string">'conv1'</span> <span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token string">'relu1'</span> <span class="token punctuation">:</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ModuleList的三个方法append 在后面加网络层，extend 拼接两个ModuleList  insert 指定在ModuleList中插入</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linears <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> linear <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>linears<span class="token punctuation">)</span><span class="token punctuation">:</span>            x <span class="token operator">=</span> linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token comment"># 下面是使用ModuleDict的例子</span><span class="token keyword">class</span> <span class="token class-name">B</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>choice <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleDict<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>            <span class="token string">'conv'</span> <span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token string">'pool'</span> <span class="token punctuation">:</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>activations <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleDict<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>            <span class="token string">'relu'</span> <span class="token punctuation">:</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token string">'prelu'</span> <span class="token punctuation">:</span> nn<span class="token punctuation">.</span>PReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> choice<span class="token punctuation">,</span> act<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>choices<span class="token punctuation">[</span>choice<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>activations<span class="token punctuation">[</span>act<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>torchvision.models.AlexNet中有AlexNet网络的构建</p><p>PS：<a href="https://blog.csdn.net/manmanking/article/details/104830822">关于ReLU函数里面的inplace参数的设置</a></p><h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><ul><li><p>1d 2d 3d 卷积</p><p>一般情况下，卷积核在几个维度上滑动就是几维卷积</p></li><li><p>卷积 nn.Conv2d</p><p>nn.Conv2d是对多个二维信号进行二维卷积</p><p>in_channels 输入通道数，out_channels 输出通道数，等价于卷积核的个数</p><p>kernel_size 卷积核尺寸   stride 步长   padding 填充个数   dilation 空洞卷积大小</p><p><strong>空洞卷积 就是带孔的卷积，比如5 * 5的卷积核 带孔的话 可能就是1, 1; 1, 3; 1, 5; 3, 1;3, 3; 3, 5; 5, 1;5, 3;5, 5有值</strong></p><p>groups 分组卷积设置 分组卷积 就是分不同部分独立进行卷积,  bias 偏置</p><p><strong>尺寸计算：</strong></p><script type="math/tex; mode=display">out_{size} = \frac{In_{size} - kernel_{size}}{stride} + 1 \\H_{out} = \lfloor\frac{H_{in} + 2 \times padding[0] - dilation[0] \times (kernel\_size[0] - 1 )  - 1}{stride[0]} + 1 \rfloor</script><p>下面是一个例子：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">img  <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path_img<span class="token punctuation">)</span><span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>img_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transfomrs<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>img_tensor <span class="token operator">=</span> img_transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span>img_tensor<span class="token punctuation">.</span>unsqueeze_<span class="token punctuation">(</span>dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>flag <span class="token operator">=</span> <span class="token number">1</span><span class="token keyword">if</span> flag<span class="token punctuation">:</span>    conv_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>    <span class="token comment"># 卷积核的shape是1, 3, 3, 3</span>    <span class="token comment"># 第一个1是输出通道数，第一个3是输出通道数</span>    <span class="token comment"># 最后两个3是二维卷积核的尺寸</span>    nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_normal_<span class="token punctuation">(</span>conv_layer<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">)</span>    img_conv <span class="token operator">=</span> conv_layer<span class="token punctuation">(</span>img_tensor<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下面的图就是卷积过程</p><p><img src="https://z3.ax1x.com/2021/09/15/4ETs5F.png" alt="4ETs5F.png"></p></li><li><p>转置卷积  nn.ConvTranspose</p><p>又称为反卷积Deconvolution和部分跨越卷积Fractionally-strided Convolution 用于对图像进行上采样</p><p>有个通病就是棋盘效应</p></li></ul><h3 id="池化、线性、激活函数层"><a href="#池化、线性、激活函数层" class="headerlink" title="池化、线性、激活函数层"></a>池化、线性、激活函数层</h3><p>nn.MaxPool2d 对二维信号 进行最大值池化</p><ul><li><p>kernel_size 池化核尺寸</p></li><li><p>stride 步长</p></li><li><p>padding 填充个数</p></li><li><p>return_indices 记录池化像素索引 就是记录取的最大值对应的索引</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 就是保证不重叠</span><span class="token comment"># nn.MaxUnpool2d 对二维信号进行最大值池化上采样</span>img_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>high <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span> size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>maxpool_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> return_indices<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>img_pool<span class="token punctuation">,</span> indices <span class="token operator">=</span> maxpool_layer<span class="token punctuation">(</span>img_tensor<span class="token punctuation">)</span>img_reconstruct <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>img_pool<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>maxunpool_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxUnpool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>img_unpool <span class="token operator">=</span> maxunpool_layer<span class="token punctuation">(</span>img_reconstruct<span class="token punctuation">,</span> indices<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><script type="math/tex; mode=display">input = [1, 2, 3], \quad shape = (1, 3) \\W_0 = \begin{pmatrix}1 & 1 & 1\\2 & 2 & 2\\3 & 3 & 3\\4 & 4 & 4\\\end{pmatrix} \\Hidden = Input * W_0^T = [6, 12, 18, 24]</script></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>linear_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>linear_layer<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span> <span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>linear_layer<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">)</span>output <span class="token operator">=</span> linear_layer<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="搭建LeNet识别手写数字"><a href="#搭建LeNet识别手写数字" class="headerlink" title="搭建LeNet识别手写数字"></a>搭建LeNet识别手写数字</h3><p><a href="yann.lecun.com/exdb/mnist">MNIST数据集官网</a></p><p><a href="https://blog.csdn.net/panrenlong/article/details/81736754">读取MNIST数据集的方法文章1</a><br><a href="https://www.cnblogs.com/emanlee/p/12391308.html">读取MNIST数据集的方法文章2</a></p><p><strong>看官网给的数据格式，idx3的前面4个int不是数据，idx1的前面2个int不是数据</strong></p><p>struct.unpack(‘&gt;IIII’)  是使用大端法来读取4个int32</p><p>对于idx1的文件 开头用’&gt;II’ 读就OK了</p><p>struct.unpack(‘&gt;784B’)  是使用大端法来读取784个unsigned byte</p><p>我代码改了一下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> struct<span class="token keyword">def</span> <span class="token function">decode_idx3</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>bin_data <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>    _<span class="token punctuation">,</span> nums<span class="token punctuation">,</span> rows<span class="token punctuation">,</span> cols <span class="token operator">=</span> struct<span class="token punctuation">.</span>unpack_from<span class="token punctuation">(</span><span class="token string">'>IIII'</span><span class="token punctuation">,</span> bin_data<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>    fmt <span class="token operator">=</span> <span class="token string">'>'</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>nums <span class="token operator">*</span> rows <span class="token operator">*</span> cols<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'B'</span>    <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>struct<span class="token punctuation">.</span>unpack_from<span class="token punctuation">(</span>fmt<span class="token punctuation">,</span> bin_data<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> rows<span class="token punctuation">,</span> cols<span class="token punctuation">)</span>  train_image <span class="token operator">=</span> decode_idx3<span class="token punctuation">(</span>train_image_path<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>train_image<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cmap <span class="token operator">=</span> <span class="token string">'grey'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>PS：虽然这个跟前面的内容没啥关系</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">set_seed</span><span class="token punctuation">(</span>seed <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>PS2 : 我在<a href="github.com/activatedgeek/LeNet-5/blob/master/run.py">链接</a>中发现了visdom这个库</p><p><strong>下面是LeNet的代码： </strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">LeNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> classes<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>LeNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>            <span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>            <span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>            <span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>            <span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>            <span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            <span class="token comment"># 这里是 16 * 5 * 5的原因是 10 * 10 * 16 downsample后成5 * 5 * 16</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>            <span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>            <span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>            <span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>            <span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> classes<span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment"># 这里将[1, 16, 5, 5]的tensor转换成了[1, 400]的tensor</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>要注意的是MNIST官网里面的数据集是28 <em> 28的 而LeNet的输入要求是32 </em> 32</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 数据集的定义</span><span class="token keyword">class</span> <span class="token class-name">MNIST</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">,</span> label<span class="token punctuation">,</span> transform<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data        self<span class="token punctuation">.</span>label <span class="token operator">=</span> label        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> self<span class="token punctuation">.</span>label<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'shape incorrect'</span>            <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        data <span class="token operator">=</span> Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        label <span class="token operator">=</span> self<span class="token punctuation">.</span>label<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        data <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>        <span class="token keyword">return</span> data<span class="token punctuation">,</span> label        <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>下面是训练前的操作</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">net <span class="token operator">=</span> LeNet<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transformstransform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>train_data <span class="token operator">=</span> MNIST<span class="token punctuation">(</span>train_image<span class="token punctuation">,</span> train_label<span class="token punctuation">,</span> transform<span class="token punctuation">)</span> test_data <span class="token operator">=</span> MNIST<span class="token punctuation">(</span>test_image<span class="token punctuation">,</span> test_label<span class="token punctuation">,</span> transform<span class="token punctuation">)</span>data_train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>data_test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optimcriterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>trAin</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss_list<span class="token punctuation">,</span> batch_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>tqdm<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span>data_train_loader<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            output <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>            labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>            <span class="token comment">#if i % 10 == 0:</span>            <span class="token comment">#    print('Train - Epoch %d, Batch: %d, Loss: %f' % (epoch, i, loss.detach().cpu().item()))</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>teSt</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    total_correct <span class="token operator">=</span> <span class="token number">0</span>    avg_loss <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>tqdm<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span>data_test_loader<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>        avg_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        pred <span class="token operator">=</span> output<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        total_correct <span class="token operator">+=</span> pred<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>view_as<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    avg_loss <span class="token operator">/=</span> <span class="token number">10000</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test Avg. Loss: %f, Accuracy: %f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>avg_loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span>total_correct<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>训练出来的准确率是98.5% 我用自己在mspaint手写进行测试 准确率并不高，</p><p>注意 mspaint手写数字之后一定要改成 黑底白字</p><h5 id="pytorch中-softmax-logsoftmax-nllloss-crossentropyloss的区别"><a href="#pytorch中-softmax-logsoftmax-nllloss-crossentropyloss的区别" class="headerlink" title="pytorch中 softmax logsoftmax nllloss crossentropyloss的区别"></a>pytorch中 softmax logsoftmax nllloss crossentropyloss的区别</h5><p><a href="https://blog.csdn.net/qq_28418387/article/details/95918829">参考链接</a>. 里面给的例子非常好</p><script type="math/tex; mode=display">softmax(x_i) = \frac{exp(x_i)}{\sum_j exp(x_j)} \\logsoftmax(x_i) = log(\frac{exp(x_i)}{\sum_j exp(x_j)})</script><p>crossentropyloss 可以看作是 softmax + log + NLLLoss</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> pytorch </tag>
            
            <tag> LeNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习 Part I</title>
      <link href="2021/07/16/pytorch%20study%201/"/>
      <url>2021/07/16/pytorch%20study%201/</url>
      
        <content type="html"><![CDATA[<h3 id="张量的拼接"><a href="#张量的拼接" class="headerlink" title="张量的拼接"></a>张量的拼接</h3><p>torch.cat  将张量按维度dim进行拼接，不会扩张张量的维度，torch.stack  在新创建的维度dim上进行拼接</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">t1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>t2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>t3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>t1<span class="token punctuation">,</span> t2<span class="token punctuation">]</span><span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>t4 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>t3<span class="token punctuation">,</span> t4<span class="token punctuation">]</span><span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># t3 变成 [1, 2, 3, 4, 5, 6]</span><span class="token comment"># t4 变成 IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1) 因为原来的t1 t2都是维度1 如果竖着叠 就变成维度2了</span>t5 <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>t6 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>t5<span class="token punctuation">,</span> t5<span class="token punctuation">]</span><span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token comment">#在第0维度拼接 所以是 2 + 2 = 4</span>t7 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>t5<span class="token punctuation">,</span> t5<span class="token punctuation">]</span><span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment">#t6 变成 torch.ones((4, 3))</span><span class="token comment">#t7 变成 torch.ones((2, 6))</span>t8 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>t5<span class="token punctuation">,</span> t5<span class="token punctuation">,</span> t5<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#生成的维度就是(2, 9)</span><span class="token comment"># 对于stack</span>t <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>t_stack <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>t<span class="token punctuation">,</span> t<span class="token punctuation">]</span><span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token comment">#那么相当于[2, 3, 1] 和 [2, 3, 1] 按第二维度进行拼接，拼接的结果是[2, 3, 2]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="张量的切分"><a href="#张量的切分" class="headerlink" title="张量的切分"></a>张量的切分</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#torch.chunk(input, chunks, dim = 0) 按dim进行平均切分，返回张量列表，若不能整除，最后一份张量小于其他张量 chunks是要切分的份数 dim要切分的维度</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>list_of_tensors <span class="token operator">=</span> torch<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span>a<span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> chunks <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">for</span> idx<span class="token punctuation">,</span> t <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>list_of_tensors<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"第&#123;&#125;个张量 &#123;&#125;,shape is &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> t<span class="token punctuation">,</span> t<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#第1个张量 tensor([[1., 1., 1.],</span><span class="token comment">#        [1., 1., 1.]]),shape is torch.Size([2, 3])</span><span class="token comment">#第2个张量 tensor([[1., 1.],</span><span class="token comment">#        [1., 1.]]),shape is torch.Size([2, 2])</span>torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> split_size_or_sections<span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token comment">#功能是将张量按维度dim进行切分  返回值  张量列表</span><span class="token comment"># split_size_or_sections 为int 表示每一份的长度， 为list时 按list元素切分</span>list_of_tensors  <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>t<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># 切出来的 长度是 2, 2, 1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="张量的索引"><a href="#张量的索引" class="headerlink" title="张量的索引"></a>张量的索引</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> dim<span class="token punctuation">,</span> index<span class="token punctuation">,</span> out<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token comment"># 在维度dim上，按index索引数据 返回值：依index索引数据拼接的张量</span>t <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>t_select <span class="token operator">=</span> torch<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>t<span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> index <span class="token operator">=</span> idx<span class="token punctuation">)</span><span class="token comment"># t 随机出来的是 [[4, 5, 0], [5, 7, 1], [2, 5, 8]]</span><span class="token comment"># t_select 出来的是 [[4, 5, 8], [2, 5, 8]] 按dim 0进行索引的</span><span class="token comment">#！！！ 注意 index 的数据类型必须是torch.long</span>torch<span class="token punctuation">.</span>masked_select<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> mask<span class="token punctuation">,</span> out <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token comment">#功能：按mask中的True进行索引 返回值：一维张量，mask是与input同形状的布尔类型张量</span>t <span class="token operator">=</span> torch<span class="token punctuation">.</span>randin<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>mask <span class="token operator">=</span> t<span class="token punctuation">.</span>ge<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>t_select <span class="token operator">=</span> torch<span class="token punctuation">.</span>masked_select<span class="token punctuation">(</span>t<span class="token punctuation">,</span> mask<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="张量的变换"><a href="#张量的变换" class="headerlink" title="张量的变换"></a>张量的变换</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 当张量在内存中是连续时，新张量与input共享数据内存</span>t <span class="token operator">=</span> torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span>t_reshape <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>t<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#这句话等价于 t_reshape = torch.reshape(t, (-1, 4))</span><span class="token comment">#查看内存地址 id(t.data)</span>torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> dim0<span class="token punctuation">,</span> dim1<span class="token punctuation">)</span> <span class="token comment">#交换张量的两个维度</span>torch<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#等价于 torch.transpose(input, 0, 1)</span>torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span> <span class="token comment">#压缩长度为1的维度 dim若为None 移除所有长度为1的轴，也可指定维度</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> dim<span class="token punctuation">,</span> out <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span> <span class="token comment">#依据dim扩展维度</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="张量的数学运算"><a href="#张量的数学运算" class="headerlink" title="张量的数学运算"></a>张量的数学运算</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> alpha <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> other<span class="token punctuation">,</span> out <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span> <span class="token comment">#功能 逐元素计算input + alpha * other</span>torch<span class="token punctuation">.</span>addcmul<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> value <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">,</span> out <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token comment">#out_i = input_i + value * tensor1_i * tensor2_i</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><ul><li>确定模型 Model: $y = wx + b$</li><li><p>选择损失函数 MSE : $\frac{1}{m}\sum_{i = 1}^m (y_i - \hat{y_i})^2$</p></li><li><p>求解梯度并更新$w, b$  $ w = w - LR <em> w.grad \ \ \ b = b - LR </em> w.grad$</p></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">lr <span class="token operator">=</span> <span class="token number">0.1</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">10</span>y <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> x <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">5</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>w <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">for</span> iteration <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    wx <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>w<span class="token punctuation">,</span> x<span class="token punctuation">)</span>    y_pred <span class="token operator">=</span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>wx<span class="token punctuation">,</span> b<span class="token punctuation">)</span>    loss <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span>y <span class="token operator">-</span> y_pred<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    b<span class="token punctuation">.</span>data<span class="token punctuation">.</span>sub_<span class="token punctuation">(</span>lr <span class="token operator">*</span> b<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>    w<span class="token punctuation">.</span>data<span class="token punctuation">.</span>sub_<span class="token punctuation">(</span>lr <span class="token operator">*</span> w<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>    <span class="token keyword">if</span> iteration <span class="token operator">%</span> <span class="token number">20</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_pred<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"r-"</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token string">"Loss=%.4f"</span> <span class="token operator">%</span> loss<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fontdict<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'size'</span> <span class="token punctuation">:</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token string">'color'</span> <span class="token punctuation">:</span> <span class="token string">'red'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token number">1.5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Iteration: &#123;&#125;\nw: &#123;&#125; b: &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>iteration<span class="token punctuation">,</span> w<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> b<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>pause<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> loss<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">1</span><span class="token punctuation">:</span>            <span class="token keyword">break</span><span class="token comment"># 把lr从0.1 改成 0.01 会稳定一些 loss 一直降，而lr 为 0.1时 loss时降时升</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h3><p>计算图时用来描述运算的有向无环图</p><p>结点表示数据，如向量，矩阵，张量</p><p>边表示运算，如加减乘除卷积等</p><p>用计算图表示： $ y = (x + w) * (x + 1)$ 令中间结点是$a = x + w, b = w + 1, y = a + b$</p><p><img src="https://z3.ax1x.com/2021/07/14/WVAvGQ.png" alt="WVAvGQ.png"></p><p>作用使得梯度计算容易 当$w = 1, x = 2$时</p><script type="math/tex; mode=display">\frac{\partial y}{\partial w} = \frac{\partial y}{\partial a}\frac{\partial a}{\partial w} + \frac{\partial y}{\partial b}\frac{\partial b}{\partial w} \\\frac{\partial y}{\partial a} = b = w + 1, \frac{\partial y}{\partial b} = a = x + w,\frac{\partial a}{\partial w} = 1, \frac{\partial b}{\partial w} = 1 \\\therefore \frac{\partial y}{\partial w} = (w + 1) + (w + x) = 5</script><p>tensor 里面的is_leaf 指示张量是否为叶子结点，非叶子结点 在反向传播结束后会被释放掉</p><p>grad_fn 记录创建该张量时所用的方法 - 函数</p><h3 id="动态图"><a href="#动态图" class="headerlink" title="动态图"></a>动态图</h3><p>动态图 运算与搭建<strong>同时</strong>进行，像自由行；  静态图 先搭建图，后运算，像跟团旅游，优点是高效，缺点是不灵活</p><h3 id="autograd"><a href="#autograd" class="headerlink" title="autograd"></a>autograd</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>tensors<span class="token punctuation">,</span> grad_tensors<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> retain_graph<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> create_graph<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment">#功能是 自动求取梯度 tensors是用于求导的张量，retain_graph 保存计算图 create_graph 创建导数计算图，用于高阶求导， grad_tensors 多梯度权重</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>之前在线性回归里面的 $y.backward(…)$ 实际上是调用了$torch.autograd.backward(…)$</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">w <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>w<span class="token punctuation">,</span> x<span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>w<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>y0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>y1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>y0<span class="token punctuation">,</span> y1<span class="token punctuation">]</span><span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>grad_tensors <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>gradient<span class="token operator">=</span>grad_tensors<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token comment"># 5 + 2 * 2 = 9</span>torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> grad_outputs <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> retain_graph <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> create_graph <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token comment"># 功能 求取梯度</span><span class="token comment"># 下面进行二阶求导</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>grad_1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>y<span class="token punctuation">,</span> x<span class="token punctuation">,</span> create_graph <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>grad_1<span class="token punctuation">)</span>grad_2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>grad_1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>grad_2<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>关于autograd 要注意一下：</p><ul><li>梯度不自动清零</li><li>依赖于叶子结点的结点， requires_grad 默认为 True</li><li>叶子结点不可执行 in-place</li></ul><h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><ul><li>线性回归   $y = WX + b$</li><li>对数几率回归 $ln\frac{y}{1-y} = WX + b \Rightarrow y = \frac{1}{1 + e^{-(WX + b)}}$</li><li>对数回归  $lny = WX + b$</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>sample_nums <span class="token operator">=</span> <span class="token number">100</span>mean_value <span class="token operator">=</span> <span class="token number">1.7</span>bias <span class="token operator">=</span> <span class="token number">1</span>n_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>sample_nums<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>x0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>mean_value <span class="token operator">*</span> n_data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> biasy0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>sample_nums<span class="token punctuation">)</span>x1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token operator">-</span>mean_value <span class="token operator">*</span> n_data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> biasy1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>sample_nums<span class="token punctuation">)</span>train_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>x0<span class="token punctuation">,</span> x1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>train_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>y0<span class="token punctuation">,</span> y1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">LR</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>LR<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x    lr_net <span class="token operator">=</span> LR<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>lr <span class="token operator">=</span> <span class="token number">0.01</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>lr_net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr <span class="token operator">=</span> lr<span class="token punctuation">,</span> momentum <span class="token operator">=</span> <span class="token number">0.9</span><span class="token punctuation">)</span><span class="token keyword">for</span> iteration <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    y_pred <span class="token operator">=</span> lr_net<span class="token punctuation">(</span>train_x<span class="token punctuation">)</span>    loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>y_pred<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> train_y<span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> iteration <span class="token operator">%</span> <span class="token number">20</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        mask <span class="token operator">=</span> y_pred<span class="token punctuation">.</span>ge<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>        correct <span class="token operator">=</span> <span class="token punctuation">(</span>mask <span class="token operator">==</span> train_y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        acc <span class="token operator">=</span> correct<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> train_y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x0<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x0<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">'class 0'</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x1<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x1<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'b'</span><span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">'class 1'</span><span class="token punctuation">)</span>        w0<span class="token punctuation">,</span> w1 <span class="token operator">=</span> lr_net<span class="token punctuation">.</span>features<span class="token punctuation">.</span>weight<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        w0<span class="token punctuation">,</span> w1 <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>w0<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span>w1<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        plot_b <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>lr_net<span class="token punctuation">.</span>features<span class="token punctuation">.</span>bias<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        plot_x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>        plot_y <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token operator">-</span>w0 <span class="token operator">*</span> plot_x <span class="token operator">-</span> plot_b<span class="token punctuation">)</span> <span class="token operator">/</span> w1        plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>plot_x<span class="token punctuation">,</span> plot_y<span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'loss=%.4f'</span> <span class="token operator">%</span> loss<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fontdict<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'size'</span> <span class="token punctuation">:</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token string">'color'</span> <span class="token punctuation">:</span> <span class="token string">'red'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Iteration: &#123;&#125;\nw0:&#123;:.2f&#125; w1:&#123;:2f&#125; b: &#123;:.2f&#125; accuracy:&#123;:.2%&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>iteration<span class="token punctuation">,</span> w0<span class="token punctuation">,</span> w1<span class="token punctuation">,</span> plot_b<span class="token punctuation">,</span> acc<span class="token punctuation">)</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>pause<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> acc <span class="token operator">></span> <span class="token number">0.99</span><span class="token punctuation">:</span>            <span class="token keyword">break</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="人民币二分类"><a href="#人民币二分类" class="headerlink" title="人民币二分类"></a>人民币二分类</h3><p>DataLoader 有 Sampler 功能是生成索引和 Dataset 是根据索引生成数据和标签两个模块</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> shuffle <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> sampler <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> batch_sampler <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> num_workers <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> collate_fn <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> pin_memory <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> drop_last <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> timeout <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> worker_init_fn <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> multiprocessing_context <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token comment">#为啥我要把这些参数打出来呢？？？ 我是个傻逼</span><span class="token comment">#功能 构建可迭代的数据装载器</span><span class="token comment">#drop_last 当样本数不能被batch_size 整除时 是否舍弃最后一批数据</span><span class="token comment">#shuffle 每个epoch是否乱序</span><span class="token comment">#样本87 batchsize 8</span><span class="token comment"># 1 epoch 10 iteration drop_last = True</span><span class="token comment"># 1 epoch 11 iteration drop_last = False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="数据预处理transforms模块机制"><a href="#数据预处理transforms模块机制" class="headerlink" title="数据预处理transforms模块机制"></a>数据预处理transforms模块机制</h3><p>transforms.Normalize 功能是 逐channel地对图像进行标准化</p><script type="math/tex; mode=display">output = (input - mean) / std</script><h3 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h3><p><strong>裁剪</strong></p><ul><li><p>transforms.CenterCrop 从图像中心裁剪图片 </p><ul><li>size 裁剪出来的尺寸</li></ul></li><li><p>transforms.RandomCrop 从图片中随机裁剪出尺寸为size的图片</p><ul><li>size 所需裁剪图片尺寸</li><li>padding 设置填充大小，为a时，上下左右均填充a个像素，$(a, b)$上下a, 左右b，$(a, b, c, d)$ 左，上，右，下分别填充a，b，c，d</li><li>padding_mode 填充模式 4种<ul><li>constant 像素值由fill设定</li><li>edge 像素值由图像边缘像素决定</li><li>reflect 镜像填充，最后一个像素不镜像 $[1, 2, 3, 4] \rightarrow [3, 2, 1, 2, 3, 4, 3, 2]$</li><li>symmetric 镜像填充 最后一个像素镜像 $[1,2,3,4] \rightarrow [2, 1, 1, 2, 3, 4, 4, 3]$</li></ul></li></ul></li><li><p>transforms.RandomResizedCrop 随机大小、长宽比裁剪图片</p><ul><li><p>size 所需裁剪图片尺寸</p></li><li><p>scale 随机裁剪面积比例 默认 0.08到1</p></li><li><p>ratio 随机长宽比 默认 $\frac{3}{4}，\frac{4}{3}$</p></li><li><p>interpolation 插值方法</p><ul><li>NEAREST</li><li>BILINEAR</li><li>BICUBIC</li></ul><p>操作就是首先在0.08到1之间随机选取一个比例，然后根据ratio的长宽比去设定了图像的长和宽，然后去裁剪出来一个图片，然后再resize设定的size</p></li></ul></li><li><p>transform.FiveCrop 在图像上下左右以及中心裁剪出尺寸为size的5张图片，TenCrop对这5张图片进行水平或者垂直镜像获得10张图片 vertical_flip 是否垂直翻转</p></li></ul><p><strong>翻转</strong></p><ul><li>RandomHorizontalFlip，RandomVerticalFlip 依概率水平或垂直翻转图片</li><li>RandomRotation 随机旋转图片<ul><li>degrees 旋转角度 当为a时，在$(-a, a)$之间选择旋转角度 当为$(a, b)$时，在这个范围内选择</li><li>resample 重采样方法</li><li>expand 是否扩大图片 以保持原图信息，因为旋转可能会让图片一部分超出原来图片边界</li><li>center 设置旋转点</li></ul></li></ul><p><strong>其它</strong></p><ul><li><p>transform.Pad 对图片边缘进行填充</p></li><li><p>transform.ColorJitter 调整亮度、对比度、饱和度和色相</p><ul><li>brightness 亮度调整因子 当为a时 从$[max(0, 1-a), 1+ a]$中选择 当为$(a,b)$时从$[a,b]$中选择</li><li>contrast 对比度参数 同brightness</li><li>saturation 饱和度参数，同brightness</li><li>hue 色相参数，当为a时 从$[-a, a]$ 中选择参数</li></ul></li><li><p>RandomGrayscale 依概率将图片转换为灰度图，通道数只能是1或3</p></li><li><p>RandomAffine 对图像进行仿射变换，仿射变换是二维线性变换，由五种基本原子变换构成，分别是旋转、平移、缩放、错切和翻转 — 感觉这个函数比较高级</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">transforms<span class="token punctuation">.</span>RandomAffine<span class="token punctuation">(</span>degrees <span class="token operator">=</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token comment">#在-30 到 30之间随机选一个度数进行旋转</span>transforms<span class="token punctuation">.</span>RandomAffine<span class="token punctuation">(</span>degrees <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> translate <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fillcolor<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>transforms<span class="token punctuation">.</span>RandomAffine<span class="token punctuation">(</span>degrees <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> shear <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">45</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>RandomErasing 功能 对图像进行随机遮挡，与之前的不同，这个是对张量进行操作的</p><p>有一篇文献 Random Erasing Data Augmentation</p><p>论文推荐p = 1, scale = 0.02, 0.33  ratio = 0.3, 3.3  value = ‘random’</p><ul><li>p 概率值，执行该操作的概率</li><li>scale 遮挡区域的面积</li><li>ratio 遮挡区域的长宽比</li><li>value 设置遮挡区域的像素值 $(R, G, B)$ 或者 $(Gray)$</li></ul></li><li><p>transforms.Lambda  用户自定义lambda方法</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">transforms<span class="token punctuation">.</span>TenCrop<span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span> vertical_flip <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>transforms<span class="token punctuation">.</span>Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> crops <span class="token punctuation">:</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>crop<span class="token punctuation">)</span> <span class="token keyword">for</span> crop <span class="token keyword">in</span> crops<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>Transforms的操作</strong></p></li><li><p>transforms.RandomChoice 从一系列transforms方法中随机挑选一个</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">transforms<span class="token punctuation">.</span>RandomChoice<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>RandomVerticalFlip<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>transforms.RandomApply 依据概率执行一组transforms操作</p></li><li><p>transforms.RandomOrder 对一组transforms操作打乱顺序</p></li></ul><h3 id="自定义transforms"><a href="#自定义transforms" class="headerlink" title="自定义transforms"></a>自定义transforms</h3><p>仅接受一个参数，返回一个参数 注意transform在Compose里面调用的代码：</p><p>注意上下游的输出与输入</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Compose</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> t <span class="token keyword">in</span> self<span class="token punctuation">.</span>transforms<span class="token punctuation">:</span>            img <span class="token operator">=</span> t<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        <span class="token keyword">return</span> img<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>椒盐噪声</strong></p><p>又称为脉冲噪声，是一种随机出现的白点或者黑点，白点称为盐噪声，黑色为椒噪声</p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Deep Reinforcement Learning</title>
      <link href="2021/07/05/cs230/"/>
      <url>2021/07/05/cs230/</url>
      
        <content type="html"><![CDATA[<h2 id="Lecture-9-Deep-Reinforcement-Learning"><a href="#Lecture-9-Deep-Reinforcement-Learning" class="headerlink" title="Lecture 9 Deep Reinforcement Learning"></a>Lecture 9 Deep Reinforcement Learning</h2><p><a href="https://www.bilibili.com/video/BV1p7411Y7M8?p=9">视频链接</a></p><p>cs230 先看这个lecture 为 Project2 服务</p><p><strong>deep neural networks have been shown to be very good function approximators</strong></p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>How would you solve Go with classic supervised learning?</p><p>一种是输入是棋盘状态 标签是专家给出的下一步的意见  缺点是需要大量数据</p><script type="math/tex; mode=display">\#states = 3^{19\times 19} \approx 10^{170}</script><p>还有一个缺点，专家走的一步不一定是好的</p><p>介绍了3个RL应用： 机器人， 游戏， 广告</p><h3 id="Recycling-is-good-an-introduction-to-RL"><a href="#Recycling-is-good-an-introduction-to-RL" class="headerlink" title="Recycling is good: an introduction to RL"></a>Recycling is good: an introduction to RL</h3><p><img src="https://z3.ax1x.com/2021/07/04/RfW9Gq.png" alt="举了个例子"></p><p>只能走3步，如果discount是0.1 那么一开始往左走是最好的</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#todo 用Q-learning来看Q-learning 是否收敛于V*</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npACTIONS <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'left'</span><span class="token punctuation">,</span> <span class="token string">'right'</span><span class="token punctuation">]</span>N_STATES <span class="token operator">=</span> <span class="token number">5</span>EPSILON <span class="token operator">=</span> <span class="token number">0.9</span>ALPHA <span class="token operator">=</span> <span class="token number">0.1</span>GAMMA <span class="token operator">=</span> <span class="token number">0.9</span>points <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span>MAX_EPISODE <span class="token operator">=</span> <span class="token number">100000</span><span class="token keyword">def</span> <span class="token function">create_qtable</span><span class="token punctuation">(</span>n_states<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>n_states<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> columns <span class="token operator">=</span> ACTIONS<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">choose_action</span><span class="token punctuation">(</span>state<span class="token punctuation">,</span> qtable<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> state <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token string">'right'</span>    <span class="token keyword">if</span> state <span class="token operator">==</span> <span class="token number">5</span><span class="token punctuation">:</span><span class="token comment">#这里改为 == 4</span>        <span class="token keyword">return</span> <span class="token string">'left'</span>    actions <span class="token operator">=</span> qtable<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>state<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    <span class="token keyword">if</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> EPSILON <span class="token keyword">or</span> <span class="token punctuation">(</span>actions<span class="token punctuation">.</span><span class="token builtin">all</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        action <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>ACTIONS<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        action <span class="token operator">=</span> actions<span class="token punctuation">.</span>idxmax<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> action<span class="token keyword">def</span> <span class="token function">step</span><span class="token punctuation">(</span>state<span class="token punctuation">,</span> action<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> action <span class="token operator">==</span> <span class="token string">'left'</span><span class="token punctuation">:</span>        next_state <span class="token operator">=</span> state <span class="token operator">-</span> <span class="token number">1</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        next_state <span class="token operator">=</span> state <span class="token operator">+</span> <span class="token number">1</span>    reward <span class="token operator">=</span> points<span class="token punctuation">[</span>next_state<span class="token punctuation">]</span>    <span class="token keyword">return</span> next_state<span class="token punctuation">,</span> reward<span class="token keyword">def</span> <span class="token function">rl</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    table <span class="token operator">=</span> create_qtable<span class="token punctuation">(</span>N_STATES<span class="token punctuation">)</span>    <span class="token keyword">for</span> episode <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>MAX_EPISODE<span class="token punctuation">)</span><span class="token punctuation">:</span>        S<span class="token punctuation">,</span> step_cnt <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span>        <span class="token keyword">while</span> step_cnt <span class="token operator">&lt;</span> <span class="token number">3</span><span class="token punctuation">:</span>            action <span class="token operator">=</span> choose_action<span class="token punctuation">(</span>S<span class="token punctuation">,</span> table<span class="token punctuation">)</span>            next_state<span class="token punctuation">,</span> reward <span class="token operator">=</span> step<span class="token punctuation">(</span>S<span class="token punctuation">,</span> action<span class="token punctuation">)</span>            q_predict <span class="token operator">=</span> table<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>S<span class="token punctuation">,</span> action<span class="token punctuation">]</span>            <span class="token comment">#这里加上if next_state == 4 or 0 就怎么怎么样</span>            q_target <span class="token operator">=</span> reward <span class="token operator">+</span> GAMMA <span class="token operator">*</span> table<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>S<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment">#这个地方应改为q_target = reward + GAMMA * table.iloc[next_state, :].max()</span>            table<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>S<span class="token punctuation">,</span> action<span class="token punctuation">]</span> <span class="token operator">+=</span> ALPHA <span class="token operator">*</span> <span class="token punctuation">(</span>q_target <span class="token operator">-</span> q_predict<span class="token punctuation">)</span>            step_cnt <span class="token operator">+=</span> <span class="token number">1</span>            S <span class="token operator">=</span> next_state        <span class="token keyword">print</span><span class="token punctuation">(</span>table<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    rl<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面这个代码EPISODE 100000</p><p>运行完后发现Q表收敛了</p><div class="table-container"><table><thead><tr><th></th><th>left</th><th>right</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>20</td><td>18</td></tr><tr><td>2</td><td>9</td><td>10</td></tr><tr><td>3</td><td>90</td><td>100</td></tr><tr><td>4</td><td>0</td><td>0</td></tr></tbody></table></div><p>对于这个表 0，right为0的原因是 算法有问题，<span style='color:red;font-weight:bold'>p现实的Q是目标状态的内容，而非原来状态的</span></p><p>改了之后 运行完的Q表内容为<br>|      | left | right |<br>| —— | —— | ——- |<br>| 0    | 0    | 9.473684     |<br>| 1    | 10.526316   | 9.000000    |<br>| 2    | 9.473684    | 10.000000    |<br>| 3    | 9.000000   | 10.000000  |<br>| 4    | 0    | 0     |</p><p>4 left 不应该为0， 发现代码又一处有问题choose_action里面 state == 5 没有这个state，应该改为state == 4</p><p>但是4 left 还是为0 原因是1走3步走到4 程序就停止了 没有机会再走了。 不过这个Q表不对啊</p><p>按Q表的话 最佳路线是左 右 左 总收益是 2 + 0 + 0.81* 2</p><p>但是存在右 右 右的路线 总收益是 0 + 0.9 + 8.1</p><p><span style="color:red;font-weight">我这个算法没有终止状态，这样就会出问题</span></p><p>如果每个episode开始S的取值为np.random.randint(0, 4) 4, left有值了 但是取值并不是我们想要的</p><p>如果设置终止状态在state == 4 Q表还是那个Q表，如果设置终止状态为0 或者 4 Q表就变为</p><div class="table-container"><table><thead><tr><th></th><th>left</th><th>right</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>2</td><td>9</td></tr><tr><td>2</td><td>8.1</td><td>10</td></tr><tr><td>3</td><td>9.0</td><td>10</td></tr><tr><td>4</td><td>0</td><td>0</td></tr></tbody></table></div><p>还是有个地方不对  2，left 为8.1 就不对，这个地方向左走 最多能获得的收益是1.8</p><p><span style="color:red;font-weight:bold">当有限步数的时候Q表会有问题，按Q表走可能不会是最优选择</span></p><p><strong>Bellman equation satisfied by the optimal Q-table</strong></p><h3 id="Deep-Q-Learning"><a href="#Deep-Q-Learning" class="headerlink" title="Deep Q-Learning"></a>Deep Q-Learning</h3><p>将Q table转变为Q function 就是从Q-Learning变为Deep Q-Learning</p><p><img src="https://z3.ax1x.com/2021/07/04/Rf5n0O.png" alt="用神经网络来做function approximator"></p><p>可以将状态和行为整体作为输入，也可以更快，<strong>将状态作为输入</strong></p><p>与传统的监督学习不同的是，这个没有标签。我们应该把这个视为回归问题，因为Q score doesn’t have to be a probability between zero and one. 假如有标签$y$存在 那么</p><script type="math/tex; mode=display">L = (y - Q(s, \leftarrow))^2</script><p>那么y是什么，注意Bellman equation，我们知道最优的Q值应该满足Bellman equation</p><p>有个问题，Bellman equation取决于自身的$Q$，即等式两边都有$Q$，这意味着如果将标签设置为</p><p>$r + \gamma \times \max_{a^\prime} (Q^\prime (s^\prime, a^\prime))$ 那么在BP阶段 将在这里有一个导数</p><p>我们定义一个目标值 target value 假设是$Q(s, \leftarrow) &gt; Q(s, \rightarrow)$</p><p>随机初始化网络，然后前向传播，然后左侧Q得分大于右侧Q得分，我们的行为就是向左走</p><p>我们定义y为</p><script type="math/tex; mode=display">y = r_{\leftarrow} + \gamma \max_{a^\prime}(Q(s_{\leftarrow}^{next}, a^\prime))</script><p>It is a proxy to a good label. We hope that if we use this proxy as our label, and we learn the difference between where we are now in this proxy, we can then update the proxy get closer to the optimality. 与deep learning不同的是，<strong>label在moving！！！</strong></p><p>我们将标签定义为对我们拥有的最佳Q函数的best guess</p><p>关键问题这个网络是否会收敛到最佳Q函数呢： 有一篇论文 Convergence of Q-Learning: a simple proof</p><p><strong>还有一个问题</strong>，如果将y放到loss function中，然后要求BP，W更新了，会得到一个feedback loop使得网络不稳定，这个feedback loop没有弄明白</p><p>解决这个问题的方法是 我们的目标Q将在许多迭代中得到固定 例如100万或10万次迭代</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#试一下 用DQN来解recycling is good</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable<span class="token keyword">class</span> <span class="token class-name">DQN</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_state<span class="token punctuation">,</span> n_action<span class="token punctuation">,</span> n_hidden<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_state<span class="token punctuation">,</span> n_hidden<span class="token punctuation">)</span><span class="token punctuation">,</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_hidden<span class="token punctuation">,</span> n_hidden<span class="token punctuation">)</span><span class="token punctuation">,</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_hidden<span class="token punctuation">,</span> n_action<span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        y_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">)</span>        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">)</span>        STATES <span class="token operator">=</span> <span class="token number">5</span>GAMMA <span class="token operator">=</span> <span class="token number">0.9</span>ALPHA <span class="token operator">=</span> <span class="token number">0.1</span>EPSILON <span class="token operator">=</span> <span class="token number">0.9</span>POINTS <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span>MAX_EPISODE <span class="token operator">=</span> <span class="token number">100000</span>MOD <span class="token operator">=</span> <span class="token number">5000</span><span class="token keyword">def</span> <span class="token function">choose_action</span><span class="token punctuation">(</span>state<span class="token punctuation">,</span> dqn<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> EPSILON<span class="token punctuation">:</span>        <span class="token keyword">return</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        q_values <span class="token operator">=</span> dqn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>state<span class="token punctuation">)</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>q_values<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">step</span><span class="token punctuation">(</span>state<span class="token punctuation">,</span> action<span class="token punctuation">)</span><span class="token punctuation">:</span>    ind <span class="token operator">=</span> state<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    state<span class="token punctuation">[</span>ind<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>    ind <span class="token operator">+=</span> <span class="token number">1</span> <span class="token keyword">if</span> action <span class="token keyword">else</span> <span class="token operator">-</span><span class="token number">1</span>    state<span class="token punctuation">[</span>ind<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>    <span class="token keyword">return</span> state<span class="token punctuation">,</span> POINTS<span class="token punctuation">[</span>ind<span class="token punctuation">]</span><span class="token keyword">def</span> <span class="token function">rl</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    dqn <span class="token operator">=</span> DQN<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> episode <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>MAX_EPISODE<span class="token punctuation">)</span><span class="token punctuation">:</span>        state<span class="token punctuation">,</span> cnt <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span>        <span class="token keyword">while</span> cnt <span class="token operator">&lt;</span> <span class="token number">3</span><span class="token punctuation">:</span>            action <span class="token operator">=</span> choose_action<span class="token punctuation">(</span>state<span class="token punctuation">,</span> dqn<span class="token punctuation">)</span>            nstate<span class="token punctuation">,</span> reward <span class="token operator">=</span> step<span class="token punctuation">(</span>state<span class="token punctuation">,</span> action<span class="token punctuation">)</span>            q_predict <span class="token operator">=</span> dqn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>state<span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>            q_target <span class="token operator">=</span> dqn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>nstate<span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>episode <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> MOD <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                <span class="token keyword">print</span><span class="token punctuation">(</span>state<span class="token punctuation">,</span> nstate<span class="token punctuation">,</span> reward<span class="token punctuation">)</span>            <span class="token keyword">if</span> nstate<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">or</span> nstate<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">4</span><span class="token punctuation">:</span>                cnt <span class="token operator">=</span> <span class="token number">2</span>                q_predict<span class="token punctuation">[</span>action<span class="token punctuation">]</span> <span class="token operator">=</span> reward            <span class="token keyword">else</span><span class="token punctuation">:</span>                q_predict<span class="token punctuation">[</span>action<span class="token punctuation">]</span> <span class="token operator">=</span> reward <span class="token operator">+</span> GAMMA<span class="token operator">*</span>torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>q_target<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>            dqn<span class="token punctuation">.</span>update<span class="token punctuation">(</span>state<span class="token punctuation">,</span> q_predict<span class="token punctuation">)</span>            state <span class="token operator">=</span> nstate            cnt <span class="token operator">+=</span> <span class="token number">1</span>                    <span class="token keyword">if</span> <span class="token punctuation">(</span>episode <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> MOD <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token builtin">input</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> <span class="token string">":"</span><span class="token punctuation">,</span> dqn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token builtin">input</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-"</span> <span class="token operator">*</span> <span class="token number">70</span><span class="token punctuation">)</span>rl<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>用神经网络来代替Q表 这个网络不是很稳定 运行多次 最后生成的Q表差的有点大</p><p>举例：</p><p><img src="https://z3.ax1x.com/2021/07/05/R5r8r4.png" alt="收敛情况1"></p><p><img src="https://z3.ax1x.com/2021/07/05/R5r3MF.png" alt="收敛情况2"></p><p><img src="https://z3.ax1x.com/2021/07/05/R5rlxU.png" alt="收敛情况3"></p><p>存在两个问题：</p><p>Q1 当在中间这个格子的时候 居然是要向左走   Q2 一直向左走</p><p>比较这个版本和之前的版本 <strong>我觉得Q2的原因是可能代码中缺少actions.all() == 0</strong></p><p>发现之前的代码 因为只会走3步 那么actions.all() == 0 永远为true，也就是random walk，如果去掉这个 走三步一下就会收敛了</p><p><span style="color:red;font-weight:bold;font-size:20px">debug发现，np.random.randint(0, 1)只会生成数字0</span></p><h3 id="新的代码"><a href="#新的代码" class="headerlink" title="新的代码"></a>新的代码</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable<span class="token keyword">class</span> <span class="token class-name">DQN</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_state<span class="token punctuation">,</span> n_action<span class="token punctuation">,</span> n_hidden<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_state<span class="token punctuation">,</span> n_hidden<span class="token punctuation">)</span><span class="token punctuation">,</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_hidden<span class="token punctuation">,</span> n_hidden<span class="token punctuation">)</span><span class="token punctuation">,</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_hidden<span class="token punctuation">,</span> n_action<span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        y_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">)</span>        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">)</span>STATES <span class="token operator">=</span> <span class="token number">5</span>GAMMA <span class="token operator">=</span> <span class="token number">0.9</span>ALPHA <span class="token operator">=</span> <span class="token number">0.1</span>EPSILON <span class="token operator">=</span> <span class="token number">0.9</span>POINTS <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span>MAX_EPISODE <span class="token operator">=</span> <span class="token number">100000</span>MOD <span class="token operator">=</span> <span class="token number">5000</span><span class="token keyword">def</span> <span class="token function">choose_action</span><span class="token punctuation">(</span>state<span class="token punctuation">,</span> dqn<span class="token punctuation">)</span><span class="token punctuation">:</span>    ind <span class="token operator">=</span> state<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> EPSILON <span class="token keyword">or</span> <span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        q_values <span class="token operator">=</span> dqn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>state<span class="token punctuation">)</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>q_values<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">step</span><span class="token punctuation">(</span>state<span class="token punctuation">,</span> action<span class="token punctuation">)</span><span class="token punctuation">:</span>    ind <span class="token operator">=</span> state<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    nstate <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    ind <span class="token operator">+=</span> <span class="token number">1</span> <span class="token keyword">if</span> action <span class="token keyword">else</span> <span class="token operator">-</span><span class="token number">1</span>    nstate<span class="token punctuation">[</span>ind<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>    <span class="token keyword">return</span> nstate<span class="token punctuation">,</span> POINTS<span class="token punctuation">[</span>ind<span class="token punctuation">]</span><span class="token keyword">def</span> <span class="token function">rl</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    dqn <span class="token operator">=</span> DQN<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> episode <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>MAX_EPISODE<span class="token punctuation">)</span><span class="token punctuation">:</span>        state<span class="token punctuation">,</span> cnt <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span>        <span class="token keyword">while</span> cnt <span class="token operator">&lt;</span> <span class="token number">3</span><span class="token punctuation">:</span>            action <span class="token operator">=</span> choose_action<span class="token punctuation">(</span>state<span class="token punctuation">,</span> dqn<span class="token punctuation">)</span>            nstate<span class="token punctuation">,</span> reward <span class="token operator">=</span> step<span class="token punctuation">(</span>state<span class="token punctuation">,</span> action<span class="token punctuation">)</span>            q_predict <span class="token operator">=</span> dqn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>state<span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>            q_target <span class="token operator">=</span> dqn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>nstate<span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>episode <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> MOD <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                <span class="token keyword">print</span><span class="token punctuation">(</span>state<span class="token punctuation">,</span> nstate<span class="token punctuation">,</span> reward<span class="token punctuation">)</span>            <span class="token keyword">if</span> nstate<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">or</span> nstate<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">4</span><span class="token punctuation">:</span>                cnt <span class="token operator">=</span> <span class="token number">2</span>                q_predict<span class="token punctuation">[</span>action<span class="token punctuation">]</span> <span class="token operator">=</span> reward            <span class="token keyword">else</span><span class="token punctuation">:</span>                q_predict<span class="token punctuation">[</span>action<span class="token punctuation">]</span> <span class="token operator">=</span> reward <span class="token operator">+</span> GAMMA<span class="token operator">*</span>torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>q_target<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>            dqn<span class="token punctuation">.</span>update<span class="token punctuation">(</span>state<span class="token punctuation">,</span> q_predict<span class="token punctuation">)</span>            state <span class="token operator">=</span> nstate            cnt <span class="token operator">+=</span> <span class="token number">1</span>                    <span class="token keyword">if</span> <span class="token punctuation">(</span>episode <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> MOD <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token builtin">input</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> <span class="token string">":"</span><span class="token punctuation">,</span> dqn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token builtin">input</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-"</span> <span class="token operator">*</span> <span class="token number">70</span><span class="token punctuation">)</span>rl<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>不像单纯的Q-Learning 收敛稳定，这个会在一定范围内一直在波动</p><p>再没有出现之前 非常奇怪的收敛点了，15000episode之后 就会收敛到下面这张图附近</p><p><img src="https://z3.ax1x.com/2021/07/05/R5fsL6.png" alt="R5fsL6.png"></p><h3 id="Deep-Q-Learning-application-Breakout-Atari"><a href="#Deep-Q-Learning-application-Breakout-Atari" class="headerlink" title="Deep Q-Learning application: Breakout Atari"></a>Deep Q-Learning application: Breakout Atari</h3><p>input 图像 输出 游戏操作  存在一个问题 不知道球是在向上运动还是向下运动，解决方法 用多张图片。给定状态$S$ 计算$S$的函数$\phi(S)$ 这个give you the history of this state which is the four-sequence of four last frames.</p><p><img src="https://z3.ax1x.com/2021/07/04/RfbogH.png" alt="DQN算法"></p><p>与监督学习不同的是， 我们只对我们探索过的内容进行训练。这意味着当我从状态$S$开始，我在网络中前向传播了这个$\phi (S)$ 我得到我的Q值向量，我选择最佳的Q值，我得到一个新的状态$S^\prime$.</p><p>在监督学习中 同样的数据会在不同的epoch中使用 也就是会重复使用，而在DQN中不是这样，因为我们仅在探索时进行训练 我们可能永远不会回到那里。尤其时因为训练会受到我们去过位置的影响，这段是我自己人工翻译的， 感觉不是很通顺 这里我也弄得不是很明白</p><p>意思是we will never train on some parts of the game, so we need other techniques to keep this training stable. 那就是Experience replay</p><p><img src="https://z3.ax1x.com/2021/07/04/RfLkyd.png" alt="常规训练方法和加了experience replay的训练方法"></p><p>用experience replay的一个重大优势是破除连续数据之间的相关性</p><p>换个说法：当在用一堆猫狗图片来训练一个猫狗分类器，如果先在猫的图像上面训练，然后再在狗的图像上面训练，然后在猫，然后在狗，我们不会converge 因为网络会super biased towards predicting cat after seeing 10 images of cat. Super biased with predicting dogs when it sees 10 images of dog.</p><p>另一个优势是： you are basically trading computation and memory against exploration. Exploration is super costly. The state-space might be super big, but you know you have enough computation probably</p><h3 id="Advanced-topics"><a href="#Advanced-topics" class="headerlink" title="Advanced topics"></a>Advanced topics</h3><p>没听懂</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RL </tag>
            
            <tag> cs230 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> Q-Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MDPs ValuePolicy Iteration</title>
      <link href="2021/07/03/cs229%2017/"/>
      <url>2021/07/03/cs229%2017/</url>
      
        <content type="html"><![CDATA[<h2 id="Lecture-17-MDPs-ValuePolicy-Iteration"><a href="#Lecture-17-MDPs-ValuePolicy-Iteration" class="headerlink" title="Lecture 17 MDPs ValuePolicy Iteration"></a>Lecture 17 MDPs ValuePolicy Iteration</h2><p><a href="https://www.bilibili.com/video/BV1JE411w7Ub?p=23">视频链接</a></p><p>start to talk about algorithms for solving MDPs</p><p>We need to define sth. called <strong>the value function</strong> which tells you how good it is to be in different states of the MDP and then we’ll define the value function and then talk about an algorithm called value iteration for computing the value function.</p><p>回忆lecture16的内容，为了找到最佳的policy，可能有成千上万的可选择的policies，如果有11个状态，每个状态可采取4个行动，那么可能的策略就有$4^{11}$种</p><h3 id="计算最佳策略"><a href="#计算最佳策略" class="headerlink" title="计算最佳策略"></a>计算最佳策略</h3><script type="math/tex; mode=display">* = star</script><p>由于网页渲染星号会出问题，所以文中所有的star 都是*号</p><p>Define: $V^{\pi}$，$V ^ {star}$，$\pi ^ {star}$ ;  based on these definitions we’ll derive that $\pi^{star}$ is the optimal policy</p><p><span style='color:red;font-weight:bold'>For a policy </span>$\pi$, $V^\pi : S \rightarrow R $<span style='color:red;font-weight:bold'> is s.t.</span> $V^\pi (s)$ <span style='color:red;font-weight:bold'>is to the expected total payoff for starting in state s and executing</span> $\pi$</p><script type="math/tex; mode=display">V^\pi (s) = E[R(s_0) + \gamma R(s_1) + \cdots | \pi, s_0 = s]</script><p>$V^\pi$ 被称为value function for policy $\pi$</p><p><img src="https://z3.ax1x.com/2021/07/01/RyQhx1.png" alt="下面的图是某一个策略pi"></p><p><img src="https://z3.ax1x.com/2021/07/01/Ryl0Fe.png" alt="上面的策略对应的value function"></p><h3 id="Bellman-Equation"><a href="#Bellman-Equation" class="headerlink" title="Bellman Equation"></a>Bellman Equation</h3><script type="math/tex; mode=display">V^\pi (s) = R(s) + \gamma \sum_{s^\prime}P_{s\pi (s)}(s^\prime)V^\pi (s^\prime) \tag{1}</script><p>假如在$s=s_0$的时候开始，机器人马上获取在$s_0$的收益 即即使奖励$R(s_0)$ </p><script type="math/tex; mode=display">V^\pi (s) = E[R(s_0) + \gamma R(s_1) + \gamma^2 R(s_2) + \cdots | \pi, s_0 = s] \\= E[R(s_0) + \gamma (R(s_1) + \gamma R(s_2) + \cdots) | \pi, s_0 = s] \\= E[R(s_0) + \gamma V^\pi(s_1) | \pi, s_0 = s]</script><p>方程式$(1)$ 的意义在于Given $\pi$, get a linear system of equation in terms of $V^\pi (s)$</p><p>举个例子 之前机器人的例子：</p><script type="math/tex; mode=display">V((3, 1)) = R((3, 1)) + \gamma(0.8V^\pi((3, 2)) + 0.1V^\pi((2, 1)) + 0.1V^\pi((4, 1)))</script><p>因为有11个状态 那么就会有11个未知数，和 11个Bellman equations，解线性方程得结果</p><p><img src="https://z3.ax1x.com/2021/07/02/RyyvNQ.png" alt="11个状态组成得线性方程组"></p><p>$V^{star}$ is the optimal value function   $V ^ {star} (s) = \max_\pi V^\pi (s)$</p><p>下面是关于$V^{star}$的bellman 方程</p><script type="math/tex; mode=display">V^* (s) = R(s) + \max_a \gamma \sum_{s^\prime}P_{sa} (s^\prime)V^*(s^\prime) \tag{2}</script><p>if take action $a$ 那么 $\sum_{s^\prime}P_{sa} (s^\prime)V^{star}(s^\prime)$ 就是expected future reward</p><p>由方程$(2)$ 就可以推出$\pi^{star} (s)$ 即</p><script type="math/tex; mode=display">\pi^* (s) = argmax_a \sum_{s^\prime}P_{sa}(s^\prime)V^*(s^\prime)</script><p>作个小总结 $V^{star} (s) = V^{\pi^{star}}(s) \ge V^\pi (s) \ for \ every \ \pi, s$ </p><p>我们要做的就是找到$V^{star}$， 使用argmax方程来求得$\pi ^ {star}$</p><h3 id="Value-iteration"><a href="#Value-iteration" class="headerlink" title="Value iteration"></a>Value iteration</h3><p> 是一个算法来找到$V ^ {star}$ </p><ul><li><p>初始化$V(s) := 0$  for every s</p></li><li><p>For every s, repeatedly update:</p><script type="math/tex; mode=display">V(s) := R(s) + \max_a \gamma \sum_{s^\prime}P_{sa}(s^\prime)V(s^\prime)</script><p>类似于梯度下降 就是update所有components of V simultaneously，有synchronous update</p><p>就是计算所有状态然后进行同时覆盖。有一种替代方法是异步更新 就是一个一个更新</p><p>一般用synchronous update</p></li></ul><p>用value iteration 计算出的$V^{star}$ 结果是：</p><p><img src="https://z3.ax1x.com/2021/07/02/R6CEZt.png" alt="value iteration的结果"></p><p>由这张图 知道处于$(3, 1)$的时候应该向左走</p><h3 id="Policy-Iteration"><a href="#Policy-Iteration" class="headerlink" title="Policy Iteration"></a>Policy Iteration</h3><p>这个用来求解MDP问题</p><ul><li><p>Initialize $\pi$ randomly</p></li><li><p>Repeat until convergence:</p><p>​    Set $V := V^\pi$ i.e. solve Bellman’s equations to get $V^\pi$ </p><p>​    Set $\pi (s) := argmax_a \sum_{s^\prime}P_{sa}(s^\prime)V(s^\prime)$  假设$V$就是optimal value function</p><p>注意$V^\pi$ 是解linear system of equations</p></li></ul><p>对于状态很多的情况，解线性方程就很耗时，用value iteration 会更好一点</p><p>对于value iteration $V \rightarrow V ^ {star}$ <strong>就将梯度下降，向最优值收敛是越来越靠近最优值，但是永远达不到最优值</strong></p><h3 id="如果不知道-P-sa"><a href="#如果不知道-P-sa" class="headerlink" title="如果不知道$P_{sa}$"></a>如果不知道$P_{sa}$</h3><p>当state transition probabilities are often not known in advance. And so in many MDP implementations we need to estimate this form data.</p><script type="math/tex; mode=display">P_{sa}(s^\prime) = \frac{\# \ times \ took \ action \ "a" \ in \ state \ s \ and \ got \ to \ s^\prime}{\# \ times \ took \ action \ "a" \ in \ state \ s}</script><p>or $\frac{1}{|S|}$  if above is $\frac{“0”}{0}$ </p><p>总结一下：</p><ul><li><p>Repeat {</p><p>​    Take actions w.r.t. $\pi$ to get experience in MDP</p><p>​    Update estimates of $P_{sa}$ and possibly $R$</p><p>​    Solve Bellman’s equation using value iteration to get $V$</p><p>​    Update $\pi (s) = argmax_a \sum_{s^\prime}P_{sa}(s^\prime)V(s^\prime)$</p><p>}</p></li></ul><p>上面这个算法没有exploration</p><p>如果加上exploration的话 那么就不是take actions $\pi$ 而是 0.9 take actions $\pi$ 0.1 take randomly</p><p>这种exploration policy is called $\epsilon$-greedy；在每个时间步长你仍一枚biased coin;</p><p>这里的$\epsilon$ 就是0.1</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cs229 </tag>
            
            <tag> RL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PCA and ICA</title>
      <link href="2021/07/01/cs229%20pca/"/>
      <url>2021/07/01/cs229%20pca/</url>
      
        <content type="html"><![CDATA[<h3 id="Lecture-hidden-PCA-and-ICA"><a href="#Lecture-hidden-PCA-and-ICA" class="headerlink" title="Lecture hidden PCA and ICA"></a>Lecture hidden PCA and ICA</h3><p><a href="https://www.bilibili.com/video/BV1JE411w7Ub?p=21">视频链接</a> 因为看Lecture 16的时候 感觉跳了一集，所以找到了这里</p><p><strong>PCA ： Principal Components Analysis</strong></p><p><strong>ICA ：Independent Components Analysis</strong></p><h3 id="motivation-example"><a href="#motivation-example" class="headerlink" title="motivation example:"></a>motivation example:</h3><p>Want measure children’s height in centimeters and also the height in inches</p><p>Because of <strong>round off</strong> to the nearest centimeter or round off to the nearest inch</p><p><strong>The data is almost prefectly correlated but not completely</strong> [7:21]的图</p><p>你知道这其实是一个一维的数据，但是以2维的形式存在；</p><p>另一个例子是 横坐标是pilot skill 纵坐标是pilot enjoyment，从这个2维数据里面得到pilot aptitude</p><p>PCA 就是将高维数据转化成低维数据；实际上 会用PCA 将10000维数据变成100维数据 而非2变1</p><p>在running PCA之前 要做Pre-processing</p><ul><li>$\mu = \frac{1}{m}\sum_{i = 1}^mx^{(i)}$</li><li>$x^{(i)} \leftarrow x^{(i)} - \mu$</li><li><p>$\sigma^2 = \frac{1}{m} \sum_i x_j^{(i)}$</p></li><li><p>$x_j^{(i)} \leftarrow \frac{x_j^{(i)}}{\sigma_j}$</p></li></ul><p>做完之后 features have zero mean， one standardize variance</p><h3 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h3><p>[14:44] 二维的数据 进行1维压缩，有好的subspace 绿色的线， 也有差的subspace 红色的线，对于好的projection， <strong>所有点到subspace的和的总数距离小</strong>，对于PCA 我们就是想要找到绿色的线</p><p>图中绿色的点are spread apart very far from each other，红色的点are close to each other，So if you like to preserve as much of the variability of the data as possible</p><p>对于PCA有两种数学上等价的推导方式 老师介绍的是第二种</p><ul><li>一种是所有点到subspace的距离之和最小</li><li>另一种是所有点到subspace的投影长度之和最大</li></ul><p>A second intuition of PCA : Define PCA is you want ot find a line onto which project the data 使数据尽可能的spread as far as possible</p><p>要找到绿线 即要找到一个和绿线同方向的单位向量$u$  这里绿线就表示subspace</p><p>If $||u|| = 1$, then length of projection of $x^{(i)}$ onto $u$ is $u^Tx^{(i)}$ </p><p>So PCA choose $u$ to maximize:</p><script type="math/tex; mode=display">\max_{u : ||u || = 1} \frac{1}{m}\sum_{i = 1}^m (x^{(i)^T}u)^2 = \frac{1}{m}\sum_{i = 1}^m u^Tx^{(i)}x^{(i)^T}u = u^T(\frac{1}{m}\sum_{i = 1}^mx^{(i)}x^{(i)^T})u</script><p>令$\Sigma = \frac{1}{m}\sum_{i=1}^mx^{(i)}x^{(i)^T}$</p><p>那么就是$\max_{u : ||u|| = 1}u^T\Sigma u$  <strong>那么u就是principal eigenvector of matrix $\Sigma$</strong></p><p>这里的$\Sigma$是covariance matrix，我们做了preprocessing之后的$x^{(i)}$构成的矩阵</p><p>下面是关于上面加粗内容的证明：</p><script type="math/tex; mode=display">\max_{u : ||u|| = 1}u^T\Sigma u \ 构造拉格朗日函数 \\\mathcal{L}(u,\lambda) = u^T\Sigma u - \lambda(u^Tu - 1) \\ \nabla\mathcal{L} = \Sigma u - \lambda u  = 0 \Rightarrow \Sigma u = \lambda u</script><p>General case : If wish to project data to k dimensions</p><p>Set $u_1, u_2, \cdots, u_k$ to be top k eigenvectors of $\Sigma$，$\lambda_1, \lambda_2, \cdots, \lambda_k$ are corresponding eigenvalues</p><p>Have $x^{(i)} \in R^n$ $n = 1000$， 要用PCA降维到10维 $u_1, u_2, \cdots, u_k$ 其中$k = 10$</p><p>我们就有了New Representation $x^{(i)} \rightarrow (u_1^Tx^{(i)}, u_2^Tx^{(i)}, \cdots, u_{10}^Tx^{(i)})  = y^{(i)} \in R^k$</p><p>从$y$得到$x$ $x^{(i)} \approx y_1^{(i)}u_1 + y_2^{(i)}u_2 + \cdots + y_k^{(i)}u_k$ 其中$y_i$是标量</p><p><strong>666</strong></p><p>[33:00]的图 展示了<strong>为什么PCA需要 preprocessing</strong></p><h3 id="Application-of-PCA"><a href="#Application-of-PCA" class="headerlink" title="Application of PCA:"></a>Application of PCA:</h3><ul><li><p>Visualization</p><p>Project from n dimensional to 2 dimensional or 3 dimensional to view</p><p>举了个例子，猴子脑电信号50维 很难visualize</p></li><li><p>Compression for ML efficiency</p></li><li><p>用PCA来reduce overfitting 不是很合适，用正则化更好</p></li><li><p>用PCA来做outlier detection不是很合适</p></li></ul><p>总结一下： 基本上PCA 就是用在可视化</p><p>如果有训练集和测试集，eigenvectors 用训练集的</p><div class="table-container"><table><thead><tr><th>—</th><th>model $p(x)$ e.g. anomaly detection</th><th>Non-probabilistic</th></tr></thead><tbody><tr><td>“Subspaces”</td><td>Factor analysis</td><td>PCA</td></tr><tr><td>“Clusters”</td><td>GMM</td><td>K-means</td></tr></tbody></table></div><p>PS 对于PCA k dimension subspace 比较稳定， 单个eigenvector不怎么稳定 由于数值计算等原因</p><h3 id="如何选择k值"><a href="#如何选择k值" class="headerlink" title="如何选择k值"></a>如何选择k值</h3><p>有一种选择是：$\frac{\lambda_1 + \lambda_2 + \cdots + \lambda_k}{\lambda_1 + \lambda_2 + \cdots + \lambda_n} = 0.9$  人们称这个retain $90\%$ of variance of data</p><h3 id="ICA"><a href="#ICA" class="headerlink" title="ICA"></a>ICA</h3><p>ICA 可以用来解决Cocktail party problem 有点厉害</p><p>问题可以描述为：</p><p>Original source $s \in R$ (n speakers)  $s_j^{(i)} = $ signal from speaker $j$ at time $i$</p><p>在某个时刻$t$ 对于第一个speaker 振幅为 $s_1^{(t)}$ 对于第二speaker 振幅为$s_2^{(t)}$</p><p>我们观察到 $x^{(i)} = As^{(i)}$  其中$x^{(i)} \in R^n$ n microphones</p><p>$x_j^{(i)}$ is recording of microphone $j$ at time $i$  其中$j = 1, \cdots, n$</p><p>即 $x_j^{(i)} = \sum_kA_{jk}s_k^{(i)}$  目标是找到$W = A^{-1}$ so that $s^{(i)} = Wx^{(i)}$</p><p>Notation:</p><script type="math/tex; mode=display">W = \begin{pmatrix} w_1^T \\ w_2^T  \\ \vdots \\  w_n^T  \\\end{pmatrix}</script><p>则 $s_j^{(i)} = w_j^Tx^{(i)}$</p><p>老师讲了个二个 independent source 1 和 source 2 每个source产生random的数据</p><p>对于这个数据有两个ambiguity 一个是不知道which one is S1 and which one is S2</p><p>第二个是 sign ambiguity 我们不知道哪个是 + S1 哪个是 - S1</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cs229 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Independent Component Analysis and RL</title>
      <link href="2021/07/01/cs229%2016/"/>
      <url>2021/07/01/cs229%2016/</url>
      
        <content type="html"><![CDATA[<h2 id="Lecture-16-Independent-Component-Analysis-and-RL"><a href="#Lecture-16-Independent-Component-Analysis-and-RL" class="headerlink" title="Lecture 16 Independent Component Analysis and RL"></a>Lecture 16 Independent Component Analysis and RL</h2><p><a href="https://www.bilibili.com/video/BV1JE411w7Ub?p=22">视频链接</a></p><h3 id="ICA"><a href="#ICA" class="headerlink" title="ICA"></a>ICA</h3><p>感觉这个有点神奇，不是很懂</p><ul><li>CDFs Cumulative distribution function</li><li>ICA model</li></ul><p>Recap: $S_1^{(t)}$ is the sound emitted by speaker one at time t</p><p>$S_j^{(i)} =  speaker \  j \ at \  time \  i \ ,  \  x^{(i)} = As^{(i)}, x\in\mathcal{R}^n$</p><p>Goal:  Find $W = A^{-1}, S^{(i)} = Wx^{(i)}$ $W = \begin{pmatrix} -w_1^T-  \\  \vdots \\ -w_n^T -\end{pmatrix}$</p><hr><p>PS：如果数据是均匀分布，ICA能分离，如果是高斯分布 ICA不能分离，由两个标准高斯分布组成的二维空间，S1和S2是旋转对称的，就会有旋转的歧义</p><p><strong>ICA  is possible only if  your data is non  Gaussian</strong></p><hr><p>为了使用ICA ，We need to figure out what is the density of S</p><p>我们知道S的概率密度 $P_S(s)$ 因为$x = As = W^{-1}s$ 我们就知道 $s = Wx$</p><p>我们需要计算$x$的概率密度，因为当你得到训练集的时候，只能观察$x$，用到MLE，必须要知道$x$的概率密度是多少</p><p>猜想 $P_X(x) = P_S(Wx)$是否是正确的，  这个对于离散的随机变量是正确的，对于连续的就不正确</p><p>反例：</p><script type="math/tex; mode=display">P_S(s) = 1\{  0  \le s \le 1 \} \quad \quad S \sim  Uniform(0, 1) \\x = 2s \quad  \quad A = 2 \quad  \quad  W = \frac{1}{2}</script><p>那么 x  就应该是0到2上的均匀分布 其概率密度应该为$P_X(x) = \frac{1}{2}1 \{  0 \le x \le 2 \}$</p><p>把$P_X(x)$和$P_S(Wx)$分别带入到等式，发现等式不成立，正确的式子应该是：</p><script type="math/tex; mode=display">P_X(x) = P_S(wx)|w|</script><p>还有一点重要 choose the density of what your speakers’ voices sound like</p><p>如果选择sigmoid函数 作为CDF 其概率密度 有点像 高斯，但是他有fatter tails 因为高斯函数是$e^{-x^2}$衰减的 goes to 0 very quickly, sigmoid的概率密度captures human voice  and many natural phenomena better than a Gaussian density because there are a larger number of extreme outliers that are more than one or two standard deviations away.</p><p>除了 sigmoid还可以有其它的选择  比如 双重指数分布</p><p><strong>因为n个speaker  speak  independently</strong></p><script type="math/tex; mode=display">P(s) = \prod_{i = 1}^n P_S(s_i)</script><script type="math/tex; mode=display">P_X(x) = P_S(wx)|w| = (\prod_{j = 1}^n P_S(w_j^Tx))|w|</script><p><strong>MLE</strong></p><script type="math/tex; mode=display">\ell(w) = \sum_{i = 1}^nlog[(\sum_jP_S(w_j^Tx^{(i)}))|w|]</script><p>求导结果参考讲义</p><p><strong>ICA通常用于清理EEG数据</strong></p><p>如果麦克风的数量少于speaker 那么这是个比较难的问题</p><p><strong>如果有两个麦克风，那么这两个麦克风记录的声音会不会很相似？？ </strong></p><h3 id="RL-666哇"><a href="#RL-666哇" class="headerlink" title="RL 666哇"></a>RL 666哇</h3><p>RL的一个挑战问题是 Credit assignment problem</p><p>play chess 如果是在第50步失败 得到奖励-1</p><p><strong>MDP</strong> Markov decision process</p><p><span style='color:red;font-weight:bold'>下面的内容就是说的如何将问题化为MDP的形式 </span></p><p>MDP是five tuple $(S, A, \{ P_{sa}\},\gamma,R)$</p><p>$S$ 是 set of states; $A$ 是 set of actions; $P_{sa}$ 是 state transition probabilities $\sum_s^\prime P_{sa}(s^\prime) = 1$</p><p>$\gamma$ 是discount factor 取值在0到1之间  $R$ 是 reward function</p><p><img src="https://z3.ax1x.com/2021/07/01/RyCic9.png" alt="RyCic9.png"></p><p><strong>上面这张图是我博客里面的第二张图，这张图是放在图床上面的</strong></p><p>这是一个非常简单的迷宫，这个MDP有11个state 机器人可能处在11个位置</p><p>对于Actions 可能是向北，向东，向南，向西</p><p>如果让人向北走，有可能他脚底一滑，向东走了  实际上课程里面的小人是小车，小车会打滑</p><p>对于$P_{sa}$  具体一点 $P_{(3,1)N}((3,2)) = 0.8$  $P_{(3,1)N}((4, 1)) = 0.1$ 和 $P_{(3,1)N}((2, 1)) = 0.1$ </p><p>假如要机器人走到右上角，那么我们将$(4, 3)$的位置放上奖励 + 1 如果不想让机器人走到哪一个格就在那一格上面放上 -1 比如在$(4, 2)$上面</p><p>还有其它的一些设计方法，一个常见的选择是put a very small penalty $R(s) = -0.02$ 对于其它的state</p><p>举个例： </p><ul><li><p>比如机器人一开始在$S_0$的位置</p></li><li><p>Choose action $a_0$, get to $s_1$  is distributed according to $P_{s_0a_0}$</p></li><li><p>Choose action $a_1$</p></li><li>Get to $s_2$ is distributed according to $P_{s_1a_1}$</li></ul><p>假设机器人的状态序列是$s_0, s_1, s_2, \cdots$ 那么总的收益是 $R(s_0) + \gamma R(s_1) + \gamma^2 R(s_2) + \cdots$</p><p>RL的目标就是Choose actions over time to maximize</p><script type="math/tex; mode=display">E[R(s_0) + \gamma R(s_1) + \gamma^2 R(s_2) + \cdots]</script><p><strong>大多数强化学习算法会提出a policy that maps from states to actions</strong> 即$\pi: S \rightarrow A$</p><p>因此大多数强化学习算法的输出是policy 另一种叫法是controller</p><p>强化学习的问题是给出了MDP的定义，然后<strong>有一个强化学习算法</strong> 找到使期望收益最大化的策略$\pi$</p><p>用强化学习解决chess问题的一个难点在于，一次action是包括自己的一步和对手的一步，但是你不知道对方会走什么 那么这就存在一个概率分布</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cs229 </tag>
            
            <tag> 机器学习 </tag>
            
            <tag> RL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Project 1 用闲置电脑搭建centos服务器</title>
      <link href="2021/06/30/%E7%94%A8%E9%97%B2%E7%BD%AE%E7%94%B5%E8%84%91%E6%90%AD%E5%BB%BAcentos%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
      <url>2021/06/30/%E7%94%A8%E9%97%B2%E7%BD%AE%E7%94%B5%E8%84%91%E6%90%AD%E5%BB%BAcentos%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="Project-1-用闲置电脑搭建centos服务器"><a href="#Project-1-用闲置电脑搭建centos服务器" class="headerlink" title="Project 1 用闲置电脑搭建centos服务器"></a>Project 1 用闲置电脑搭建centos服务器</h2><p>由于之前做网页做的觉得感觉还不错，想着以后在云服务器上面搭建网站，但是网页写的不好，就想自己搭一个服务器来模拟一下云服务器，一般云服务器上面都是centos，所以就选择了centos作为本地服务器的OS。虽然可以用虚拟机来搭服务器，不过家里有闲置的电脑的话，就用闲置的电脑吧。之前写的博客都没有图，这次贴一张图。</p><p><img src="https://ss0.baidu.com/7Po3dSag_xI4khGko9WTAnF6hhy/exp/w=500/sign=f3e4832706e9390156028d3e4bec54f9/0823dd54564e92585e34bde99b82d158ccbf4eb0.jpg" alt=""></p><h3 id="Start"><a href="#Start" class="headerlink" title="Start !!!"></a>Start !!!</h3><p>centos系统为7.5   iso镜像在vault上面下载 <a href="https://vault.centos.org/">网页链接</a></p><p>用ultraiso 将iso文件拷贝到U盘中</p><p>闲置电脑 开机启动设置为U盘  我的闲置电脑是联想的thinkpad 不用设置开机启动 之间在开机的时候按F12键 选择U盘启动，<strong>iso里面有方法可以将硬盘格式化 reclaim方法</strong></p><p>当时我选择了最小化安装，</p><p>分配硬盘是 /boot 2g  ext4 ; swap 8g   ;  其余是 / </p><p>开启了无线网卡 然后安装</p><p>安装完 发现和我之前在虚拟机上安装GNOME版的不一样，这个版本只有root，root的～路径是/root</p><p><strong>然后 ifconfig 发现没有ifconfig 这个命令！！</strong></p><p>然后发现ping www.baidu.com 也ping不通，下面进行了一系列操作来解决这个问题</p><ul><li><p>ip addr 查看无线网卡 我查到的名字是wlp3s0</p></li><li><p>ip link set wlp3s0 up</p></li><li><p>```text<br>wpa_supplicant -B -i wlp3s0 -c &lt;(wpa_passphrase “WiFi 名称” “密码”)</p><pre class="line-numbers language-none"><code class="language-none">+ dhclient wlp3s0+ service network restart此时查看ip addr 会发现 wlp3s0下面有ip地址在&#x2F;etc&#x2F;resolv.conf 设置dns&#96;&#96;&#96;txtnameserver 223.5.5.5<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后ping baidu.com成功了</p></li></ul><p>根据清华源网站的教程 教源改成了清华源<a href="https://mirrors.cnnic.cn/help/centos/">链接</a> 按照上面进行操作</p><p>报错啦 <a href="http://mirrors.tuna.tsinghua.edu.cn/repodata/repomd.xml">http://mirrors.tuna.tsinghua.edu.cn/repodata/repomd.xml</a> [Errno 14] HTTP Error 404 - Not Found</p><p>看到这篇文章 <a href="https://blog.csdn.net/yuesichiu/article/details/53351324">文章链接</a> 上面说不要直接修改resolv.conf 而是要通过NetwrokManager来修改 其实不是这个原因，而是我误解了清华源网站上面的修改 应该是把<strong>mirrorlist中mirror.centos.org替换成mirrors.tuna.tsinghua.edu.cn 后面的url不变</strong></p><p>虽然404的问题没了，但是还是有新的问题</p><p>于是我按照这篇博文里面的设置 <a href="https://blog.csdn.net/xiaojin21cen/article/details/84726193">博客链接</a> 设置完之后yum makecache就OK了</p><p>yum install ifconfig  显示No package ifconfig available</p><p>用yum search ifconfig 显示net-tools.x86_64</p><p>然后我用yum install net-tools 然后ifconfig就能用了</p><p>即<strong>ifconfig 是 net-tools里面的内容</strong> 根据ifconfig里面显示的ip地址 用另一台电脑ping它 结果ping成功了</p><p>用ssh登录 mac的话 <strong>ssh 用户名@ip地址</strong> 用户名别掉了</p><p>ssh登录成功以后 w命令 发现有两个user 都是root</p><p><strong>一个是tty1   另一个是pts/0</strong>  发现登录时间不对 于是想看看linux如何查看时间</p><p>date命令查看时间 发现时间是CST，但是时间不对</p><p>yum -y表示安装过程中全部选yes  按照教程<a href="https://blog.csdn.net/king_wang10086/article/details/76178711">链接</a></p><p>yum install -y ntpdate  中间突然关机一次 重启后 报了个错</p><p>Delta RPMs disabled because /usr/bin/applydeltarpm not installed</p><p>突然发现ping www.baidu.com ping不通 要重新登录一下无线</p><p>登录完之后 yum install 就ok了 然后再 ntpdate us.pool.ntp.org 时间就正确了</p><h3 id="觉得用wpa登wifi比较麻烦"><a href="#觉得用wpa登wifi比较麻烦" class="headerlink" title="觉得用wpa登wifi比较麻烦"></a>觉得用wpa登wifi比较麻烦</h3><p>使用NetworkManager 的方法 <a href="https://blog.k4nz.com/949d40228a77b57d0fc0e7cd0ca4cbf1/">参考连接</a> 总结一下：</p><ul><li><strong>yum install -y NetworkManager-wifi</strong></li><li><strong>systemctl restart NetworkManager.service</strong></li><li><strong>nmcli device wifi list</strong></li><li><strong>nmcli device wifi connect “SSID-Name” password “your password”</strong></li></ul><p>出现问题 Error: Connection activation failed: 7 Secrets were required, but not provided</p><p>把电脑reboot之后 再来 就OK了</p><p>使用nmcli connection show 就能看到 NAME UUID TYPE DEVICE</p><p><strong>重启电脑后发现开机自动连接WIFI</strong></p><h3 id="centos-最小化安装查看电池电量"><a href="#centos-最小化安装查看电池电量" class="headerlink" title="centos 最小化安装查看电池电量"></a>centos 最小化安装查看电池电量</h3><p>在我的电脑上是 cat /sys/class/power_supply/BAT0/capacity</p><h3 id="安装python"><a href="#安装python" class="headerlink" title="安装python"></a>安装python</h3><p>使用命令python 发现电脑上默认的python 版本是2.7.5</p><p><a href="https://jingyan.baidu.com/article/19020a0ac2d827139c28423b.html">参考文章1</a>  <a href="https://www.cnblogs.com/jiangxiaobo/p/11734294.html">参考文章2</a></p><p>我想试试最简单的安装方法 先在官网上下载python<a href="https://www.python.org/downloads/source/">链接地址</a></p><p>在下载的Download XZ compressed source tarball上右键复制链接地址 发现</p><p><a href="https://www.python.org/ftp/python/3.9.6/Python-3.9.6.tar.xz">https://www.python.org/ftp/python/3.9.6/Python-3.9.6.tar.xz</a></p><p>准备用wget命令来下载 结果发现没有这个命令 yum -y install wget</p><p>下载得到Python-3.9.6.tar.xz 然后 使用xz -d Python-3.9.6.tar.xz <strong>得到Python-3.9.6.tar</strong></p><p>接着tar xf Python-3.9.6.tar</p><p>接着要安装gcc 来进行编译 发现安装的gcc 是4.8.5-44.el7版本</p><p>在install gcc的时候 有installing for dependencies 和 updating for dependencies</p><p><strong>接着安装make</strong> yum -y install make 发现安装的版本是1:3.82-24.el7</p><p><strong>安装的时候有个Repository 为base 我比较好奇</strong></p><p>然后 ./configure —prefix=/usr/local/python396</p><p>然后make 出现了个问题 fatal error: ffi.h: No such file or directory</p><p>使用yum install libffi-devel  再make 就成功了</p><p><strong>但是在指定目录下面没有找到python</strong></p><p>那是make 完了之后还有make install ！！！！</p><p>make install 报错 ModuleNotFoundError: No module named zlib</p><p>yum install zlib -y 之后再make install 还是同样的错</p><p>按照教程 安装 yum install zlib* -y <a href="https://blog.csdn.net/sirria1/article/details/83115582">关于zlib的相关资料</a></p><p><strong>设置系统默认的python为3.9.6版本</strong></p><ul><li>先看python的路径 which python 发现时/usr/bin</li><li>移除掉原来的python mv /usr/bin/python /usr/bin/python.bak</li><li>建立软链接 ln  -s /usr/local/python396/bin/python3 /usr/bin/python3</li><li>建立pip3的软链接 ln -s /usr/local/python396/bin/pip3 /usr/bin/pip3</li></ul><h3 id="centos最小化-怎么上下翻页"><a href="#centos最小化-怎么上下翻页" class="headerlink" title="centos最小化 怎么上下翻页"></a>centos最小化 怎么上下翻页</h3><p>shift + pageup  或者 shift + pagedown</p><p>但是发现往上翻的页数有限</p><h3 id="安装python虚拟环境"><a href="#安装python虚拟环境" class="headerlink" title="安装python虚拟环境"></a>安装python虚拟环境</h3><p>准备使用python的venv  <a href="https://docs.python.org/3/library/venv.html">参考链接</a>   <a href="https://www.jianshu.com/p/c5f973fd34d4">python3 venv简单使用</a></p><p>总结一下 就是在工作目录下使用 python -m venv . </p><p>启动虚拟环境 就是用source ./bin/activate</p><p><strong>用pip list</strong>来查看安装了哪些库 </p><p>进入了虚拟环境之后 我想要安装django 结果报错</p><p>WARNING: pip is configured with locations that require TLS/SSL, however the ssl module in Python is not available.</p><p><a href="https://jingyan.baidu.com/article/cbf0e500475c042eab289362.html">解决方法</a></p><p><strong>准备安装openssl-devel的时候， 发现yum用不了了</strong> 网上搜了一下 找到<a href="https://blog.csdn.net/weixin_39541750/article/details/110558052">解决方法</a></p><p>方法就是修改yum配置文件 vi /usr/bin/yum，把文件头部的#!/usr/bin/python改成#!/usr/bin/python2.7保存退出即可。另外如果存在vim /usr/bin/yum-config-manager的话也需要改成python2.7。</p><p>此外在CentOS环境下安装其他命令报如下错误时，需要执行 vim /usr/libexec/urlgrabber-ext-down将/usr/bin/python改为/usr/bin/python2.7。修改完成后再一次执行，发现安装成功了。</p><p>yum install openssl-devel 版本为1.0.2 貌似不高 就准备卸了 再网上重装一个</p><p><a href="https://www.cnblogs.com/lemon-le/p/13419429.html">参考链接</a></p><h3 id="查看python3-是否编译openssl"><a href="#查看python3-是否编译openssl" class="headerlink" title="查看python3 是否编译openssl"></a>查看python3 是否编译openssl</h3><p>下面这个操作还是贼厉害的</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"> python3 -c &quot;import sysconfig; print(sysconfig.get_config_var(&#39;CONFIG_ARGS&#39;))&quot;&#39;--prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;python3&#39; &#39;--with-openssl&#x3D;&#x2F;usr&#x2F;local&#x2F;openssl&#39; &#39;--enable-shared&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>发现没有编译</p><p>查看软链接的方式  ls -il /usr/bin/python</p><p>wget <a href="https://www.openssl.org/source/openssl-1.1.1a.tar.gz">https://www.openssl.org/source/openssl-1.1.1a.tar.gz</a><br>tar -zxvf openssl-1.1.1a.tar.gz</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd openssl-1.1.1g&#x2F;.&#x2F;config --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;opensslmakemake install<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>安装报错 提示You need Perl 5</strong></p><p><a href="https://blog.csdn.net/pyd1040201698/article/details/98488982">安装perl 5的方法</a></p><ul><li>wget <a href="https://www.cpan.org/src/5.0/perl-5.28.0.tar.gz">https://www.cpan.org/src/5.0/perl-5.28.0.tar.gz</a> </li><li>cd perl-5.28.0</li><li>./Configure -des -Dprefix=$HOME/localperl</li><li>make</li><li>make test</li><li>make install</li></ul><p>写这篇文章的时候最新版本时5.34 奇数版本号不稳定 要安装偶数版本号</p><p><strong>又差东西pod2html command not found</strong></p><p>pod2html是perl的东西，因为我的perl安装在</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">$HOMD&#x2F;localperl上面<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>感觉这个问题可以先放一下 运行openssl的时候 报错</p><p>error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory</p><p><a href="https://www.cnblogs.com/xyb930826/p/6077348.html">解决方法</a></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ln -s &#x2F;usr&#x2F;local&#x2F;lib64&#x2F;libssl.so.1.1 &#x2F;usr&#x2F;lib64&#x2F;libssl.so.1.1ln -s &#x2F;usr&#x2F;local&#x2F;lib64&#x2F;libcrypto.so.1.1 &#x2F;usr&#x2F;lib64&#x2F;libcrypto.so.1.1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这个不太行 换个方法 <a href="https://www.bswen.com/2018/11/others-Openssl-version-cause-error-when-loading-shared-libraries-libssl.so.1.1.html">方法链接</a></p><p><strong>里面有个重要信息：We can find that the ‘libcrypto.so.1.1’ is located in the /usr/local/lib64, But openssl try to find the .so libraries in the LD_LIBRARY_PATH</strong></p><p>又搜到另一个方法：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">echo &quot;&#x2F;usr&#x2F;local&#x2F;lib64&#x2F;&quot; &gt;&gt; &#x2F;etc&#x2F;ld.so.confldconfig<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>不太行</p><p><strong>cd到/usr/local/lib64发现根本就没有这两个文件</strong> 于是我用在编译的openssl中的lib进行软链</p><p>我的openssl 中 lib的路径是/usr/local/openssl/lib</p><p>用ln -s /usr/local/openssl/lib/libssl.so.1.1 /usr/lib64/libssl.so.1.1  就OK了</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">wget https:&#x2F;&#x2F;www.openssl.org&#x2F;source&#x2F;openssl-1.1.1a.tar.gztar -zxvf openssl-1.1.1a.tar.gzcd openssl-1.1.1a# 2.编译安装.&#x2F;config --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;openssl no-zlib #不需要zlibmakemake install# 3.备份原配置mv &#x2F;usr&#x2F;bin&#x2F;openssl &#x2F;usr&#x2F;bin&#x2F;openssl.bakmv &#x2F;usr&#x2F;include&#x2F;openssl&#x2F; &#x2F;usr&#x2F;include&#x2F;openssl.bak# 4.新版配置ln -s &#x2F;usr&#x2F;local&#x2F;openssl&#x2F;include&#x2F;openssl &#x2F;usr&#x2F;include&#x2F;opensslln -s &#x2F;usr&#x2F;local&#x2F;openssl&#x2F;lib&#x2F;libssl.so.1.1 &#x2F;usr&#x2F;local&#x2F;lib64&#x2F;libssl.soln -s &#x2F;usr&#x2F;local&#x2F;openssl&#x2F;bin&#x2F;openssl &#x2F;usr&#x2F;bin&#x2F;openssl# 5.修改系统配置## 写入openssl库文件的搜索路径echo &quot;&#x2F;usr&#x2F;local&#x2F;openssl&#x2F;lib&quot; &gt;&gt; &#x2F;etc&#x2F;ld.so.conf## 使修改后的&#x2F;etc&#x2F;ld.so.conf生效 ldconfig -v# 6.查看openssl版本openssl version.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;python396 --with-openssl&#x3D;&#x2F;usr&#x2F;local&#x2F;opensslmakemake install<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><span style='color:red;font-size:30px'>全部搞定后 再pip install django 成功啦！！！</span></p><p>接着一波操作</p><ul><li>django-admin startproject gweb</li><li>python manage.py runserver 0.0.0.0:8000</li></ul><p>报错No module named ‘_sqlite3’</p><p>yum install sqlite-devel 然后重新编译</p><p>再运行 报新错 SQLite 3.9.0 or later is required found 3.7.17 <a href="https://blog.csdn.net/line_on_database/article/details/116058659">解决方法</a></p><p>export LD_LIBRARY_PATH = /usr/local/lib:$LD_LIBRARY_PATH</p><p>又报新错 deterministic=True requires SQLite 3.8.3 or higher</p><p><strong>重新编译一下python还是不行</strong> </p><p><a href="https://blog.csdn.net/weixin_42047023/article/details/110131770">找到新的解决方法</a>  核心思想是把代码里面的sqlite3 换成 pysqlite3</p><p>然后python manage.py runserver 0.0.0.0:8000 启动成功</p><p>用另一台电脑  访问192.168.1.106:8000 报错</p><p>DisallowedHost at /</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">Invalid HTTP_HOST header: &#39;192.168.1.106:8000&#39;. You may need to add &#39;192.168.1.106&#39; to ALLOWED_HOSTS.<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>在setting.py里面 修改为ALLOWED_HOSTS = [‘*’] 就OK了</strong> </p><h3 id="PS-每次看电池电量的命令太长了"><a href="#PS-每次看电池电量的命令太长了" class="headerlink" title="PS 每次看电池电量的命令太长了"></a>PS 每次看电池电量的命令太长了</h3><p>设置简短的命令</p><ul><li>cd /root</li><li>vi .bashrc</li><li>加上alias capa=’cat /sys/class/power_supply/BAT0/capacity’</li><li>source .bashrc</li></ul><h3 id="最后再把之前export的临时变量-写到bashrc中去"><a href="#最后再把之前export的临时变量-写到bashrc中去" class="headerlink" title="最后再把之前export的临时变量 写到bashrc中去"></a>最后再把之前export的临时变量 写到bashrc中去</h3><p>export LD_LIBRARY_PATH=/usr/local/lib:/usr/lib64</p><p><span style='color:#DA70D6;font-size:30px;font-weight:bold'>Project 1 完结撒花~~~</span></p>]]></content>
      
      
      <categories>
          
          <category> Project系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Project </tag>
            
            <tag> centos </tag>
            
            <tag> 认真系列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GDA Naive Bayes</title>
      <link href="2021/06/18/cs229%205/"/>
      <url>2021/06/18/cs229%205/</url>
      
        <content type="html"><![CDATA[<h2 id="Lecture-5-GDA-Naive-Bayes"><a href="#Lecture-5-GDA-Naive-Bayes" class="headerlink" title="Lecture 5 GDA Naive Bayes"></a>Lecture 5 GDA Naive Bayes</h2><p><a href="https://www.bilibili.com/video/BV1JE411w7Ub?p=7">视频链接</a></p><p><a href="http://cs229.stanford.edu/notes2020fall/notes2020fall/cs229-notes2.pdf">讲义链接</a></p><h3 id="Generative-Learning-Algorithms"><a href="#Generative-Learning-Algorithms" class="headerlink" title="Generative Learning Algorithms"></a>Generative Learning Algorithms</h3><p><strong>logistic regression 是在寻找一条直线，寻找一个将正例和负例分开的决策边界</strong></p><p>Generative Learning Algorithm没有寻找这种分离$($即并非是查看两个类然后去找到分离线$)$</p><p>而是<strong>一次查看一个类，根据这个类的所有训练数据尝试建立这个类的模型</strong>，在分类的时候，对于测试数据代入到每个类的模型之中，选择最有可能的一类。<strong>$($重要$)$</strong></p><ul><li><p>Discriminative learning algorithm：</p><p>Learn $\mathcal{P}(y|x)$ or learn $h_\theta(x)$ directly</p></li><li><p>Generative learning algorithm：</p><p>Learn $\mathcal{P}(x|y)$ 例如给定类别，what are the features likely gonna be like?</p><p>Learn $\mathcal{P}(y)$ (一般称作为class prior)</p></li></ul><p>根据Bayes rule $\mathcal{P}(y = 1 | x)  = \frac{\mathcal{P}(x | y = 1)\mathcal{P}(y = 1)}{\mathcal{P}(x)}$ 其中$\mathcal{P}(x) = \mathcal{P}(x | y = 1) \mathcal{P}(y = 1)+ \mathcal{P}(x | y = 0)\mathcal{P}(y = 0)$</p><p><strong>下面是两个generative learning algorithm的实例，一个针对continuous value features，另一个针对discrete features</strong></p><h3 id="Gaussian-Discriminant-Analysis-GDA"><a href="#Gaussian-Discriminant-Analysis-GDA" class="headerlink" title="Gaussian Discriminant Analysis$($GDA$)$"></a>Gaussian Discriminant Analysis$($GDA$)$</h3><p>假设$x \in \mathcal{R}^n$, <strong>高斯判别分析的核心假设是，我们将假定$\mathcal{P}(x|y)$服从高斯分布</strong></p><p>[10:00]开始讲多元高斯分布 讲到[19: 00]</p><p>GDA model：</p><script type="math/tex; mode=display">\mathcal{P}(x | y = 0) = \frac{1}{(2\pi)^\frac{n}{2}|\Sigma|^\frac{1}{2}}exp(-\frac{1}{2}(x - \mu_0)^T\Sigma^{-1}(x - \mu_0)) \\\mathcal{P}(x | y = 1) = \frac{1}{(2\pi)^\frac{n}{2}|\Sigma|^\frac{1}{2}}exp(-\frac{1}{2}(x - \mu_1)^T\Sigma^{-1}(x - \mu_1)))</script><p>这个模型的参数有$\mu_0,\mu_1,\Sigma,\phi$，<strong>注意模型假设这两个多元高斯分布的协方差矩阵是相同的</strong></p><p><strong>老师说可以使两个协方差矩阵不同，但是一般不这么做，一般都假设两个协方差矩阵是相同的</strong></p><p>对$\mathcal{P}(y)$进行建模，$y$取二元值，对此建模为伯努利，即$\mathcal{P}(y) = \phi^y(1 - \phi)^{1- y}$</p><p><strong>PS: 奥本海姆读$\phi$ 最后一个音节是i，吴恩达读$\phi$ 最后一个音节是ai</strong></p><h4 id="fit-parameters"><a href="#fit-parameters" class="headerlink" title="fit parameters"></a>fit parameters</h4><p>我们有训练集$\{ (x^{(i)},y^{(i)}\} \quad i = 1, \cdots, m$ 我们要做的是maximize the joint likelihood</p><script type="math/tex; mode=display">\begin{aligned}\ell(\phi, \mu_0, \mu_1, \Sigma) &= \prod_{i = 1}^{m}\mathcal{P}(x^{(i)},y^{(i)};\phi,\mu_0,\mu_1,\Sigma) \\&= \prod_{i = 1}^{m}\mathcal{P}(x^{(i)}|y^{(i)};\mu_0,\mu_1,\Sigma)\mathcal{P}(y^{(i)};\phi)\end{aligned}\tag{1}</script><p>对于discriminative learning algorithm 我们maxmize的是conditional likelihood：</p><script type="math/tex; mode=display">\ell(\theta) = \prod_{i = 1}^{m}\mathcal{P}(y^{(i)} | x^{(i)}, \theta)</script><p>对$(1)$进行最大似然估计，解得$\phi = \frac{\sum_{i = 1}^my^{(i)}}{m} = \frac{\sum_{i = 1}^m1\{y^{(i)} = 1 \}}{m}$ 其中1是一个indicator，$1\{ y^{(i)} = 1 \}$ 返回0或者1 根据里面的东西是否正确 $1\{ true \} = 1$ 和 $1\{false\} = 0$</p><p>$\mu_0 = \frac{\sum_{i = 1}^m1\{y^{(i)} = 0 \}x^{(i)}}{\sum_{i = 1}^mi\{y^{(i)}\} = 0}$ 和 $\mu_1 = \frac{\sum_{i = 1}^m1\{y^{(i)} = 1 \}x^{(i)}}{\sum_{i = 1}^mi\{y^{(i)}\} = 1}$ 从这个式子可以看出，均值的最大似然估计就是把一个类所有的数据 然后对所有的数据取均值，这个值就是均值$\mu$的最大似然估计</p><script type="math/tex; mode=display">\Sigma = \frac{1}{n}\sum_{i = 1}^n(x^{(i)} - \mu_{y^{(i)}})(x^{(i)} - \mu_{y^{(i)}})^T</script><p>用这个模型进行预测$arg\max_y\mathcal{P}(y | x)  = arg\max_y \frac{\mathcal{P}(x | y)\mathcal{P}(y)}{\mathcal{P}(x)}$ 相对于$y$ $\mathcal{P}(x)$是个常数</p><p>所以$arg\max_y\mathcal{P}(y | x)  = arg\max_y \mathcal{P}(x | y)\mathcal{P}(y)$</p><p><strong>区别argmax 和 max 两个notation </strong></p><script type="math/tex; mode=display">\min_z(z - 5)^2 = 0 \\arg\min_z(z - 5)^2 = 5</script><p>[37:20]开始讲用Logistic Regression 和 GDA 来对数据进行分类（如果GDA两个分布的协方差矩阵不相同，那么分界面可能就不是直线了</p><h4 id="与Logistic-Regression进行比较"><a href="#与Logistic-Regression进行比较" class="headerlink" title="与Logistic Regression进行比较"></a>与Logistic Regression进行比较</h4><p>这个部分讲义里面写的非常的详细</p><p>Compared to logistic regression，for a fixed $\phi, \mu_0, \mu_1, \Sigma$, lets plot $\mathcal{P}(y = 1 | x;\phi,\mu_0,\mu_1,\Sigma) $ as a function of x [43:40] 用1维的两个高斯 来举例GDA模型</p><p>核心在于<strong>GDA for a fixed $\phi, \mu_0, \mu_1, \Sigma$, lets plot $\mathcal{P}(y = 1 | x;\phi,\mu_0,\mu_1,\Sigma)$ as a function of x 是一个sigmoid函数，但是与logistic regression的sigmoid函数得到的decision boundary是不同的</strong></p><p>GDA 是一个比logistic regression <strong>更强</strong>的假设</p><p>一般做一个更强的假设，如果假设正确，那么模型就会做的很好$($即使对于非常小的数据集$)$</p><p>如果假设错误$( \mathcal{P}(x|y)$是服从泊松分布，结果得到的也是一个sigmoid函数$)$，那么模型效果就很差；对于弱的假设，模型就会更加稳定，在大数据的时代 数据很多，用logistic regression能克服模型偏弱的缺陷</p><p><strong>老师说他仍然使用GDA之类的算法的原因是 it’s actually quite computationally efficient, 因为求$\mu$就是求个加起来取平均，求个$\Sigma$就是求个矩阵乘法</strong></p><p><strong>老师说判断一个人机器学习能力 是在于对于小样本的数据集能否训练出相当好的模型</strong></p><h3 id="Naive-Bayes"><a href="#Naive-Bayes" class="headerlink" title="Naive Bayes"></a>Naive Bayes</h3><p>naive bayes是适用于$x$离散数据</p><p>naive bayes的核心假设是<strong>Assume $x_i$’s are conditionally independent given y</strong></p><script type="math/tex; mode=display">\mathcal{P}(x_1, \cdots, x_{10000}) = \mathcal{P}(x_1|y)\mathcal{P}(x_2|y) \cdots \mathcal{P}(x_{10000}|y) = \prod_{i = 1}^{10000}\mathcal{P}(x_i | y)</script><p>参数有$\phi_{j|y=1} = \mathcal{P}(x_j = 1| y = 1), \phi_{j|y=0} = \mathcal{P}(x_j = 0| y = 0), \phi_y \quad j = 1, \cdots, n$</p><p>Joint likelihood: $\ell(\phi_j, \phi_{j|y} = \prod_{i = 1}^m \mathcal{P}(x^{(i)}, y^{(i)}; \phi_y, \phi_{j|y}))$</p><p>用MLE 解得</p><script type="math/tex; mode=display">\phi_y = \frac{\sum_{i = 1}^m1\{y^{(i)} = 1\}}{m}  \\\phi_{j | y = 1} = \frac{\sum_{i = 1}^m1\{x_j^{(i)} = 1,y^{(i)} = 1\}}{\sum_{i = 1}^m1\{y^{(i)} = 1\} }</script><p>老师说对于垃圾邮件分类，logistic regression要做的比这个好，naive bayes的优点是computationally efficient</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cs229 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>EM Algorithm Factor Analysis</title>
      <link href="2021/05/22/cs229%2015/"/>
      <url>2021/05/22/cs229%2015/</url>
      
        <content type="html"><![CDATA[<h2 id="Lecture-15-EM-Algorithm-Factor-Analysis"><a href="#Lecture-15-EM-Algorithm-Factor-Analysis" class="headerlink" title="Lecture 15 EM Algorithm Factor Analysis"></a>Lecture 15 EM Algorithm Factor Analysis</h2><p>这一章会讲到Factor analysis 这个模型对于高维少量的数据也有用</p><p>前12分钟 用上一节课讲的EM算法 来推GMM算法 每个参数是怎么更新的，M步对函数求偏导</p><h3 id="Factor-Analysis"><a href="#Factor-Analysis" class="headerlink" title="Factor Analysis"></a>Factor Analysis</h3><p>在这个模型中$z^{(i)}$不是离散的，$z^{(i)}$是连续的，而且$z^{(i)}$是高斯分布的</p><p><strong>再回顾一下上节课讲的EM算法</strong></p><p>定义$J(\theta, Q) = \sum_i\sum_{z^{(i)}}Q_i(z^{(i)})log\frac{P(x^{(i)}, z^{(i)};\theta)}{Q_i(z^{(i)})}$</p><p>由上节课 我们知道$l(\theta) \ge J(\theta, Q)$ for any $\theta, Q$ ， 另一种角度来看EM算法</p><p>E步 ：Maximize $J$ w.r.t. $Q$  即选Q让等号成立             M步 ：Maximize $J$ w.r.t. $\theta$</p><p>EM算法也被称作为 a coordinate ascent algorithm relative to this cost function $J$</p><p>老师举了个例子 n = 2 m = 100的时候 [18:30]图，两个高斯混合就够了，即$m &gt;&gt; n$的时候用GMM效果是很好的，<strong>如果$m \approx n$ 或者 $m &lt;&lt; n$的时候</strong>  比如 m = 30 n = 100</p><p>model a single Gaussian: $X \sim N(\mu, \Sigma)$   MLE: $\mu = \frac{1}{m}\sum_ix^{(i)}$ $\Sigma = \frac{1}{m}\sum_{i = 1}^m(x^{(i)} - \mu)(x^{(i)} - \mu)^T$</p><p>If $m \le n$, the $\Sigma$ will be <strong>singular</strong> 那么概率密度里面$\frac{1}{|\Sigma|^\frac{1}{2}}$就会无定义 而且对于指数项里面的$\Sigma^{-1}$也无法求, MLE失效，举了个二维空间 两个训练样本的例子，训练出来的高斯模型的轮廓将是infinitely skinny</p><p>Factorial analysis 最早出现于心理学研究中 研究100 psychological attributes 研究对象是30人</p><p>针对这个问题的想到解决方法：</p><ul><li>Constrain $\Sigma$ to be diagonal 这个模型是假设所有的特征都是不想关的，这不是一个好的假设</li><li>Constrain $\Sigma$ to be $\sigma^2I$  这个模型更糟</li></ul><p>$z \sim N(0, I),\  z \in R^d \ (d &lt; n)$  举个例子 d = 3 m = 30 n = 100</p><p>我们假设 $X = \mu + \Lambda z + \epsilon$  其中 $\epsilon \sim N(0, \Phi)$   这个模型中 每个参数为</p><script type="math/tex; mode=display">\mu \in R^n, \Lambda \in R^{n\times d},\Phi \in R^{n \times n} \ diagonal</script><p>那么 $x | z \sim N(\mu + \Lambda z, \Phi)$</p><p>d为d个main driving factors affecting the temperature of this room</p><p>老师用100个sensor测学校温度的例子来说明 这个模型，$\Phi$为对角线 说明每个sensor的噪声是相互独立的</p><p>老师举了两个例子 第一个例子 d = 1 n = 2 m = 7  第二个例子 d = 2 n = 3 m = 5</p><p>感觉有点降维的味道 第二个例子说明大部分的数据会集中在 线性变换后的平面附近，二维在三维线性变换 构成的是平面，但也可以是距离平面有点的远的地方，只要方差比较大，每一维的方差是不一样的</p><h3 id="The-derivation-of-EM-for-factor-analysis"><a href="#The-derivation-of-EM-for-factor-analysis" class="headerlink" title="The derivation of EM for factor analysis"></a>The derivation of EM for factor analysis</h3><p>推理比较tricky 视频最后30分钟 推导公式中比较tricky的部分 这要看讲义 光看视频看不懂 一脸懵逼</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cs229 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Expectation-Maximization Algorithms</title>
      <link href="2021/05/22/cs229%2014/"/>
      <url>2021/05/22/cs229%2014/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.bilibili.com/video/BV1JE411w7Ub?p=19">视频链接</a></p><h2 id="Lecture-14-Expectation-Maximization-Algorithms"><a href="#Lecture-14-Expectation-Maximization-Algorithms" class="headerlink" title="Lecture 14 Expectation-Maximization Algorithms"></a>Lecture 14 Expectation-Maximization Algorithms</h2><h3 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h3><p>[2:45] 开始演示了K-means的动画</p><p>Data $\{x^{(1)},x^{(2)},x^{(3)},,\cdots,x^{(m)}\}$</p><p>step 1 Initialize cluster centroids  $\mu_1,\cdots,\mu_k$ randomly，对于高维数据 一般是随机选k个训练样本，把这k个样本做为质心</p><p>step 2 Repeat until convergence</p><ul><li><p>Set $c^{(i)} := argmin_j ||x^{(i)} - \mu_j||^2$</p></li><li><p>For $j = 1, \cdots, k$</p><p>​    $\mu_j := \frac{\sum_{i = 1}^m 1\{c^{(i)} = j \} x^{(i)}}{\sum_{i = 1}^m i\{c^{(i) }= j\}}$</p></li></ul><p>这个算法是会收敛的</p><p>这个算法的cost function是$j(c,\mu) = \sum_{i = 1}^m || x^{(i)} - \mu_{c^{(i)}}||^2$</p><p>K-means 会收敛到局部最小值， 所以要多多初始化几次 选最好的一次</p><h3 id="Density-estimation"><a href="#Density-estimation" class="headerlink" title="Density estimation"></a>Density estimation</h3><p>可用于anomaly detection， model $p(x)$ 如果一个样本 $p(x) &lt; \epsilon$ 那么这个样本就是异常</p><p>the mixture of Gaussians model [21:03] 有图形，motivation就是anomaly detection</p><p>老师举了一个一维的例子，这个算法很像GDA，但是GMM不知道每个示例是属于哪个高斯的</p><p>EM算法能让我们尽管不知道每个样本是来自哪个高斯也能fit a model</p><p>Suppose there is a latent random variable $z$ and $x^{(i)},z^{(i)} $ </p><script type="math/tex; mode=display">P(x^{(i)}, z^{(i)}) = P(x^{(i)} | z^{(i)})P(z^{(i)})</script><p>where $z^{(i)} \sim Multinomial(\phi)$  $x^{(i)} | z^{(i)} = j \sim N(\mu_j, \Sigma_j)$</p><p>If we knew the $z^{(i)}$’s, we can use MLE  这就是GDA了</p><p><strong>E-step</strong> Guess value of $z^{(i)}$’s</p><p>Set $w^{(i)}_j = P(z^{(i)}) = j |x^{(i)}; \phi, \mu, \Sigma) = \frac{P(x^{(i)}|z^{(i)} = j)P(z^{(i) = j})}{\sum_{i = 1}^k p(x^{(i)}|z^{(i)} = l)P(z^{(i)} = l)}$</p><p>$w^{(i)}_j$ is  how much $x^{(i)}$ is assigned to the $\mu_j$ Gaussian</p><p>where $P(x^{(i)}|z^{(i)} = j) \sim N(\mu_j, \Sigma_j)$ and $P(z^{(i)} = j) = \phi_j$</p><p><strong>M-step</strong> 用E步里面得到的$w^{(i)}_j$来计算$\phi_j$和$\mu_j$和$\Sigma_j$</p><p><strong>发现没</strong> 这个很像K-means的过程！<strong>EM算法是一个框架</strong></p><p>当EM算法结束，就有了$P(x, z)$的联合分布 那么x的概率就是</p><script type="math/tex; mode=display">P(x) = \sum_kP(x, z)</script><p><strong>666</strong></p><h3 id="EM推理"><a href="#EM推理" class="headerlink" title="EM推理"></a>EM推理</h3><p><strong>Jensen’s inequality</strong></p><p>Let $f$ be a convex function e.g. $f^{\prime\prime}(x) \ge 0$</p><p>Let $X$ be a random variable Then $f(E[X]) \le E[f(X)]$</p><p>如果$f^{\prime\prime}(x) &gt; 0$ 那么$E[f(x)] = f(E[x]) \iff X \ is \ a\ constant$</p><p>如果$f$是一个strictly convex function 那么意思是$f$是一条直线</p><p>Have model for $P(x, z; \theta)$ Only observe $x$ , $\{x^{(1)}, x^{(2)}, \cdots, x^{(m)}\}$</p><script type="math/tex; mode=display">l(\theta) = \sum_{i = 1}^m logP(x^{(i)}; \theta) = \sum_{i = 1}^mlog\sum_{z(i)}P(x^{(i)},z^{(i)};\theta) \tag{1}</script><p>want to find $argmax_\theta l(\theta)$</p><p>图[61:37]E步是构造一个下界函数 即绘制绿色曲线，M步是找到这个曲线的最大值； 这个动画非常棒</p><p>EM算法可能会收敛于局部最优值，需要进行多次初始化 取最佳 就可以得到全局最优值 </p><p>1式继续变化得</p><script type="math/tex; mode=display">=\sum_i log\sum_{z^{(i)}}Q_i(z^{(i)})\frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})}</script><p>where $Q_i(z^{(i)})$是概率分布 i.e. $\sum_{z^{(i)}}Q_i(z^{(i)}) = 1$</p><p>继续化简</p><script type="math/tex; mode=display">= \sum_ilogE_{z^{(i)}\sim Q_i}[\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}] \ge \sum_iE_{z^{(i)}\sim Q_i}[log\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}]</script><script type="math/tex; mode=display">= \sum_i \sum_{z^{(i)}}Q_i(z^{(i)})log\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})} \tag{3}</script><p>对于3式 x式固定得，z是求和得，只有$\theta$是变量 可看作是$\theta$的函数</p><p>On a given iteration of EM with parameters $\theta$, we want:</p><script type="math/tex; mode=display">\sum_ilogE_{z^{(i)}\sim Q_i}[\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}] = \sum_iE_{z^{(i)}\sim Q_i}[log\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}]</script><p>For this to hold true 需要$\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}$ 是常数</p><p>Set $Q_i(z^{(i)})$正比于$P(x^{(i)}, z^{(i)}; \theta)$</p><p>取法就是$Q_i(z^{(i)}) = \frac{P(x^{(i)}, z^{(i)}; \theta)}{\sum_{z^{(i)}}P(x^{(i)}, z^{(i)}; \theta)} = P(z^{(i)} | x^{(i)};\theta)$</p><p>总结一下就是：</p><p>E-step : Set $Q_i(z^{(i)}) = P(z^{(i)} | x^{(i)};\theta)$</p><p>M-step: $\theta := argmax_\theta\sum_i\sum_{z^{(i)}}Q_i(z^{(i)})log\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}$</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cs229 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Debug ML Models and Error Analysis</title>
      <link href="2021/05/22/cs229%2013/"/>
      <url>2021/05/22/cs229%2013/</url>
      
        <content type="html"><![CDATA[<h2 id="Lecture-13-Debug-ML-Models-and-Error-Analysis"><a href="#Lecture-13-Debug-ML-Models-and-Error-Analysis" class="headerlink" title="Lecture 13 Debug ML Models and Error Analysis"></a>Lecture 13 Debug ML Models and Error Analysis</h2><p>感觉这节课很重要~  PS 想到深度学习能自动提取特征就非常的nice</p><p><a href="https://www.bilibili.com/video/BV1JE411w7Ub?p=17">视频链接</a></p><h3 id="Motivating-example"><a href="#Motivating-example" class="headerlink" title="Motivating example"></a>Motivating example</h3><p>当训练出的模型 的准确率不符合预期的时候：</p><ul><li><p>Common approach: Try improving the algorithm in different ways</p><ul><li>Try getting more training examples        Fixes high variance</li><li>Try a smaller set of features         Fixes high variance</li><li>Try a larger set of features          Fixes high bias</li><li>Try changing the features: Email header vs. email body features   Fixes high bias</li><li>Run gradient descent for more iterations    Fixes optimization algorithm</li><li>Try Newton’s method                    Fixes optimization algorithm</li><li>Use a different value for $\lambda $           Fixes optimization objective</li><li>Try using another algorithm     Fixes optimization objective</li></ul><p>一般会玄学地从中选一个</p></li><li><p><strong>bias vs variance diagnostic</strong></p><ul><li>Variance: Training error will be much lower than test error</li><li>Bias: Training error will also be high</li></ul></li></ul><p>老师画的图 [14:16] 横坐标是<strong>training set size</strong> 纵坐标是<strong>error</strong></p><p>当training set个数少的时候，training error是可以为0的 比如对于线性回归，1个点或两个点 training error就为0，数据量变多的时候 training error 会跟着涨</p><p><strong>重要</strong> as you increase the training set size , you find that the gap between training and test error usually closes <strong>如果test error 和 training error 有较大的gap 那么就是high variance</strong></p><p>对于high bias的情况，training error is unacceptable high，small gap between training and test error</p><p><strong>A very small gap between the training and the test error, 当图像是这样的话，不管再获得多少数据，error基本不会变</strong> </p><p><strong>PS 对于现在batch的形式，老师的这个图是有效的吗，如何实现training set增加，比如我有1000个数据集 我想让数据集从0到1000 数据集大小为100的时候 我该怎么挑数据</strong></p><p>常见的问题  Is the algorithm converging? 就是gradient descent有没有收敛</p><p>或者是 是否在优化错误的函数</p><p>即 到底是优化的函数的锅 还是优化方法的锅</p><p>对于区分non-spam 和 spam邮件，可以会不同类型设置不同的权重，比如希望能检测出spam，希望尽量减小漏掉spam的概率，spam的cost就大一些</p><h3 id="SVM-LR-Example"><a href="#SVM-LR-Example" class="headerlink" title="SVM LR Example"></a>SVM LR Example</h3><p>An SVM outperforms logistic regression, but you really want to deploy logistic regression for your application.</p><p>Let $\theta_{SVM}$ be the parameters learned by an SVM</p><p>Let $\theta_{BLR}$ be the parameters learned by logistic regression</p><p>You care about weighted accuracy:</p><script type="math/tex; mode=display">a(\theta)  = max_\theta \sum_i \omega^{(i)}1\{ h_\theta(x^{(i)}) = y^{(i)}\}</script><p>$\theta_{SVM}$ outperforms $\theta_{BLR}$. So:  $a(\theta_{SVM}) &gt; a(\theta_{BLR})$</p><p>BLR Binary Logistic Regression tries to maximize:</p><script type="math/tex; mode=display">J(\theta) = \sum_{i = 1}^mlogp(y^{(i)}|x^{(i)},\theta) - \lambda||\theta||^2</script><p>Diagnostic: $J(\theta_{SVM}) &gt; J(\theta_{BLR}) ?$</p><p>Case 1：$a(\theta_{SVM}) &gt; a(\theta_{BLR}) \ \ J(\theta_{SVM}) &gt; J(\theta_{BLR}) $</p><p>This means that $\theta_{BLR}$ fails to maximize $J$, adn the problem is with the convergence of the algorithm. Problem is with optimization algorithm</p><p>Case 2：$a(\theta_{SVM}) &gt; a(\theta_{BLR}) \ \ J(\theta_{SVM}) \le J(\theta_{BLR}) $</p><p>This means that BLR succeeded at maximizing $J(\theta)$, But the SVM, which does worse on $J(\theta)$, actually does better on weighted accuracy $a(\theta)$.</p><p>This means that $J(\theta)$ is the wrong function to be maximizing, if you care about $a(\theta)$. Problem is with objective function of the maximization problem.</p><h3 id="自动飞行器的例子"><a href="#自动飞行器的例子" class="headerlink" title="自动飞行器的例子"></a>自动飞行器的例子</h3><p>1 Build a simulator of helicopter</p><p>2 Choose a cost function</p><p>3 Run reinforcement learning algorithm to fly helicopter in simulation, so as to try to minimize cost function</p><p>如果训练出来的$\theta_{RL}$ 比人类pilot差很多  那么要么改进模拟器 要么改进cost function 要么改进optimization algorithm</p><p>Let $\theta_{human}$ be the human control policy. If $J(\theta_{human}) &lt; J(\theta_{RL})$，then the problem is in the reinforcement learning algorithm.</p><p>If  $J(\theta_{human}) \ge J(\theta_{RL})$，then the problem is in the cost function.</p><p>Finding a good cost function is really difficult</p><h3 id="Error-Analysis-Tool"><a href="#Error-Analysis-Tool" class="headerlink" title="Error Analysis Tool"></a>Error Analysis Tool</h3><pre class="line-numbers language-mermaid" data-language="mermaid"><code class="language-mermaid">graph LRid(Camera image) --&gt; id2(Preprocessing)id2 --&gt; id3(Facedetection) --&gt;id4(Eyes Segmentation) &amp; id5(Nose segmentation) &amp; id6(Mouth segmentation) --&gt; id7(Logistic regression) --&gt; id8(Label)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>现实中的项目 涉及到多个component</p><p>How much error is attributable to each of the components ?</p><p>Plug in ground-truth for each component, and see how accuracy changes.</p><p>可以是累积式 即到检测某个模块之前的所有模块都是真实数据，也可以是非累积性的， 即测哪个哪个真实 其余非真实</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cs229 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CSS基础 III</title>
      <link href="2021/05/16/css3/"/>
      <url>2021/05/16/css3/</url>
      
        <content type="html"><![CDATA[<p>这是学堂在线上面的前端课程<a href="https://www.xuetangx.com/search?query=%E5%89%8D%E7%AB%AF&amp;page=1">课程链接</a></p><h3 id="CSS-Transform"><a href="#CSS-Transform" class="headerlink" title="CSS Transform"></a>CSS Transform</h3><p>是对元素进行平移translate， 旋转rotate，缩放scale， 倾斜skew</p><p><strong>transform不会的对其它元素布局产生影响</strong></p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.emoji</span><span class="token punctuation">&#123;</span>    <span class="token property">transform</span> <span class="token punctuation">:</span> <span class="token function">translate</span><span class="token punctuation">(</span>100px<span class="token punctuation">,</span> 100px<span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token selector">.emoji</span><span class="token punctuation">&#123;</span>    <span class="token property">transform</span> <span class="token punctuation">:</span> <span class="token function">translateX</span><span class="token punctuation">(</span>100px<span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token selector">.emoji</span><span class="token punctuation">&#123;</span>    <span class="token property">transform</span> <span class="token punctuation">:</span> <span class="token function">translateY</span><span class="token punctuation">(</span>-1em<span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token selector">.emoji</span><span class="token punctuation">&#123;</span>    <span class="token property">transform</span> <span class="token punctuation">:</span> <span class="token function">translate</span><span class="token punctuation">(</span>100%<span class="token punctuation">,</span> 100%<span class="token punctuation">)</span> 这是移动自身大小的距离<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.emoji</span><span class="token punctuation">&#123;</span>    <span class="token property">transform</span><span class="token punctuation">:</span> <span class="token function">translateX</span><span class="token punctuation">(</span>100px<span class="token punctuation">)</span>           <span class="token function">rotate</span><span class="token punctuation">(</span>90deg<span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>先延X轴移动100px  然后顺时针旋转90度</p><p><strong>如果是先rotate 90度， 然后再translate 100px 那么效果不一样，因为rotate 90度之后 X轴变为向下方向的了</strong></p><p>还可以进行3D 变换</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.emoji</span><span class="token punctuation">&#123;</span>    <span class="token property">transform</span> <span class="token punctuation">:</span> <span class="token function">perspective</span><span class="token punctuation">(</span>100px<span class="token punctuation">)</span>        <span class="token function">rotateY</span><span class="token punctuation">(</span>40deg<span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>perspective 设置的是屏幕举例人眼的距离</p><p>translate3d(dx, dy, dz) 最后一个是z轴方向的偏移量</p><h3 id="CSS-Transition-即过渡效果"><a href="#CSS-Transition-即过渡效果" class="headerlink" title="CSS Transition 即过渡效果"></a>CSS Transition 即过渡效果</h3><p>指定从一个状态到另一个状态时如何过渡</p><p>动画的意义：告诉用户发生了什么</p><p>transition属性：</p><ul><li>transition-property 哪个属性改变的时候 需要发生过渡</li><li>transition-duration 这个过渡需要持续多长时间</li><li>transition-timing-function 这个变化是匀速的 还是先快后慢 先慢后快</li><li>transition-delay  发生改变的延时</li></ul><p><strong>666</strong></p><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>box<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span><span class="token punctuation">></span></span><span class="token style"><span class="token language-css">    <span class="token selector">.box</span><span class="token punctuation">&#123;</span>        <span class="token property">height</span> <span class="token punctuation">:</span> 200px<span class="token punctuation">;</span>        <span class="token property">background</span> <span class="token punctuation">:</span> coral<span class="token punctuation">;</span>        <span class="token property">transition-property</span> <span class="token punctuation">:</span> height<span class="token punctuation">;</span>        <span class="token property">transition-duration</span> <span class="token punctuation">:</span> 1s<span class="token punctuation">;</span>        <span class="token property">transition-timing-function</span> <span class="token punctuation">:</span> linear<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token selector">.box : hover</span><span class="token punctuation">&#123;</span>        <span class="token property">height</span> <span class="token punctuation">:</span> 400px<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>transition: all 1s linear  任意一个属性发生变化 都会有变化效果，变化时间为1s， 匀速变化</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.box</span><span class="token punctuation">&#123;</span>    <span class="token property">height</span> <span class="token punctuation">:</span> 200px<span class="token punctuation">;</span>    <span class="token property">background</span> <span class="token punctuation">:</span> coral<span class="token punctuation">;</span>    <span class="token property">transition</span> <span class="token punctuation">:</span> all 1s linear<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token selector">.box : hover</span><span class="token punctuation">&#123;</span>    <span class="token property">height</span> <span class="token punctuation">:</span> 400px<span class="token punctuation">;</span>    <span class="token property">background</span> <span class="token punctuation">:</span> green<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>也可以对于不同属性的变化 设置不同的效果</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.box</span><span class="token punctuation">&#123;</span>    <span class="token property">height</span> <span class="token punctuation">:</span> 200px<span class="token punctuation">;</span>    <span class="token property">background</span> <span class="token punctuation">:</span> coral<span class="token punctuation">;</span>    <span class="token property">transition</span> <span class="token punctuation">:</span> height 500ms linear<span class="token punctuation">,</span>         background 2s linear<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下面是设置delay</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.box</span><span class="token punctuation">&#123;</span>    <span class="token property">height</span> <span class="token punctuation">:</span> 200px<span class="token punctuation">;</span>    <span class="token property">width</span> <span class="token punctuation">:</span> 400px<span class="token punctuation">;</span>    <span class="token property">background</span> <span class="token punctuation">:</span> coral<span class="token punctuation">;</span>    <span class="token property">transition</span> <span class="token punctuation">:</span> height 1s linear<span class="token punctuation">,</span>             width 1s linear 1s<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token selector">.box:hover</span><span class="token punctuation">&#123;</span>    <span class="token property">height</span> <span class="token punctuation">:</span> 400px<span class="token punctuation">;</span>    <span class="token property">width</span> <span class="token punctuation">:</span> 100px<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="CSS-Animation"><a href="#CSS-Animation" class="headerlink" title="CSS  Animation"></a>CSS  Animation</h3><p>实现更复杂的样式变化效果</p><p>使用方法：</p><ul><li>定义关键帧样式</li><li>应用动画到元素上</li></ul><p><strong>666</strong></p><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>scroll-down<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    ↓<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span><span class="token punctuation">></span></span><span class="token style"><span class="token language-css">    <span class="token atrule"><span class="token rule">@keyframes</span> down</span> <span class="token punctuation">&#123;</span>        <span class="token selector">from</span><span class="token punctuation">&#123;</span>            <span class="token property">margin-top</span> <span class="token punctuation">:</span> 0<span class="token punctuation">;</span>            <span class="token property">opacity</span> <span class="token punctuation">:</span> 1<span class="token punctuation">;</span>        <span class="token punctuation">&#125;</span>        <span class="token selector">50%</span><span class="token punctuation">&#123;</span>            <span class="token property">margin-top</span> <span class="token punctuation">:</span> 0.5em<span class="token punctuation">;</span>            <span class="token property">opacity</span> <span class="token punctuation">:</span> 0.3<span class="token punctuation">;</span>        <span class="token punctuation">&#125;</span>        <span class="token selector">to</span><span class="token punctuation">&#123;</span>            <span class="token property">margin-top</span><span class="token punctuation">:</span> 0<span class="token punctuation">;</span>            <span class="token property">opacity</span> <span class="token punctuation">:</span> 1<span class="token punctuation">;</span>        <span class="token punctuation">&#125;</span>    <span class="token punctuation">&#125;</span>        <span class="token selector">.scroll-down</span><span class="token punctuation">&#123;</span>        <span class="token property">position</span><span class="token punctuation">:</span> fixed<span class="token punctuation">;</span>        <span class="token property">top</span><span class="token punctuation">:</span> 50%<span class="token punctuation">;</span>        <span class="token property">left</span><span class="token punctuation">:</span> 50%<span class="token punctuation">;</span>        <span class="token property">transform</span><span class="token punctuation">:</span> <span class="token function">translate</span><span class="token punctuation">(</span>-50%<span class="token punctuation">,</span> 50%<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token property">font</span><span class="token punctuation">:</span> normal normal 100px/1 Helvetica<span class="token punctuation">;</span>        <span class="token property">color</span><span class="token punctuation">:</span> #f66<span class="token punctuation">;</span>        <span class="token property">animation</span><span class="token punctuation">:</span> down 1.5s ease infinite<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>animation 属性：</p><ul><li>animation-name 关键帧的名字</li><li>animation-duration 动画的持续时间</li><li>animation-timing-function 关键帧之间过渡的快慢</li><li>animation-delay 动画播放的延时</li><li>animation-iteration-count 动画播放的次数</li><li>animation-direction 动画是正序播放还是倒叙序播放</li></ul><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>beats<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    ❤<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span><span class="token punctuation">></span></span><span class="token style"><span class="token language-css">    <span class="token atrule"><span class="token rule">@keyframes</span> beats</span><span class="token punctuation">&#123;</span>        <span class="token selector">from</span><span class="token punctuation">&#123;</span>            <span class="token property">transform</span> <span class="token punctuation">:</span> <span class="token function">scale</span><span class="token punctuation">(</span>1<span class="token punctuation">)</span>        <span class="token punctuation">&#125;</span>        <span class="token selector">to</span><span class="token punctuation">&#123;</span>            <span class="token property">transform</span><span class="token punctuation">:</span> <span class="token function">scale</span><span class="token punctuation">(</span>2<span class="token punctuation">)</span>        <span class="token punctuation">&#125;</span>    <span class="token punctuation">&#125;</span>    <span class="token selector">.beats</span><span class="token punctuation">&#123;</span>        <span class="token property">position</span><span class="token punctuation">:</span> fixed<span class="token punctuation">;</span>        <span class="token property">top</span><span class="token punctuation">:</span> 50%<span class="token punctuation">;</span>        <span class="token property">left</span><span class="token punctuation">:</span> 50%<span class="token punctuation">;</span>        <span class="token property">margin-top</span><span class="token punctuation">:</span> -0.5em<span class="token punctuation">;</span>        <span class="token property">margin-left</span><span class="token punctuation">:</span> -0.5em<span class="token punctuation">;</span>        <span class="token property">font</span><span class="token punctuation">:</span> normal normal 100px/1 Helvetica<span class="token punctuation">;</span>        <span class="token property">color</span><span class="token punctuation">:</span> #f66<span class="token punctuation">;</span>        <span class="token property">animation</span><span class="token punctuation">:</span> beats 1s ease infinite<span class="token punctuation">;</span>        <span class="token property">animation-direction</span><span class="token punctuation">:</span> alternate<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="响应式设计"><a href="#响应式设计" class="headerlink" title="响应式设计"></a>响应式设计</h3><p>响应式设计是同一个页面可以适应不同屏幕大小设备的设计方案</p><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">name</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>viewport<span class="token punctuation">"</span></span> <span class="token attr-name">content</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>width = device-width, initial-scale = 1.0<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于PC页面采用的视口大小 就是浏览器窗口的大小， 对于手机浏览器就不是这样，出于兼容以前PC网页的考虑，</p><p>手机浏览器在布局的时候使用的视口宽度是980px，而手机浏览器的宽度一般比这个要小，所以 整个页面会被缩小，为了让手机浏览器有更好的体验，要告诉手机浏览器不要使用980px的视口大小，而是使用和设备宽度的小</p><p>上面的代码就是干这个的</p><p>图片尺寸设置 适应不同的宽度</p><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">src</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>...<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span><span class="token punctuation">></span></span><span class="token style"><span class="token language-css">    <span class="token selector">img</span><span class="token punctuation">&#123;</span>        <span class="token property">max-width</span> <span class="token punctuation">:</span> 100%<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>让背景图片适应不同的宽度</p><p>background-size : contain; 把图片自动缩放到容器内，把图片完整展示出来</p><p>background-size : cover;  把图片缩放到覆盖整个容器的大小 某些内容会被裁切掉</p><p>针对 不同屏幕尺寸 应用不同的样式 用media query</p><pre class="line-numbers language-html" data-language="html"><code class="language-html">@media screen and (min-width: 480px)&#123;.box&#123;font-size : 16px;&#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以查询的media： width、height 、device-height、device-width、device-pixel-ratio、orientation</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">body</span><span class="token punctuation">&#123;</span>    <span class="token property">margin</span><span class="token punctuation">:</span> 0<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token selector">nav</span><span class="token punctuation">&#123;</span>    <span class="token property">display</span><span class="token punctuation">:</span> flex<span class="token punctuation">;</span>    <span class="token property">background</span><span class="token punctuation">:</span> lightblue<span class="token punctuation">;</span>    <span class="token property">line-height</span><span class="token punctuation">:</span> 2<span class="token punctuation">;</span>    <span class="token property">justify-content</span><span class="token punctuation">:</span> space-around<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token atrule"><span class="token rule">@media</span> screen <span class="token keyword">and</span> <span class="token punctuation">(</span><span class="token property">max-width</span><span class="token punctuation">:</span> 480px<span class="token punctuation">)</span></span><span class="token punctuation">&#123;</span>    <span class="token selector">nav</span><span class="token punctuation">&#123;</span>        <span class="token property">flex-direction</span><span class="token punctuation">:</span> column<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用不同尺寸的图片 要考虑流量的问题，在手机 上不需要高分辨率的图片</p><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">srcset</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>/img/large.jpg 1200w,               /img/normal.jpg 800w,               /img/small.jpg 400w<span class="token punctuation">"</span></span>     <span class="token attr-name">sizes</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>(max-width: 320px) 400px,              (max-width: 640px) 800px,              1200px<span class="token punctuation">"</span></span>     <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>...<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>设置字体大小的套路之一</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">html</span><span class="token punctuation">&#123;</span>    <span class="token property">font-size</span> <span class="token punctuation">:</span> 18px<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token selector">article h1</span><span class="token punctuation">&#123;</span>    <span class="token property">font-size</span> <span class="token punctuation">:</span> 2rem<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token selector">article p</span><span class="token punctuation">&#123;</span>    <span class="token property">font-size</span> <span class="token punctuation">:</span> 1rem<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token atrule"><span class="token rule">@media</span> screen <span class="token keyword">and</span> <span class="token punctuation">(</span><span class="token property">max-width</span><span class="token punctuation">:</span> 480px<span class="token punctuation">)</span></span><span class="token punctuation">&#123;</span>    <span class="token selector">html</span><span class="token punctuation">&#123;</span>        <span class="token property">font-size</span><span class="token punctuation">:</span> 14px    <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>里面的r 代表着root的意思</p><h3 id="处理CSS的兼容性"><a href="#处理CSS的兼容性" class="headerlink" title="处理CSS的兼容性"></a>处理CSS的兼容性</h3><p>了解浏览器支持的情况</p><ul><li>caniuse.com</li><li>MDN CSS Reference</li><li>Codrops CSS Reference</li><li>QuirksMode.org CSS</li></ul><p><strong>处理浏览器不支持的情况</strong></p><p>浏览器hack原理 同一个属性，后面书写的值覆盖前面书写的值</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">p</span><span class="token punctuation">&#123;</span>    <span class="token property">display</span><span class="token punctuation">:</span> table<span class="token punctuation">;</span>    <span class="token property">display</span><span class="token punctuation">:</span> flex<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>对于不支持flex的浏览器就会用table </p><p>条件注释</p><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token comment">&lt;!--[if IE 7]>&lt;p>只能在IE 7下看到我&lt;/p>&lt;![endif]--></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>还可以用浏览器的怪癖 略掉</p>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CSS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CSS基础 II</title>
      <link href="2021/05/16/css2/"/>
      <url>2021/05/16/css2/</url>
      
        <content type="html"><![CDATA[<p>这是学堂在线上面的前端课程<a href="https://www.xuetangx.com/search?query=%E5%89%8D%E7%AB%AF&amp;page=1">课程链接</a></p><h3 id="CSS-布局概述"><a href="#CSS-布局概述" class="headerlink" title="CSS 布局概述"></a>CSS 布局概述</h3><p>[00:15] 图片 显示了Header Nav Content Footer的布局</p><p>布局 Layout 确定内容的大小和位置的算法， 依据元素、容器、兄弟节点和内容等信息来计算</p><p>定位有三种模式： <strong>常规流</strong> Normal Flow， <strong>浮动</strong>， <strong>绝对定位</strong></p><p>常规流里面包含：行级， 块级， 表格布局， Flexbox，Grid布局</p><p>​    根元素、浮动和绝对定位的元素会脱离常规流</p><p>​    其它元素都在常规流之内， 常规流中的盒子，在某种排版上下文中参与布局</p><p>行级排版上下文 Inline Formatting Context IFC</p><p>只包含行级盒子的容器会创建一个IFC， IFC内的排版规则</p><ul><li>盒子在一行内水平摆放</li><li>一行放不下时，换行显示</li><li>text-align决定一行内盒子的水平对齐</li><li>vertical-align 决定一行内盒子的水平对齐</li><li>避开浮动 float 元素</li></ul><p>块级排版上下文 Block Formatting Context BFC</p><p>某些容器会创建一个BFC</p><ul><li>根元素</li><li>浮动、 绝对定位、 inline-block</li><li>Flex子项 和 Grid子项</li><li>overflow值不是visible的块盒</li></ul><p><strong>BFC内的排版规则</strong></p><ul><li>盒子从上到下摆放</li><li>垂直margin合并</li><li>BFC内盒子的margin不会与外面的合并</li><li>BFC不会和浮动元素重叠</li></ul><p>在流中 一个盒子的子盒子只能是全部是块级 或者全部是行级，如果一个容器中又有行级又有块级</p><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>span</span><span class="token punctuation">></span></span>    This is atext and     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span><span class="token punctuation">></span></span>    block    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>    and other text<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>span</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>html 会将行级的盒子包含在一个匿名的块级盒子里面</p><h3 id="Flexible-Box"><a href="#Flexible-Box" class="headerlink" title="Flexible Box"></a>Flexible Box</h3><p>Flexible Box是一种新的排版上下文，它可以控制子级盒子的摆放流向，摆放顺序，盒子宽度和高度，水平和垂直方向的对齐，是否允许拆行</p><p><strong>666</strong> 设置display: flex 使元素生成也给块级的Flex容器； display: inline-flex 使元素生成一个行级的Flex容器</p><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>container<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>a<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        A    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>b<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        B    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>c<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        C    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span><span class="token punctuation">></span></span><span class="token style"><span class="token language-css">    <span class="token selector">.container</span><span class="token punctuation">&#123;</span>        <span class="token property">display</span> <span class="token punctuation">:</span> flex<span class="token punctuation">;</span>        <span class="token property">border</span> <span class="token punctuation">:</span> 2px solid red<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token selector">.a, .b, .c</span><span class="token punctuation">&#123;</span>        <span class="token property">text-align</span> <span class="token punctuation">:</span> center<span class="token punctuation">;</span>        <span class="token property">padding</span> <span class="token punctuation">:</span> 1em<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token selector">.a</span> <span class="token punctuation">&#123;</span> <span class="token property">background</span> <span class="token punctuation">:</span> #fcc<span class="token punctuation">;</span> <span class="token punctuation">&#125;</span>    <span class="token selector">.b</span> <span class="token punctuation">&#123;</span> <span class="token property">background</span> <span class="token punctuation">:</span> #cfc<span class="token punctuation">;</span> <span class="token punctuation">&#125;</span>    <span class="token selector">.c</span> <span class="token punctuation">&#123;</span> <span class="token property">background</span> <span class="token punctuation">:</span> #ccf<span class="token punctuation">;</span> <span class="token punctuation">&#125;</span></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面代码里面的div 就不是按块级的排列 从上到下，而是按照flex的排版，从左到右</p><p><strong>可以用flex-direction来控制flex内的流向</strong></p><p>flex-direction: row 或者 row-reverse 或者 column 从上到下 或者 column-reverse</p><p>当子元素比较多的时候 可以用flex-wrap来控制是否换行  默认使nowrap 就是不换行</p><p><strong>之所以叫flex 是因为里面的元素是可以设置弹性的 即flexibility</strong></p><p>flex-grow 有剩余空间时的伸展能力 flex-shrink 容器空间不足时收缩能力 flex-basis 没有伸展或收缩时的基础长度</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.a, .b, .c</span><span class="token punctuation">&#123;</span><span class="token property">width</span> <span class="token punctuation">:</span> 100px<span class="token punctuation">&#125;</span><span class="token selector">.a</span><span class="token punctuation">&#123;</span> <span class="token property">flex-grow</span> <span class="token punctuation">:</span> 2<span class="token punctuation">&#125;</span><span class="token selector">.b</span><span class="token punctuation">&#123;</span> <span class="token property">flex-grow</span> <span class="token punctuation">:</span> 1<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>c是100px， a 和 b填充剩余空间， 且a的宽度是b的两倍 计算方法是把容器的宽度减去300px 剩余的空间按照2 ： 1分别分配给a 和 b</p><p>flex-shrink 的默认值是1 默认是可以收缩的</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.a, .b, .c</span> <span class="token punctuation">&#123;</span> <span class="token property">width</span> <span class="token punctuation">:</span> 70% <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>显示出来是三个平分整个空间，但不是70%</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.a, .b, .c</span> <span class="token punctuation">&#123;</span> <span class="token property">width</span> <span class="token punctuation">:</span> 70% <span class="token punctuation">&#125;</span><span class="token selector">.a</span> <span class="token punctuation">&#123;</span><span class="token property">flex-shrink</span> <span class="token punctuation">:</span> 0<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>a不能收缩了，a的宽度必须是70% ； 如果b也设为不能收缩的时候， a和b就会溢出容器</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.a</span><span class="token punctuation">&#123;</span>    <span class="token property">width</span> <span class="token punctuation">:</span> 20%<span class="token punctuation">;</span>    <span class="token property">flex-basis</span> <span class="token punctuation">:</span> 50%<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>flex-basis的优先级是高于width的 会覆盖width</p><p>如果div a 、div b、 div c里面的字的个数是不一样的，那么宽度不一样</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.a, .b, .c</span><span class="token punctuation">&#123;</span>    <span class="token property">flex-grow</span> <span class="token punctuation">:</span> 1<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>三个框就不一样宽，因为是总宽减三宽之和，得的差除3 后分别加到三个div上 宽度不一样</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.a, .b, .c</span><span class="token punctuation">&#123;</span>    <span class="token property">flex</span> <span class="token punctuation">:</span> 1 1 0<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>这样设置 三个宽度就是一样的了</p><p>flex-direction的方向称为主轴，和主轴的垂直方向称为侧轴，要设置元素在主轴方向的对齐 用</p><p>justify-content 可以设置为flex-start flex-end center space-between space-around space-evenly</p><p>flex-start 主轴出发的方向  space-between 是a、b、c中间有空白，space-around 是 a、b、c中间和两边都有空白，align-items 是设置测轴方向的对齐 flex-start flex-end center baseline stretch</p><p><strong>可以给容器中某一个元素设置对齐方式</strong> 就是设置align-self</p><p>[05:17]的图片 显示了 align-items 和 align-content 一起使用时的效果，一个行内 一个行间</p><p>可以设置order 属性来决定排列顺序，排列顺序是按order的从小到大的顺序来排列</p><p><strong>感觉按照这个知识点 可以写出一个2048的游戏</strong></p><p>视频举了一个用flex来布局的博客</p><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>header</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h1</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>logo<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        My Blog    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h1</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>nav</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>#<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Home<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>#<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Posts<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>#<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>About<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>nav</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>header</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>wrapper<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>main</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>article</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h2</span><span class="token punctuation">></span></span>                 My blog title            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h2</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>                Some content in paragraph 1            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>                Some content in paragraph 2            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>                Some content in paragraph 3            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>                Some content in paragraph 4            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>article</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>main</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>aside</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h3</span><span class="token punctuation">></span></span>            Hot topics        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h3</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ul</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>#<span class="token punctuation">"</span></span><span class="token punctuation">></span></span> Topic 1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>#<span class="token punctuation">"</span></span><span class="token punctuation">></span></span> Topic 2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>#<span class="token punctuation">"</span></span><span class="token punctuation">></span></span> Topic 3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ul</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>aside</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>footer</span><span class="token punctuation">></span></span>    Copyrights <span class="token entity named-entity" title="&copy;">&amp;copy;</span> 2018<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>footer</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span><span class="token punctuation">></span></span><span class="token style"><span class="token language-css">    <span class="token selector">header</span><span class="token punctuation">&#123;</span>        <span class="token property">display</span> <span class="token punctuation">:</span> flex<span class="token punctuation">;</span>        <span class="token property">align-items</span> <span class="token punctuation">:</span> center<span class="token punctuation">;</span>        <span class="token property">background</span> <span class="token punctuation">:</span> coral<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token selector">nav</span><span class="token punctuation">&#123;</span>        <span class="token property">flex-grow</span> <span class="token punctuation">:</span> 1<span class="token punctuation">;</span>        <span class="token property">text-align</span> <span class="token punctuation">:</span> right<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token selector">.wrapper</span><span class="token punctuation">&#123;</span>        <span class="token property">display</span><span class="token punctuation">:</span>flex<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token selector">main</span><span class="token punctuation">&#123;</span>        <span class="token property">flex-grow</span> <span class="token punctuation">:</span> 1<span class="token punctuation">;</span>        <span class="token property">order</span> <span class="token punctuation">:</span> 1<span class="token punctuation">;</span>        <span class="token property">background</span> <span class="token punctuation">:</span> lightblue<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token selector">aside</span><span class="token punctuation">&#123;</span>        <span class="token property">width</span> <span class="token punctuation">:</span> 180px<span class="token punctuation">;</span>        <span class="token property">background</span> <span class="token punctuation">:</span> lightgreen<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token selector">footer</span><span class="token punctuation">&#123;</span>        <span class="token property">text-align</span> <span class="token punctuation">:</span> center<span class="token punctuation">;</span>        <span class="token property">background</span> <span class="token punctuation">:</span> lightgray<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Grid布局"><a href="#Grid布局" class="headerlink" title="Grid布局"></a>Grid布局</h3><p>flex是单向的摆放， Grid是二维的布局； 用display : grid 使元素生成一个块级的grid容器，使用grid-template相关属性将容器划分为网络， 设置每一个子项占哪些行、列</p><p>划分网格</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token property">grid-template-columns</span><span class="token punctuation">:</span> 100px 100px 200px<span class="token punctuation">;</span><span class="token property">grid-template-rows</span><span class="token punctuation">:</span> 100px 100px<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>没有指定元素占几格，默认一个元素 占一格</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token property">grid-template-columns</span><span class="token punctuation">:</span> 30% 30% auto<span class="token punctuation">;</span><span class="token property">grid-template-rows</span><span class="token punctuation">:</span> 100px auto<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>grid有个特殊的单位 是fr，fr表示fraction </p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token property">grid-template-columns</span><span class="token punctuation">:</span> 100px 1fr 1fr<span class="token punctuation">;</span><span class="token property">grid-template-rows</span><span class="token punctuation">:</span> 100px 1fr<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>宽度除了100px 后面剩余部分 1fr 占50%</p><p>网格区域是由线来定义的，比如 1 1 3 3  行开始的线 列开始的线 行结束的线 列结束的线</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.preview</span><span class="token punctuation">&#123;</span>    <span class="token property">display</span> <span class="token punctuation">:</span> grid<span class="token punctuation">;</span>    <span class="token property">grid-template-rows</span><span class="token punctuation">:</span> 1fr 1fr 1fr<span class="token punctuation">;</span>    <span class="token property">grid-template-columns</span><span class="token punctuation">:</span>1fr 1fr 1fr<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token selector">.a</span><span class="token punctuation">&#123;</span>    <span class="token property">grid-row-start</span> <span class="token punctuation">:</span> 1<span class="token punctuation">;</span>    <span class="token property">grid-column-start</span> <span class="token punctuation">:</span> 1<span class="token punctuation">;</span>    <span class="token property">grid-row-end</span> <span class="token punctuation">:</span> 3<span class="token punctuation">;</span>    <span class="token property">grid-column-end</span> <span class="token punctuation">:</span> 3<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>class a 从左上角开始占4格</p><p><strong>网格线可以被命名</strong> 命名的方式是用中括号括起来</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.preview</span><span class="token punctuation">&#123;</span>    <span class="token property">grid-template-columns</span><span class="token punctuation">:</span>        [left] 100px [center] 1fr [right]<span class="token punctuation">;</span>    <span class="token property">grid-template-rows</span><span class="token punctuation">:</span>        [top]        1fr        [middle]        1fr        [bottom]<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token selector">.a</span><span class="token punctuation">&#123;</span>    <span class="token property">grid-area</span> <span class="token punctuation">:</span> top/left/bottom/center<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>命名网格区域    666</strong></p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.preview</span><span class="token punctuation">&#123;</span>    <span class="token property">display</span> <span class="token punctuation">:</span> grid<span class="token punctuation">;</span>    <span class="token property">grid-template-columns</span> <span class="token punctuation">:</span> 200px 1fr<span class="token punctuation">;</span>    <span class="token property">grid-template-rows</span><span class="token punctuation">:</span> 50px                        1fr                        50px<span class="token punctuation">;</span>    <span class="token property">grid-template-areas</span><span class="token punctuation">:</span> <span class="token string">"header header"</span>         <span class="token string">"aside  main"</span>                         <span class="token string">"footer footer"</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token selector">.a</span><span class="token punctuation">&#123;</span>    <span class="token property">grid-area</span><span class="token punctuation">:</span> header<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token selector">.d</span><span class="token punctuation">&#123;</span>    <span class="token property">grid-area</span>  <span class="token punctuation">:</span> footer<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>grid-gap属性  可以设置 网格之间的间距 默认值是0</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token property">grid-row-gap</span><span class="token punctuation">:</span> 10px<span class="token punctuation">;</span><span class="token property">grid-column-gap</span><span class="token punctuation">:</span> 20px<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>行方向上的对齐 是用justify-items 默认值是stretch 还 可以设置为start end center</p><p>列方向上的对齐 是用align-items 默认值是stretch 还 可以设置为start end center</p><p>也 可以设置单独容器的对其方式 用justify-self  align-self</p><p><strong>有时候设置的网格不会占满整个容器的</strong></p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.preview</span><span class="token punctuation">&#123;</span>    <span class="token property">grid-template-rows</span><span class="token punctuation">:</span> 100px 100px<span class="token punctuation">;</span>    <span class="token property">grid-template-columns</span><span class="token punctuation">:</span> 100px 100px 100px<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>通过 align-content 和 justify-content来设置区域在容器内的对齐方式 </p><h3 id="表格样式"><a href="#表格样式" class="headerlink" title="表格样式"></a>表格样式</h3><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">table th</span><span class="token punctuation">&#123;</span>    <span class="token property">width</span> <span class="token punctuation">:</span> 100px<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>设置表头的宽度为100px 实际上不一定为100px 因为这个会受每一列的内容影响</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">table th, table td</span><span class="token punctuation">&#123;</span>    <span class="token property">width</span><span class="token punctuation">:</span> 100px<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>此时列与列 宽度相同</p><p>table-layout : fixed 表格的宽度计算就不会根据里面的内容做自动调整</p><p>边框设置  用border属性， border-collapse 来设置相邻的边框是不是合并</p><p>table的 排版方式也 可以用在其它容器上 加上display: table 就OK了</p><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>nav</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>#<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Home<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>#<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Blog<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>#<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Links<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>#<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>About<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>nav</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span><span class="token punctuation">></span></span><span class="token style"><span class="token language-css">    <span class="token selector">nav</span><span class="token punctuation">&#123;</span>        <span class="token property">display</span> <span class="token punctuation">:</span> table<span class="token punctuation">;</span>        <span class="token property">width</span> <span class="token punctuation">:</span> 100%<span class="token punctuation">;</span>        <span class="token property">background</span> <span class="token punctuation">:</span> lightblue<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>        <span class="token selector">nav a</span><span class="token punctuation">&#123;</span>        <span class="token property">display</span> <span class="token punctuation">:</span> table-cell<span class="token punctuation">;</span>        <span class="token property">text-align</span><span class="token punctuation">:</span> center<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="table-container"><table><thead><tr><th>display属性值</th><th>对应的HTML标签</th></tr></thead><tbody><tr><td>table</td><td>table</td></tr><tr><td>table-row</td><td>tr</td></tr><tr><td>table-row-group</td><td>tbody</td></tr><tr><td>table-header-group</td><td>thead</td></tr><tr><td>table-footer-group</td><td>tfoot</td></tr><tr><td>table-cell</td><td>td/th</td></tr><tr><td>table-caption</td><td>caption</td></tr></tbody></table></div><h3 id="浮动Float"><a href="#浮动Float" class="headerlink" title="浮动Float"></a>浮动Float</h3><p>浮动的概念来源于传统的印刷排版中的文字环绕图片这种效果，左浮动就是把图片放在容器的左边 文字绕开图片进行展示 如下图</p><p><img src="img\img1.png" alt=""></p><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>section</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span>  <span class="token attr-name">src</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>/m.jpg<span class="token punctuation">"</span></span> <span class="token attr-name">width</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>300<span class="token punctuation">"</span></span> <span class="token attr-name">alt</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>mojave<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>        text ...    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>section</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span><span class="token punctuation">></span></span><span class="token style"><span class="token language-css">    <span class="token selector">img</span><span class="token punctuation">&#123;</span>        <span class="token property">float</span> <span class="token punctuation">:</span> left<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>浮动对布局的影响</p><ul><li>浮动元素脱离常规流，漂浮在容器左边或者右边</li><li>浮动元素贴着容器边缘或另外的浮动元素</li><li>浮动元素不会影响常规流里面的块级盒子</li><li>浮动元素后面的行盒会变短以避开浮动元素</li></ul><p>clear属性设置 一个 元素是否能和浮动元素重叠 clear : left 表示不能和左浮动重叠</p><p>下面的不是很懂</p><p>将浮动的影响控制在容器内</p><ul><li>Block Formatting Context<ul><li>BFC的高度包含浮动元素</li><li>BFC不会和浮动元素上下重叠</li></ul></li><li>创建BFC 意思是加了下面的内容就会使非BFC的 创建BFC<ul><li>overflow 非visible</li><li>float、inline-block、绝对定位</li></ul></li></ul><p>[08:01] 举例了应用</p><h3 id="定位"><a href="#定位" class="headerlink" title="定位"></a>定位</h3><p>position 属性： static  默认值， 非定位元素</p><p>relative <strong>相对自身原本位置偏移</strong>， 不脱离文档流</p><p>absolute 绝对定位，相对非static祖先元素定位</p><p>fixed        相对于浏览器窗口绝对定位</p><p>position : relative</p><ul><li>在常规流里面布局</li><li>相对于自己本应该在的位置进行偏移</li><li>使用top 、left 、 bottom 、 right 设置偏移长度</li><li>流内其它元素当它没有偏移一样布局</li></ul><p>666 我终于懂了~~</p><p>position : absolute</p><ul><li>脱离常规流</li><li>相对于最近的非static祖先定位 找到祖先position是absolute 或者使relative</li><li>不会对流内元素布局造成影响</li></ul><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h1</span><span class="token punctuation">></span></span>    页面标题<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h1</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>container<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>box<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>段落内容堕落内容 1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>段落内容堕落内容 2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>段落内容堕落内容 3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>段落内容堕落内容 4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span><span class="token punctuation">></span></span><span class="token style"><span class="token language-css">    <span class="token selector">.container</span><span class="token punctuation">&#123;</span>        <span class="token property">background</span> <span class="token punctuation">:</span> lightblue<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token selector">.box</span><span class="token punctuation">&#123;</span>        <span class="token property">position</span><span class="token punctuation">:</span> absolute<span class="token punctuation">;</span>        <span class="token property">top</span><span class="token punctuation">:</span> 0<span class="token punctuation">;</span>        <span class="token property">left</span><span class="token punctuation">:</span> 0<span class="token punctuation">;</span>        <span class="token property">width</span><span class="token punctuation">:</span> 100px<span class="token punctuation">;</span>        <span class="token property">height</span><span class="token punctuation">:</span> 100px<span class="token punctuation">;</span>        <span class="token property">background</span><span class="token punctuation">:</span> red<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>box 会找到根元素，会根据根元素进行定位</p><p>如果想要box 根据 container 进行定位， 直接给container 加上position : relative 就可以了</p><p>下面是绝对定位使用很常见的场景 用它来实现居中</p><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h1</span><span class="token punctuation">></span></span>    页面标题<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h1</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>container<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>box<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>段落内容堕落内容 1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>段落内容堕落内容 2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>段落内容堕落内容 3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>段落内容堕落内容 4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span><span class="token punctuation">></span></span><span class="token style"><span class="token language-css">    <span class="token selector">.container</span><span class="token punctuation">&#123;</span>        <span class="token property">background</span> <span class="token punctuation">:</span> lightblue<span class="token punctuation">;</span>        <span class="token property">position</span><span class="token punctuation">:</span> relative<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token selector">.box</span><span class="token punctuation">&#123;</span>        <span class="token property">position</span><span class="token punctuation">:</span> absolute<span class="token punctuation">;</span>        <span class="token property">top</span><span class="token punctuation">:</span> 50%<span class="token punctuation">;</span>        <span class="token property">left</span><span class="token punctuation">:</span> 50%<span class="token punctuation">;</span>        <span class="token property">width</span><span class="token punctuation">:</span> 100px<span class="token punctuation">;</span>        <span class="token property">height</span><span class="token punctuation">:</span> 100px<span class="token punctuation">;</span>        <span class="token property">background</span><span class="token punctuation">:</span> red<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>此时box的左上角在container的正中心的位置 如果要实现元素居中</p><p>加上margin-top : -50px    margin-left : -50px  即自身宽度和高度的一半</p><p><strong>如果我们设置了left和right 两个值之后</strong> 宽度就可以计算出来了， 如果宽度 也设置了， 那么right就是根据left和宽度做变化，如果不设置top left right bottom 那么这些值就是auto</p><p>他就会在他原本应该在的位置， 当元素还在流内时的位置</p><p>position : fixed  脱离了常规流 是相对于浏览器窗口的位置，不会随页面滚动发生位置变化</p><p>[09:04] 举了一个例子</p><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>nav</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>#<span class="token punctuation">"</span></span><span class="token punctuation">></span></span> 首页 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>#<span class="token punctuation">"</span></span><span class="token punctuation">></span></span> 导航1 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>#<span class="token punctuation">"</span></span><span class="token punctuation">></span></span> 导航2 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>nav</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>main</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>section</span><span class="token punctuation">></span></span> 1 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>section</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>section</span><span class="token punctuation">></span></span> 2 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>section</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>section</span><span class="token punctuation">></span></span> 3 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>section</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>section</span><span class="token punctuation">></span></span> 4 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>section</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>section</span><span class="token punctuation">></span></span> 5 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>section</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>main</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>#<span class="token punctuation">"</span></span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>go-top<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>返回顶部<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span><span class="token punctuation">></span></span><span class="token style"><span class="token language-css">    <span class="token selector">nav</span><span class="token punctuation">&#123;</span>        <span class="token property">postion</span> <span class="token punctuation">:</span> fixed<span class="token punctuation">;</span>        <span class="token property">line-height</span> <span class="token punctuation">:</span> 3<span class="token punctuation">;</span>        <span class="token property">background</span> <span class="token punctuation">:</span> <span class="token function">rgba</span><span class="token punctuation">(</span>0<span class="token punctuation">,</span> 0<span class="token punctuation">,</span> 0<span class="token punctuation">,</span> 0.3<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token property">width</span> <span class="token punctuation">:</span> 100%<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token selector">nav a</span><span class="token punctuation">&#123;</span>        <span class="token property">padding</span> <span class="token punctuation">:</span> 0 1em<span class="token punctuation">;</span>        <span class="token property">color</span> <span class="token punctuation">:</span> <span class="token function">rgba</span><span class="token punctuation">(</span>255<span class="token punctuation">,</span> 255<span class="token punctuation">,</span> 255<span class="token punctuation">,</span> 0<span class="token punctuation">,</span>7<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token selector">.go-top</span><span class="token punctuation">&#123;</span>        <span class="token property">position</span><span class="token punctuation">:</span> fixed<span class="token punctuation">;</span>        <span class="token property">right</span><span class="token punctuation">:</span> 1em<span class="token punctuation">;</span>        <span class="token property">bottom</span><span class="token punctuation">:</span> 1em<span class="token punctuation">;</span>        <span class="token property">color</span> <span class="token punctuation">:</span> #fff<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>无论怎么滚动 nav 和 返回顶部都在浏览器固定的位置</p><h3 id="堆叠层级"><a href="#堆叠层级" class="headerlink" title="堆叠层级"></a>堆叠层级</h3><p><strong>z-index</strong></p><ul><li>为定位元素指定其在z轴的上下层级</li><li>用一个整数表示，数值越大，越靠近用户</li><li>初始值为auto， 可以为负数、0、正数</li></ul><p><strong>堆叠上下文的创建</strong></p><ul><li>Root元素</li><li>z-index值不为auto的relative / absolute</li><li>position 是 fixed的元素</li><li>设置了某些属性的元素<ul><li>opacity 为 1</li><li>transform</li><li>animation</li></ul></li></ul><p>[05: 33] 举了一个例子</p><p><strong>绘制顺序</strong></p><p>在每一个堆叠上下文中，从下到上：</p><ul><li>形成该上下文的元素的border 和 background</li><li>z-index 为负值的子堆叠上下文</li><li>常规流内的块级元素</li><li>浮动元素</li><li>常规流内行级元素</li><li>z-index 为 0的子元素或子堆叠上下文</li><li>z-index 为正数的子堆叠上下文</li></ul>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CSS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ApproxEstimation Error</title>
      <link href="2021/05/09/cs229%209/"/>
      <url>2021/05/09/cs229%209/</url>
      
        <content type="html"><![CDATA[<h2 id="Lecture-9-ApproxEstimation-Error"><a href="#Lecture-9-ApproxEstimation-Error" class="headerlink" title="Lecture 9 ApproxEstimation Error"></a>Lecture 9 ApproxEstimation Error</h2><p><a href="https://www.bilibili.com/video/BV1JE411w7Ub?p=12">视频链接</a></p><p>这节课大部分内容是基于两个假设</p><ul><li>there exists a data distribution D from which x，y pairs are sampled; training set and test set come from the same distribution</li><li><p>all the samples are sampled independently</p><p>[5:28]的图 m个训练样本$x^{(1)}, y^{(1)}, \cdots, x^{(m)}, y^{(m)}$都是随机变量，经过Learning Algorithm 这个Deterministic Function 得到了$\hat{h}$或者$\hat{\theta}$，这个也是random variable</p></li></ul><p>Distribution of $\theta$ 我们称之为Sampling Distribution 存在$\theta^<em>$ or $h^</em>$ 我们称之为“True” parameter，我们希望这个parameter 是learning algorithm的输出，然而我们永远不会知道$\theta^*$是什么</p><p>注意$\theta^<em>$ 和$h^</em>$ 不是随机的， 意味着没有与之相关的概率分布，只是一个我们不知道的常数</p><h3 id="bias-和-variance的概念"><a href="#bias-和-variance的概念" class="headerlink" title="bias 和 variance的概念"></a>bias 和 variance的概念</h3><p>[13: 55] 左上角是high bias low variance， 右上角是high bias high variance</p><p>左下角是low bias low variance， 右下角是low bias high variance</p><p>bias is basically  checking whether the sampling distribution kind of centered around the true parameter.</p><p><strong>variance is  measuring basically how dispersed the sampling distribution is</strong></p><p>偏差和方差基本上是采样分布的first and second moments of your sampling distribution</p><p>如果收集无数个samples 那么其variance将变成0</p><p>如果当$m \to \infty$时 $\hat{\theta} \to \theta^*$  我们称这样的算法时consistent</p><p>high bias algorithm means no matter how much data or evidence you provided, it kind of always keep away from $\theta^*$ </p><p>high variance algorithm can easily get swayed by noise in the data.</p><p>bias 和 variance 是相互独立的</p><p>fighting variance的方法</p><ul><li>more data</li><li>regularization</li></ul><h3 id="hypothesis的分析"><a href="#hypothesis的分析" class="headerlink" title="hypothesis的分析"></a>hypothesis的分析</h3><p>在the space of hypothesis中，</p><p>假设存在一个最好的hypothesis g，即take this hypothesis and take the expected value of the loss with respect to the data generating distribution across an infinite amount of data. you kind of have the lowest error with this. [26: 00]的图</p><p>$g$ - best possible hypothesis ;  $h^*$ best in class $\mathcal{H}$ ; $\hat{h}$ learnt from finite data</p><p>$\epsilon(h)$: Risk / Generalization Error $E_{(x, y) \sim D}[1\{h(x) \ne y\}]$</p><p>$\hat{\epsilon}(h)$: Empirical Risk $= \frac{1}{m} \sum_{i = 1}^m 1\{ h(x^{(i)} \ne y^{(i)}\}$ 相当于有限版的$\epsilon(h)$</p><p>$\epsilon(g)$: Bayes Error / Irreducible Error   $\epsilon(h^*) - \epsilon(g) $ 是 Approximation Error</p><p>$\epsilon(\hat{h}) - \epsilon(h^*)$ 是 Estimation Error</p><p>容易看出 $\epsilon(\hat{h}) $ 是 estimation error， approximation error， Irreducible error的和</p><p>第一种error 是由于limited data造成的， 第二种error 是由模型选择造成的， 第三种error是不可避免的 其中第一种error可以表示为Estimation Error + Estimation Variance</p><p>我们经常提到的bias 和 variance 是</p><p>Bias 为 Estimation Error + approximation error</p><p>Variance 为 Estimation Variance </p><p>Bias is basically trying to capture why is $\hat{h}$ far from a $g$</p><p>根据[38:40]的图，如果$\mathcal{H}$减小 那么圈子会缩小，variance会下降，但是有可能偏离g 即bias上升</p><p>正则化就是会使$\mathcal{H}$ 减小，bias可能增大，不一定</p><p>Fight high bias</p><ul><li>make $\mathcal{H}$ bigger</li></ul><h3 id="Empirical-risk-minimization-ERM"><a href="#Empirical-risk-minimization-ERM" class="headerlink" title="Empirical risk minimization ERM"></a>Empirical risk minimization ERM</h3><p>empirical risk minimizer是一个a very specific type of learning algorithms</p><script type="math/tex; mode=display">\hat{h}_{ERM} = argmin_{h \in \mathcal{H}} \frac{1}{m}\sum_{i = 1}^m 1\{h(x^{(i)}) \ne y^{(i)} \}</script><p>Uniform Convergence</p><p>有两个核心问题：</p><p>if we do empirical risk minimization what about the generalization of an effect ?</p><p>第一个问题 $\hat{\epsilon}(h)$ versus $\epsilon(h)$   第二个问题 $\hat{\epsilon}(h)$ versus $\epsilon(h^*)$   </p><p>Tools: 1 Union Bound</p><p>如果我们有k个事件$A_1$, $A_2$, $\cdots$, $A_k$ 不需要相互独立，则</p><script type="math/tex; mode=display">P(A_1 \cup A_2 \cup \cdots \cup A_k) \le P(A_1) + P(A_2) + \cdots+ P(A_k)</script><p>2 Hoeffding’s Inequality</p><p>Let $Z_1$, $Z_2$, $\cdots$,$Z_m \sim Bernoulli(\phi)$  $\hat{\phi} = \frac{1}{m}\sum_{i = 1}^mZ_i$ Let $\gamma &gt; 0$ [margin]</p><script type="math/tex; mode=display">Pr(|\hat{\phi} - \phi)| > \gamma) \le 2 exp(-2\gamma^2 m)</script><p>[62:00] $\epsilon(h)$ 和 $\hat{\epsilon}_S(h)$的图  $E[\hat{\epsilon}_S(h_i)] = \epsilon(h_i)$</p><script type="math/tex; mode=display">Pr(|\hat{\epsilon}(h_i) - \epsilon(h_i)| > \gamma) \le2exp(-2\gamma^2m) \tag{1}</script><p>对于$\hat{\epsilon}_S(h_i)$ 的图像是针对一个特定的size，当size变化了，$\hat{\epsilon}_S(h_i)$就会不同</p><p>我们对式子$(1)$扩展到所有的h，就是固定size 求关于h的期望 这个称为uniform convergence</p><p>我们试图查看经验风险曲线 converges uniformly to the 泛化风险曲线</p><p>[71:11]开始 证明了 当hypothesis class $\mathcal{H}$ 是有限的情况，思路是对所有k个假设使用union bound</p><p>感觉这部分有点硬核，建议对着讲义看</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cs229 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Data Splits, Models &amp; Cross-Validation</title>
      <link href="2021/05/09/cs229%208/"/>
      <url>2021/05/09/cs229%208/</url>
      
        <content type="html"><![CDATA[<h2 id="Lecture-8-Data-Splits-Models-amp-Cross-Validation"><a href="#Lecture-8-Data-Splits-Models-amp-Cross-Validation" class="headerlink" title="Lecture 8 Data Splits, Models &amp; Cross-Validation"></a>Lecture 8 Data Splits, Models &amp; Cross-Validation</h2><p><a href="https://www.bilibili.com/video/BV1JE411w7Ub?p=11">课程视频链接</a></p><p><a href="http://cs229.stanford.edu/notes2020fall/notes2020fall/cs229-notes5.pdf">课程讲义链接</a></p><p><a href="http://cs229.stanford.edu/notes2020fall/notes2020fall/addendum_bias_variance.pdf">课程讲义链接2</a></p><p>听第七课的时候官网上的讲师还是Andrew Ng， 今天上官网的时候 发现讲师变成Moses Charikar</p><h3 id="Bias-and-Variance"><a href="#Bias-and-Variance" class="headerlink" title="Bias and Variance"></a>Bias and Variance</h3><p><strong>easy to learn but hard to master</strong></p><p>[06:26]画了三张图，左边是underfit the data，high bias；右边是overfit the data， high variance</p><p>bias在机器学习中的定义是 this learning algorithm had very strong preconceptions that the data could be fit by linear functions and this bias turns out not to be true.</p><p>Regularization 用来减少overfitting的情况</p><script type="math/tex; mode=display">min_\theta \frac{1}{2}\sum_{i = 1}^m ||y^{(i)} - \theta^Tx^{(i)}||^2 + \frac{\lambda}{2}||\theta||^2</script><p>其中$\frac{\lambda}{2}||\theta||^2$是正则项</p><p>对于SVM，通过核函数可以映射到无限维，为啥SVM没有明显的过拟合呢，老师说理由比较复杂，简单来说就是目标函数$||\omega||^2$有着和正则化相似的效果 </p><p>至于使用$\frac{\lambda}{2}||\theta||^2$ 而非 $\sum_j \lambda_j\theta_j$ 是因为会使训练的参数变得很多</p><p>PS： 对于不同的features 每个features的范围会不同，我们需要把features normalization到同一个范围下 比如$[0, 1]$ 这个范围 通过$(x - min) / (max - min)$</p><h3 id="Train-Dev-Test-sets"><a href="#Train-Dev-Test-sets" class="headerlink" title="Train/Dev/Test sets"></a>Train/Dev/Test sets</h3><p>对于10000个训练数据，我们要进行超参数的选择的话</p><p>$S_{train}, S_{dev}, S_{test}$ 其中dev 表示development，train each model（option for degree of polynomial 或者不同的正则系数等等) on $S_{train}$，get some hypothesis $h$ and measure erroe on $S_{dev}$ and pick model with lowest error on $S_{dev}$ </p><p>传统的划分方法是60% train, 20% dev, 20% test, 对于数据集很大的情况 这个比例会变化，可能是90% train， 5% dev，5% test</p><p>对于少量的训练数据，比如100个训练数据，用K-fold  k为10是typical choice</p><p>假如对于k为5的情况，就是把100个数据集分为五个不同的子集，接着要做的是</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">For i &#x3D; 1, ... ,kTrain parameters on k - 1 pieces;Test on remaining one piece;Average k on test errorsOptional: Refit model on 100% of data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果对于更小的数据集 比如m = 20</p><p>Leave-one-out 即设K = m 缺点是计算量很大 老师用这个方法 只在m小于等于100的情况下</p><p>老师推荐了 mlyearning.org这个网站 这里有进一步讨论 如果训练集和测试集是不同的分布</p><h3 id="Feature-Selection"><a href="#Feature-Selection" class="headerlink" title="Feature Selection"></a>Feature Selection</h3><p>a special case of model selection</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">start with F &#x3D; 空Repeat:1) Try to add each feature i to F, and see which single-feature addition most improves dev set performance2) Add that feature to F<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cs229 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Introduction to Neural Networks</title>
      <link href="2021/05/09/cs229%2011/"/>
      <url>2021/05/09/cs229%2011/</url>
      
        <content type="html"><![CDATA[<h2 id="Lecture-11-amp-12-Neural-Networks"><a href="#Lecture-11-amp-12-Neural-Networks" class="headerlink" title="Lecture 11&amp;12 Neural Networks"></a>Lecture 11&amp;12 Neural Networks</h2><p><a href="https://www.bilibili.com/video/BV1JE411w7Ub?p=14">视频链接</a></p><h3 id="将逻辑回归解释为一种特殊的神经网络"><a href="#将逻辑回归解释为一种特殊的神经网络" class="headerlink" title="将逻辑回归解释为一种特殊的神经网络"></a>将逻辑回归解释为一种特殊的神经网络</h3><p>视频前40分钟 是讲这个部分的</p><p><strong>将logistics regression作为神经网络的intuitive 我觉得挺好的</strong></p><p>目标1是对一张图来进行分类，判断是不是猫，假设图片是64*64大小 把图片展成向量 变成12288维向量，用logistics regression进行训练$\hat{y} = \sigma(\theta^Tx) = \sigma(wx + b)$</p><p>训练的步骤是:</p><ul><li>初始化w和b</li><li>找到w和b的最优值</li><li>用$\hat{y} = \sigma(wx + b)$来进行预测</li></ul><p>对于神经网络里面的神经元 我们定义是linear + activation</p><p>对于模型 我们的定义是 architecture + parameters</p><p>目标2 对于图片进行三分类</p><p>把一个神经元 扩展成3个神经元 分别计算$\hat{y_i} = a^{[1]}_i = \sigma(w_i^{[1]}x + b_i^{[1]}) \ \ i = 1,2,3$</p><p>上标1 代表layer 1，对于第一类的表示为$(1, 0, 0)$ 第二类的表示为$(0, 1, 0)$ 第三类的表示为$(0, 0, 1)$ </p><p>训练方法同上，三个神经元之间没有联系，可以独立的训练这三个神经元；这个模型robust</p><p>目标3 加上约束 图片上只有一个动物 softmax multi-class regression</p><p>对于softmax 其损失函数为cross-entropy loss $\mathcal{L} = -\sum_{k = 1}^3y_klog\hat{y_k}$</p><h3 id="Neural-Networks"><a href="#Neural-Networks" class="headerlink" title="Neural Networks"></a>Neural Networks</h3><p>这个部分对应视频的后40分钟</p><p>对于之前分辨一个图片是否是猫的图片 用了一个3 layers的网络</p><p>layer denotes neurons that are not connected to each other 一层神经元</p><p>在这个三层的网络单中[45:44]的图，第一层are going to understand the fundamental concepts of the image which is the edges. Then what’s gonna happen is that these neurons are going to communicate what they found on the image to the next layer’s neuron.</p><p><strong>end to end learning</strong>: we have an input, a ground truth and we don’t constrain the network in the middle i.e. we are just training based on the input and the output</p><p>视频中介绍的向量化的式子：</p><script type="math/tex; mode=display">Z^{[1]} = W^{[1]}X + b^{[1]}</script><p>m个训练数据 输入feature的维度是n 其中Z的shape是$(3, m)$ W的shape是$(n, m)$，b的维度是$(3, 1)$</p><h3 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h3><p>下面的公式 是根据一个三层全连接神经网络 其中第一层3个神经元 第二层2个神经元 最后一层1个神经元</p><p>用batch of examples，而非single example，原因是我们想要vectorization</p><script type="math/tex; mode=display">cost \ function: \mathcal{J}(\hat{y}, y) = \frac{1}{m}\sum_{i = 1}^m\mathcal{L}^{(i)}(\hat{y}, y) \\with: \ \mathcal{L}^{(i)} = -[y^{(i)}log\hat{y}^{(i)} + (1 - y^{(i)})log(1 - \hat{y}^{(i)}))] \\Update: \ \omega^{[l]} = \omega^{[l]} - \alpha\frac{\partial y}{\partial \omega^{[l]}}</script><p>反向来计算导数：</p><script type="math/tex; mode=display">\frac{\partial \mathcal{L}}{\partial \omega^{[3]}} = -[y^{(i)}\frac{\partial}{\partial\omega^{[3]}}(log\sigma(\omega^{[3]}a^{[2]} + b^{[3]})) + (1 - y^{(i)})\frac{\partial}{\partial\omega^{[3]}}(log(1 - \sigma(\omega^{[3]}a^{[2]} + b^{[3]})))] \\= -[y^{(i)}\frac{1}{a^{[3]}}a^{[3]}(1 - a^{[3]})(a^{[2]})^T +(1-y^{(i)})\frac{1}{1 - a^{[2]}}(-1)a^{[3]}(1 - a^{[3]})(a^{[2]})^T \\= -[y^{(i)}(1 - a^{[3]})(a^{[2]})^T - (1 - y^{(i)})a^{[3]}(a^{[2]})^T] \\= -[y^{(i)}(a^{[2]})^T - a^{[3]}(a^{[2]})^T] = -(y^{(i)} - a^{[3]})(a^{[2]})^T \\\therefore \frac{\partial \mathcal{J}}{\partial \omega^{[3]}} = -\frac{1}{m}\sum_{i = 1}^m(y^{(i)} - a^{[3]})(a^{[2]})^T</script><p>反向传播到$\omega^{[2]}$</p><script type="math/tex; mode=display">\frac{\partial \mathcal{L}}{\partial \omega^{[2]}} = \frac{\partial \mathcal{L}}{\partial a^{[3]}}\frac{\partial a^{[3]}}{\partial z^{[3]}}\frac{\partial z^{[3]}}{\partial a^{[2]}}\frac{\partial a^{[2]}}{\partial z^{[2]}}\frac{\partial z^{[2]}}{\partial \omega^{[2]}}</script><p>用之前算的结果来加速这个式子的算法</p><script type="math/tex; mode=display">\because \frac{\partial \mathcal{L}}{\partial \omega^{[1]}} = \frac{\partial \mathcal{L}}{\partial z^{[3]}}\frac{\partial z^{[3]}}{\partial \omega^{[3]}}=-(y^{(i)} - a^{[3]})(a^{[2]})^T \ \ \frac{\partial z^{[3]}}{\partial \omega^{[3]}} = (a^{[2]})^T\\ \therefore \frac{\partial \mathcal{L}}{\partial a^{[3]}}\frac{\partial a^{[3]}}{\partial z^{[3]}} = a^{[3]} - y^{(i)} \\\frac{\partial z^{[3]}}{\partial a^{[2]}} = (\omega^{[3]})^T \ \ \frac{\partial a^{[2]}}{\partial z^{[2]}} = a^{[2]}(1 - a^{[2]}) \ \ \frac{\partial z^{[2]}}{\partial \omega^{[2]}} = (a^{[1]})^T \\\therefore \frac{\partial \mathcal{L}}{\partial\omega^{[2]}} = (a^{[3]} - y^{(i)})(\omega^{[3]})^Ta^{[2]}(1 - a^{[2]})(a^{[1]})^T</script><p>注意 $\frac{\partial z^{[3]}}{\partial a^{[2]}}\frac{\partial a^{[2]}}{\partial z^{[2]}}$ 因为$a^{[2]}$和$z^{[2]}$两个都是$(2, 1)$向量  所以导数也是$(2, 1)$向量 它们之间的乘法应该是点乘</p><h3 id="Improving-NN"><a href="#Improving-NN" class="headerlink" title="Improving NN"></a>Improving NN</h3><ul><li><p>Activation function</p><p>sigmoid， ReLU， tanh</p><p>Q: Why we need activation function ?  A: to get nonlinearity</p></li><li><p>Initialization method 优势在于方便optimization</p><p>对于输入数据为$(x_1, x_2)^T$  令新的数据$x_i^{(i)} = x_i^{(i)} - \mu_i$ 其中$\mu = \frac{1}{m}\sum_{i = 1}^m x^{(i)}$</p><p>然后令$\sigma^2 = \frac{1}{m}\sum_{i = 1}^m(x^{(i)})^2$  取$\tilde{x_i} = \frac{x^{(i)}}{\sigma}$</p><p>注意$\mu$和$\sigma$是根据训练集里面计算的，对于测试集也用这两个参数</p></li><li><p>Vanishing， Exploding gradients</p><p>[55:00]举了一个例子，说明随着网络的层数增加，矩阵相乘的error也会增加，有可能gradients是一个超级大的值 或者是非常小的值 权值初始化在1左右是非常好的</p><p>一个神经元的输入为n， n越大$w_i$越小，$\frac{1}{n}$的初始化时非常好的，</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span class="token operator">*</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">/</span> n<span class="token punctuation">)</span> <span class="token comment">#对于sigmoid函数 这个初始化效果很好</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span class="token operator">*</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">/</span> n<span class="token punctuation">)</span> <span class="token comment">#对于ReLU函数 这个初始化效果很好</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>上面的n 时 $n^{[l - 1]}$</p></li><li><p>其它Initialization</p><p>Xavier Initialization $W^{[l]} \sim \sqrt{\frac{1}{n^{[l - 1]}}}$   for tanh     He Initialization $W^{[l]} \sim \sqrt{\frac{2}{n^{[l]} + n^{[l - 1]}}}$</p></li><li><p>Optimization</p><p>mini-batch algorithm</p></li><li><p>Momentum algorithm</p><p>Assume you have the loss that is very extended in one direction. [72:00]有示例</p><p>What momentum is going to say is look at the past updates that you did and try to consider these past updates in order to find the right way to go</p><script type="math/tex; mode=display">v = \beta v + (1 - \beta)\frac{\partial \mathcal{L}}{\partial \omega} \\\omega = \omega - \alpha v</script></li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cs229 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CSS基础</title>
      <link href="2021/05/09/css1/"/>
      <url>2021/05/09/css1/</url>
      
        <content type="html"><![CDATA[<p>这是学堂在线上面的前端课程<a href="https://www.xuetangx.com/search?query=%E5%89%8D%E7%AB%AF&amp;page=1">课程链接</a></p><h2 id="CSS基础"><a href="#CSS基础" class="headerlink" title="CSS基础"></a>CSS基础</h2><h3 id="CSS简介"><a href="#CSS简介" class="headerlink" title="CSS简介"></a>CSS简介</h3><p>css Cascading Style Sheets 可设置颜色大小，动画效果</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">h1</span><span class="token punctuation">&#123;</span>    <span class="token property">color</span><span class="token punctuation">:</span>white<span class="token punctuation">;</span>    <span class="token property">font-size</span><span class="token punctuation">:</span>14px<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>h1是selector选择器  color是属性， white是属性值</p><p>在页面中使用CSS</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">&lt;!-- 外链 -->&lt;link rel = "stylesheet" href=" ">&lt;!-- 嵌入 -->&lt;style>li</span> <span class="token punctuation">&#123;</span><span class="token property">margin</span><span class="token punctuation">:</span> 0<span class="token punctuation">;</span><span class="token property">list-style</span><span class="token punctuation">:</span> none<span class="token punctuation">;</span> <span class="token punctuation">&#125;</span><span class="token selector">p</span>  <span class="token punctuation">&#123;</span><span class="token property">margin</span><span class="token punctuation">:</span> lem 0<span class="token punctuation">;</span><span class="token punctuation">&#125;</span>&lt;/style>&lt;!-- 内联  不推荐使用-->&lt;p style=<span class="token string">"margin:lem 0"</span>>Example Content&lt;/p><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>css工作原理</p><p>加载HTML 之后会解析HTML 然后会创建DOM树， 解析HTML时也会加载CSS 解析CSS 然后会添加样式到DOM节点</p><h3 id="基础选择器"><a href="#基础选择器" class="headerlink" title="基础选择器"></a>基础选择器</h3><p>可使用多种方式选择元素 按照标签名，类名或id； 按照属性； 按照DOM树中的位置</p><p>通配选择器*， 标签选择器</p><p>id选择器 #logo 表示id为logo的标签 一般只有一个； 类选择器 .done class为done的所有标签 可多个</p><p>属性选择器 input[type=”password”]； a[href^=”#”] 表示href的值以#开头， a[href$=”.jpg”] 表示href的值以.jpg结尾</p><p><strong>伪类 666</strong></p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">&lt;!-- 动态伪类 根据元素所处的状态来选择-->a : link</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span> <span class="token selector">选中一个正常连接a : visited</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span> <span class="token selector">访问过的链接a : hover</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span> <span class="token selector">鼠标放在链接上a : active</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span> <span class="token property">链接被鼠标按下去了</span><span class="token punctuation">:</span>focus  对于输入框 点下去后 &lt;!-- 结构性伪类 --><span class="token property">li</span><span class="token punctuation">:</span>first-child 表示li标签的第一个孩子<span class="token property">li</span><span class="token punctuation">:</span>last-child 表示li标签的最后一个孩子<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>组合器</strong></p><p>直接组合 AB 满足A同时满足B input:focus</p><p>后代组合 A B 选中B 如果它时A的子孙  nav a</p><p>亲子组合 A &gt; B 选中B， 如果它时A的子元素   section &gt; p</p><p>选择器组，多个选择器放一起， 用逗号隔开</p><h3 id="设置字体"><a href="#设置字体" class="headerlink" title="设置字体"></a>设置字体</h3><p>font-family 设置字体 </p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">h1</span><span class="token punctuation">&#123;</span>    <span class="token property">font-family</span><span class="token punctuation">:</span> Optima<span class="token punctuation">,</span> Georgia<span class="token punctuation">,</span> serif<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>设置多个字体就是为了防止浏览器有些字体没有</p><p>通用字体族 Serif 衬线体 Sans-Serif 无衬线体 Cursive 手写体 Monospace 等宽字体</p><p>使用font-family的建议 字体列表最后写上通用字体簇 英文字体放在中文字体前面</p><p>使用web fonts @font-face</p><p><strong>font-size 关键字</strong>， 长度， 百分数， 百分数时相对于父元素字体大小来的</p><p>长度px 像素， 2em 表示是父元素字体长度的两倍</p><p><strong>font-weight 设置粗细</strong></p><p><strong>font:</strong> style weight size/height family</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">h1</span><span class="token punctuation">&#123;</span>    <span class="token property">font</span><span class="token punctuation">:</span> bold 14px/1.7 Helvetica<span class="token punctuation">,</span> sans-serif<span class="token punctuation">;</span><span class="token punctuation">&#125;</span>行高是14px * 1.7<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="设置文字样式"><a href="#设置文字样式" class="headerlink" title="设置文字样式"></a>设置文字样式</h3><p>text-align 设置对齐模式， justify 是左右两边对齐</p><p>letter-spacing 是字母与字母之间的距离， word-spacing 是词与词之间的距离</p><p>text-shadow 设置文字阴影</p><h3 id="盒模型"><a href="#盒模型" class="headerlink" title="盒模型"></a>盒模型</h3><p>在浏览器进行渲染的时候 它会把页面中的元素格式化成一个一个盒子，每一个盒子都有padding, border, margin, content； content表示盒子里面内容的大小，padding是内容和边框的内边距，border是边宽，<strong>margin是盒子和其它盒子之间的距离</strong></p><ul><li><p>width 指定content box的宽度， 取值为长度，百分数-相对于容器的宽度来计算的，auto由浏览器根据其它属性确定，<strong>容器有指定高度时，百分数才生效</strong></p></li><li><p>padding-top, padding-left, padding-right, padding-bottom 默认值为0，百分数相对于容器宽度</p></li><li><p>border none表示没有边框，solid实线，dashed虚线，dotted 点状线； 指定容器边框样式、粗细和颜色</p><ul><li>border-width, border-style, border-style</li><li>或者 border: 1px solid #ccc</li><li>四个方向 border-top, border-right, border-bottom, border-left</li><li>border-left-width: 3px</li><li>可以利用border来模拟三角形</li></ul></li><li><p>margin</p><ul><li><p>使用margin: auto  水平居中</p></li><li><p>```css<br>div{</p><pre><code>width: 200px;height: 200px;backgroud: coral;margin-left: auto;margin-right: auto;</code></pre><p>}</p><pre class="line-numbers language-none"><code class="language-none">+ margin collapse  &#96;&#96;&#96;css  .a&#123;      background: lightblue;      height: 100px;      margin-bottom: 100px;  &#125;  .b&#123;      background: coral;      height: 100px;      margin-top: 100px;  &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">'</span>a<span class="token punctuation">'</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">'</span>b<span class="token punctuation">'</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>按照margin的定义两个div的垂直距离应该是200px，然而实际上是100px，因为在垂直方向上相邻的margin会被合并，取两者最大的值，这个现象只会在垂直方向上发生</p></li><li><p>margin可以为负值</p></li></ul></li><li><p>默认的height和width是关于content的，如果设置box-sizing为border-box 那么height和width就是关于content + border的</p></li><li><p>当容器的内容比较多的时候 就会溢出容器，称为overflow，overflow hidden表示超出的内容被隐藏，overflow scroll 表示内容超过的时候会有一个滚动条出现</p></li><li><p>当宽度是百分比或者auto的时候，其宽度我们并不能预先确定好，因为要根据浏览器宽度的大小和内容的多少，我们可以通过min-width和max-width 来限制实际的宽度</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">article</span><span class="token punctuation">&#123;</span>    <span class="token property">margin</span><span class="token punctuation">:</span> auto<span class="token punctuation">;</span>    <span class="token property">line-height</span><span class="token punctuation">:</span> 1.7<span class="token punctuation">;</span>    <span class="token property">max-width</span><span class="token punctuation">:</span> 20em<span class="token punctuation">;</span>    <span class="token property">min-width</span><span class="token punctuation">:</span> 10em<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面意味着一行最多20个字，最少10个字</p></li><li><p>min-height 和 max-height</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">article img</span><span class="token punctuation">&#123;</span>    <span class="token property">max-width</span> <span class="token punctuation">:</span> 100%<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ul><h3 id="CSS中的盒子"><a href="#CSS中的盒子" class="headerlink" title="CSS中的盒子"></a>CSS中的盒子</h3><p>DOM树与盒子</p><p>根据DOM树生成一系列的盒子，然后摆放盒子 称作Layout</p><p>摆放盒子</p><ul><li>盒子尺寸和类型</li><li>定位模式</li><li>节点但在DOM树中的位置</li><li>其它信息 窗口大小、图片大小等</li></ul><p>块级元素会生成块级的盒子，行级元素会生成行级元素，<strong>块级的不能和其它盒子并列摆放</strong></p><p>行级盒子可以和其它的行级盒子摆放在一行或拆开成多行，<strong>盒模型中width、height不适用</strong></p><p>行级盒子的宽度是由内容和容器来决定的</p><p>行级元素有span、em、strong、cite、code等</p><p>可以通过display属性来把任意标签设置成行级或者块级，display: block, display:inline, </p><p>display:inline-block 本身是行级，可以放在行盒中；可以设置宽高；作为一个整体不会被拆散成多行</p><p>display:none 会被忽略不会被展示出来</p><h3 id="盒子的效果"><a href="#盒子的效果" class="headerlink" title="盒子的效果"></a>盒子的效果</h3><p>圆角border-radius —- 让我想到了小米的logo 可以通过设置border-radius来设置完成</p><p>圆角可以设置成圆形，也可以设置成椭圆 20px / 50px； 也可以设置成百分比</p><p>10px 20px 30px 40px / 50px 60px 70px 80px 前面是水平方向上的，后面是垂直方向上的</p><p>background</p><ul><li>background-color 背景颜色</li><li>background-image 设置背景图片</li><li>background-repeat 背景图片是否重复</li><li>background-position 背景图片所在位置</li><li>background-size 背景图片的大小</li></ul><p>background position的一个常用的使用场景</p><p>CSS Sprites 为了让页面加载的更快，我们会把小的一些背景图合并到一张大图中，然后通过background position来使用每一张小的图片</p><p>background size默认是图片的大小</p><p>background-size: 100px auto， 宽度是100px， 高度是根据宽度来调整的</p><p>background-size: auto 100% , 高度是100%， 宽度按照比例缩放</p><p>background-size: contain 表示图片能够完全的展示出来</p><p>background-size: cover 表示图片能够完全把容器覆盖住 这个时候图片可能会被裁剪</p><p>background-clip border-box， padding-box， content-box</p><p><strong>box-shadow</strong> : 1px 1px 8px 0 gray 前面两个值 是水平和垂直方向上一个偏移量，第三个值表示阴影模糊的程度，第四个值表示阴影扩张的大小，最后是阴影的颜色， <strong>不占用空间</strong></p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token property">box-shadow</span><span class="token punctuation">:</span> 0 0 0 2px red<span class="token punctuation">,</span>0 0 0 4px orange<span class="token punctuation">,</span>0 0 0 6px yellow<span class="token punctuation">,</span>            0 0 0 8px green<span class="token punctuation">,</span>            0 0 0 10px blue<span class="token punctuation">,</span>            0 0 0 12px cyan<span class="token punctuation">,</span>            0 0 0 14px purple<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个会形成一个彩虹边框</p><h3 id="行高和垂直对齐"><a href="#行高和垂直对齐" class="headerlink" title="行高和垂直对齐"></a>行高和垂直对齐</h3><p>Font Metrics： baseline-最重要， meanline， mean line减去baseline 是x-height 是小写字母的高度，有些字母比如h 会上超过mean line 或者比如p向下超过descender line 上界时ascender line 下界是descender line，盒子的摆放需要依赖这几条线来定位，一个包含文字的行盒的高度，line-height，ascender line到顶部和descender line到底部的距离是一样的，行盒的对齐默认是根据baseline</p><p>视频[5:00] 有详细的关于垂直对齐的介绍</p><p>vertical-align: 0px  是基于baseline来对齐</p><h3 id="CSS继承"><a href="#CSS继承" class="headerlink" title="CSS继承"></a>CSS继承</h3><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>article</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h1</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>title<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        abc    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h1</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>article</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span><span class="token punctuation">></span></span><span class="token style"><span class="token language-css">    <span class="token selector">.title</span><span class="token punctuation">&#123;</span>        <span class="token property">color</span> <span class="token punctuation">:</span> blue<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token selector">article h1</span><span class="token punctuation">&#123;</span>        <span class="token property">color</span> <span class="token punctuation">:</span> red<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>哪条规则生效？ 涉及到选择器的优先级 是由特殊程度来决定的</p><h1 id="nav-list-li-a-link-id-：1-伪-类-2-伪-元素-2"><a href="#nav-list-li-a-link-id-：1-伪-类-2-伪-元素-2" class="headerlink" title="nav .list li a:link       id ：1  $($伪$)$类: 2   $($ 伪$)$ 元素 : 2"></a>nav .list li a:link       id ：1  $($伪$)$类: 2   $($ 伪$)$ 元素 : 2</h1><p>.hd ul.links a              id ：0  $($伪$)$类: 2   $($ 伪$)$ 元素 : 2   上面是122 下面是22 上面优先级高</p><p>对于前面那个例子 blue 是10  red 是 2  所以是blue</p><p>高优先级的选择器的属性会覆盖低优先级的选择器中相同的属性的值</p><p>应用， 写一个按钮的基础样式， 然后再写特有的，利用属性覆盖实现代码复用</p><pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>button</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>btn<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    普通按钮<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>button</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>button</span> <span class="token attr-name">class</span> <span class="token attr-value"><span class="token punctuation attr-equals">=</span> <span class="token punctuation">"</span>btn primary<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    主要按钮<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>button</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span><span class="token punctuation">></span></span><span class="token style"><span class="token language-css">    <span class="token selector">.btn</span><span class="token punctuation">&#123;</span>        一些基本属性    <span class="token punctuation">&#125;</span>    <span class="token selector">.btn.primary</span><span class="token punctuation">&#123;</span>        特有属性    <span class="token punctuation">&#125;</span></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>某些属性会自动继承其父元素的计算值，除非显示指定一个值</strong></p><p>有些属性是不能继承的 比如box-sizing，但是我们可以显示继承，比如使用*</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">*</span><span class="token punctuation">&#123;</span>    <span class="token property">box-sizing</span> <span class="token punctuation">:</span> inherit<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>可以使用initial 关键字显示重制为初始值</p><p>[8:45]的图介绍了 CSS求值的过程</p><h3 id="CSS中的值和单位"><a href="#CSS中的值和单位" class="headerlink" title="CSS中的值和单位"></a>CSS中的值和单位</h3><p>常见的CSS的值有9种</p><ul><li>关键字 比如 initial、inherit</li><li>字符串 “Microsoft Yahei”</li><li>URL </li><li>长度 100px、5em</li><li>百分数</li><li>整数 z-index : 5</li><li>浮点数 line-height : 1.8</li><li>颜色 #ff0000</li><li>时间 300ms</li></ul><p>长度单位</p><p>px  像素点 ； in 英寸 ； cm 厘米 ； mm 毫米； pt 1/72英寸 ; pc 1/6 英寸</p><p>em 元素字体大小 ; rem html字体大小；vh 1%窗口高 ; vw 1%窗口宽 ; vmax vw vh较大者</p><p>[6:26]介绍了 HSL的颜色表示方式</p>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CSS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Continuous-Time Fourier Transform</title>
      <link href="2021/03/29/signal%20and%20system%208/"/>
      <url>2021/03/29/signal%20and%20system%208/</url>
      
        <content type="html"><![CDATA[<h2 id="Continuous-Time-Fourier-Transform"><a href="#Continuous-Time-Fourier-Transform" class="headerlink" title="Continuous-Time Fourier Transform"></a>Continuous-Time Fourier Transform</h2><p><a href="https://www.bilibili.com/video/BV1xy4y167DD?p=8">视频地址</a></p><h3 id="用复指数信号的线性组合来表示非周期信号"><a href="#用复指数信号的线性组合来表示非周期信号" class="headerlink" title="用复指数信号的线性组合来表示非周期信号"></a>用复指数信号的线性组合来表示非周期信号</h3><p>对于一个非周期信号，基于这个信号来建立周期信号，就是把原来的信号重复一下，</p><p>形成周期为$T_0$的周期信号，图片参考视频[03:22]的图片</p><p>这个周期信号在一个周期内是和非周期信号是相同的，<strong>当周期$T_0$趋近于无穷时，周期信号变成了非周期信号</strong> </p><p><strong>核心思想</strong>：用傅里叶级数来表示这个周期信号，然后让周期趋近于无穷，得到的就是非周期信号的傅里叶变换</p><script type="math/tex; mode=display">\widetilde{x}(t) = x(t) \quad for \ |t| <\frac{T_0}{2} \\\widetilde{x}(t) = \sum_{k = -\infty}^{\infty}a_ke^{jk\omega_0t} \quad \quad \omega_0 = \frac{2\pi}{T_0} \\a_k = \frac{1}{T_0}\int_{-\frac{T_0}{2}}^{\frac{T_0}{2}}\widetilde{x}(t)e^{-jk\omega_0t}dt \\a_k = \frac{1}{T_0}\int_{-\infty}^{+\infty}x(t)e^{-jk\omega_0t}dt \\</script><p>Define: $X(\omega) \triangleq \int_{-\infty}^{+\infty}x(t)e^{-j\omega t}dt \tag{1}$       Then: $T_0a_k = X(\omega)\bigg|_{\omega = k\omega_0} \tag{*}$</p><p>$X(\omega)$ is the envelope$($ 包络函数 $)$ of $T_0a_k$ ； 这告诉了我们如何通过对包络函数的sample来建立周期信号的傅里叶级数系数</p><script type="math/tex; mode=display">\widetilde{x}(t) = \sum_{k = -\infty}^{+\infty}a_ke^{jk\omega_0t} = \sum_{k = -\infty}^{+\infty}\frac{1}{T_0}X(k\omega_0)e^{jk\omega_0t} \\\widetilde{x}(t) = \frac{1}{2\pi}\sum_{k = -\infty}^{+\infty}X(k\omega_0)e^{jk\omega_0t}\omega_0 \\As \ T_0 \rightarrow \infty, \\\omega_0 \rightarrow0,\widetilde{x}(t) \rightarrow x(t), \omega_0 \rightarrow d\omega, \Sigma \rightarrow \int \\</script><p>则得到 $x(t) = \frac{1}{2\pi}\int_{-\infty}^{+\infty}X(\omega)e^{j\omega t}d\omega \tag{2}$</p><p>方程$(1)$ 称为analysis equation   也成为傅里叶变换                       方程$(2)$称为synthesis equation</p><p>[11:00]开始的图示说明非常棒！！</p><p>$x(t)$和$X(\omega)$的关系是一一对应，即使$x(t)$是实函数，$X(\omega)$也是复函数</p><p>$X(\omega) = Re\{ X(\omega) \} + j Im \{  X(\omega) \} = |X(\omega)|e^{j\angle X(\omega)}$</p><h3 id="傅里叶变换的例子"><a href="#傅里叶变换的例子" class="headerlink" title="傅里叶变换的例子"></a>傅里叶变换的例子</h3><p>对于函数$x(t) = e^{-at}u(t)$ 其傅里叶变换是</p><p>$X(\omega) = \int_{-\infty}^{+\infty}x(t)e^{-j\omega t}dt = \int_{0}^{+\infty}e^{-at}e^{-j\omega t}dt = \int_{0}^{+\infty}e^{-t(a + j\omega)}dt = \frac{1}{a + j\omega}e^{-(a + j\omega)t}\bigg|^\infty_0$</p><p>当$a &gt; 0$ 积分求$t = +\infty$时 式子为0，当$t = 0$时 式子为$\frac{1}{a + j\omega}$   可得$e^{-at}u(t)$对应的傅里叶变换是$\frac{1}{a + j\omega}$</p><p>[18:30] 展示了 该函数与其傅里叶变换形成的函数的图像(有振幅的图，有幅度的图)</p><p>[21:30] 展示了该图像的波特图版本 振幅是$20log_{10}X(\omega)\triangleq decibels \ (dB)$ 横坐标是频率的对数，对于横坐标上面等距离移动，每次移动频率变为原来的10倍</p><p>由于横坐标是对数，所以对应的频率是大于0的频率，但是由于傅里叶变换出的函数的性质 我们可以推测出频率为负时的图像的样子</p><p><strong>Fourier Series coefficients equal $\frac{1}{T_0}$ times samples of Fourier transform of one period</strong></p><p>也就是说 对于之前求周期信号的傅里叶级数 我们可以考虑求一个周期的傅里叶变换[25:30]</p><p>可以可以！</p><h3 id="将傅里叶变换和傅里叶级数用一个通用框架来表示"><a href="#将傅里叶变换和傅里叶级数用一个通用框架来表示" class="headerlink" title="将傅里叶变换和傅里叶级数用一个通用框架来表示"></a>将傅里叶变换和傅里叶级数用一个通用框架来表示</h3><p>观察傅里叶级数和傅里叶变换的synthesis equation 我们可以发现</p><p>$\widetilde{x}(t)$的傅里叶级数是$a_k$  $\widetilde{x}(t)$的傅里叶变换是$\widetilde{X}(\omega)$ </p><p>则$\widetilde{X}(\omega) \triangleq \sum_{-\infty}^{\infty}2\pi a_k \delta(\omega - k\omega_0) \tag{3}$</p><script type="math/tex; mode=display">\widetilde{x}(t) = \frac{1}{2\pi}\int_{-\infty}^{+\infty}\widetilde{X}(\omega)e^{j\omega t}d\omega \\= \frac{1}{2\pi}\sum_{k = -\infty}^{+\infty}2\pi a_k \int_{-\infty}^{+\infty}\delta(\omega - k\omega_0)e^{-j\omega t}d\omega</script><h2 id="通用框架的例子"><a href="#通用框架的例子" class="headerlink" title="通用框架的例子"></a>通用框架的例子</h2><p>symmetric square wave     666哇</p><p>还讲了一个$x(t) = \delta(t)$的例子 $x(t)$的傅里叶变换是常数，</p><p>对于周期函数$\widetilde{x}(t) = \sum_{k = -\infty}^{+\infty}\delta(t - kT_0)$ 其对应的傅里叶变换$\widetilde{X}(\omega)$  这函数是怎么得到的 没有弄明白</p>]]></content>
      
      
      <categories>
          
          <category> 信号与系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信号与系统 </tag>
            
            <tag> 理论知识 </tag>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fourier Transform Properties</title>
      <link href="2021/03/29/signal%20and%20system%209/"/>
      <url>2021/03/29/signal%20and%20system%209/</url>
      
        <content type="html"><![CDATA[<h2 id="Fourier-Transform-Properties"><a href="#Fourier-Transform-Properties" class="headerlink" title="Fourier Transform Properties"></a>Fourier Transform Properties</h2><p><a href="https://www.bilibili.com/video/BV1xy4y167DD?p=9">视频链接</a></p><p><strong>Continuous —- Time Fourier Transform</strong></p><script type="math/tex; mode=display">x(t) = \frac{1}{2\pi}\int_{-\infty}^{+\infty}X(\omega)e^{j\omega t}d\omega \quad \quad  sysnthesis \\X(\omega) = \int_{-\infty}^{+\infty}x(t)e^{-j\omega t}dt \quad \quad analysis</script><h3 id="Symmetry"><a href="#Symmetry" class="headerlink" title="Symmetry"></a>Symmetry</h3><script type="math/tex; mode=display">x(t) \ real \ \ \Rightarrow \ X(-\omega) = X^*(\omega) \\ReX(\omega) = ReX(-\omega) \quad |X(\omega)| = |X(-\omega)| \quad</script><p>the real part is an even function of frequency, and the magnitude is an even function of frequency</p><script type="math/tex; mode=display">Im X(\omega) = -ImX(-\omega) \quad \angle X(\omega) = -\angle X(-\omega)</script><p>the imaginary part is an odd function of frequency, and the phase angle is an odd function of frequency</p><h3 id="Time-and-frequency-scaling"><a href="#Time-and-frequency-scaling" class="headerlink" title="Time and frequency scaling"></a>Time and frequency scaling</h3><script type="math/tex; mode=display">if \ x(t) \iff X(\omega) \quad then \quad x(at) \iff \frac{1}{|a|}X(\frac{\omega}{a})</script><p><strong>如果以两倍的速度播放磁带，意味着2倍线性压缩时间轴，然而实际发生的是频率变成2倍</strong></p><p>[09:07]实验展示非常好</p><h3 id="duality-relationship"><a href="#duality-relationship" class="headerlink" title="duality relationship"></a>duality relationship</h3><p>看最开始的synthesis equation 和 analysis equation</p><p>如果$X(\omega)$是时间信号$x(t)$的傅里叶变换，那么$x(t) = \frac{1}{2\pi}\int_{-\infty}^{\infty}X(\omega)e^{j\omega t} d\omega$  非常像傅里叶变换 变换的是$X(-\omega)$，再加上一个额外的因子$\frac{1}{2\pi}$  即我们可得对偶性</p><script type="math/tex; mode=display">x(t) \iff X(\omega) \quad \quad X(t) \iff 2\pi x(-\omega)</script><p><strong>这个性质非常重要！</strong> 对于离散傅里叶变换 这个性质是没有的 [15:00]显示了例子</p><h3 id="Parseval’s-relation"><a href="#Parseval’s-relation" class="headerlink" title="Parseval’s relation:"></a>Parseval’s relation:</h3><script type="math/tex; mode=display">\int_{-\infty}^{+\infty}|x(t)|^2dt = \frac{1}{2\pi}\int_{-\infty}^{+\infty}|X(\omega)|^2d\omega \\\frac{1}{T_0}\int_{T_0}|\widetilde{x}(t)|^2dt = \sum_{-\infty}^{+\infty}|a_k|^2</script><p>下面这个式子 是对于周期信号，由于周期信号的能量是无穷大，所以对于周期信号 只考虑一个周期的能力，$\widetilde{x}(t)$是一个周期的信号</p><h3 id="Time-shifting"><a href="#Time-shifting" class="headerlink" title="Time shifting:"></a>Time shifting:</h3><script type="math/tex; mode=display">x(t - t_0) \iff e^{-j\omega t_0}X(\omega)</script><p>右边的$e^{j\omega t_0}$的幅度为1，并且有一个与频率成线性关系的相位</p><p>即 a time shift corresponds to a linear change in phase and frequency</p><h3 id="Differentiation"><a href="#Differentiation" class="headerlink" title="Differentiation:"></a>Differentiation:</h3><script type="math/tex; mode=display">\frac{dx(t)}{dt} \iff j\omega X(\omega)</script><h3 id="Integration"><a href="#Integration" class="headerlink" title="Integration:"></a>Integration:</h3><script type="math/tex; mode=display">\int_{-\infty}^tx(\tau)d\tau \iff \frac{1}{j\omega}X(\omega) + \pi X(0)\delta(\omega)</script><p>因为对函数求导的时候会把常数项给消掉，所以在积分性质中 就尝试把常数项带回来 所以后面加上$\pi X(0)\delta(\omega)$</p><h3 id="Linearity"><a href="#Linearity" class="headerlink" title="Linearity:"></a>Linearity:</h3><script type="math/tex; mode=display">ax_1(t) + bx_2(t)  \iff aX_1(\omega) +bX_2(\omega)</script><p>老师说 这四个性质 for the most part, apply both to Fourier series and Fourier transforms, because what we’ve done is to incorporate the Fourier series within the framework of the Fourier transform.</p><h3 id="Two-addtional-major-properties-convolution-property-and-modulation-property"><a href="#Two-addtional-major-properties-convolution-property-and-modulation-property" class="headerlink" title="Two addtional major properties: convolution property and modulation property"></a>Two addtional major properties: convolution property and modulation property</h3><p><strong>the convolution property forms the mathematical and conceptual basis for the whole notion of filtering</strong></p><script type="math/tex; mode=display">h(t) * x(t) \iff H(\omega)X(\omega)</script><p>LTI中，对于输入信号是$\delta(t)$ 冲激响应是$h(t)$ 由于$\delta(t)$的傅里叶变换是常数1，所以输出信号的傅里叶变换是$H(\omega)$</p><p>对于卷积性质的更直观的解释是：（这个解释来源于冲激响应的傅里叶变换和频率响应之间的关系）</p><p>LTI中 如果输入信号是$e^{j\omega_0 t}$ 那么输出信号是$e^{j\omega_0 t}H(\omega_0)$ 这里的$H(\omega_0)$被称为频率响应 这个频率响应就是冲激响应的傅里叶变换</p><p>老师说 “the synthesis equation tells us how to decompose x of t as a linear combination of complex exponentials. What are the complex amplitudes of those complex exponentials? The complex amplitude of those complex exponentials is $X(\omega)$ [参考26:53的图] or proportional to x of omega $(2\pi X(\omega)d\omega)$,  as this signal goes through this linear time invariant system, what happens to each of those exponential is each one get multiplied by the frequency response at associated frequency. What comes out is the amplitude of the complex exponentials that are used to build the output</p><p>So in fact, the convolutional property simply is telling us that in terms of decomposition of the signal in terms of complex exponentials as we push that signal through a linear time invariant system, we’re separately multiplying by the frequency response the amplitudes of the exponential components used to build the input. And that sum in turn is the decomposition of the output in terms of complex exponentials.”  要尝试在概念性的程度上理解卷积特性 </p><p><strong>modulation property</strong></p><p>因为time domain和frequency domain是interchangeable 因为duality 这意味着</p><p><strong>if we multiply in the time domain, that would correspond to convolution in the frequency domain</strong>   666</p><script type="math/tex; mode=display">Modulation: \quad s(t)p(t) \iff \frac{1}{2\pi}[S(\omega)*P(\omega)] \\Convolution: \quad s(t)*p(t) \iff S(\omega)P(\omega)</script><p>对于modulation property 它是the entire basis for amplitude modulation systems as used almost universally in communications</p><p>如果we have a signal with a certain spectrum, and we multiply by a sinusoidal signal whose Fourier transform is a set of impulses, then in a frequency domain we convolve. And that corresponds to taking the original spectrum and translating it shifting it in frequency up to the frequency of the carrier.</p><h3 id="filtering的简单介绍"><a href="#filtering的简单介绍" class="headerlink" title="filtering的简单介绍"></a>filtering的简单介绍</h3><p>filtering 意思是modify separately the individual frequency components in a signal</p><p>卷积特性告诉我们 如果我们看各个频率分量，它们被乘以频率响应 那么意味着 我们可以放大或减小任何一个components separately using a linear time invariant system</p><p><strong>Ideal lowpass filter</strong> [29:54]的图  </p><p><strong>differentiator</strong> $y(t) = \frac{dx(t)}{dt} \Rightarrow H(\omega) = j\omega $ [31:10] 图，它的作用是放大高频率 衰减低频</p><p>举个例子：对于空间信号，它有高频部分和低频部分，高频对应things that are varying rapidly spatially, and low frequencies varying slowly spatially. 对[32:42]的图 进行低通滤波 就是问问视频摄像组是否可以稍微defocus it. 图像散焦[32:53] 也就是失去边缘 lost edges，edges指的是rapid variation， 我们保留的是broader slow variation.</p><p>如果想要图像的边缘增强，那么我们就differentiated the image 这个会attenuate slowly varying background and amplify the rapidly varying edges.[35:15]是经过了differentiator的图</p><h3 id="用傅里叶变换解线性常系数微分方程"><a href="#用傅里叶变换解线性常系数微分方程" class="headerlink" title="用傅里叶变换解线性常系数微分方程"></a>用傅里叶变换解线性常系数微分方程</h3><script type="math/tex; mode=display">\frac{dy(t)}{dt} + ay(t) = x(t) \\\Rightarrow j\omega Y(\omega) + aY(\omega) = X(\omega) \\\Rightarrow Y(\omega) = \frac{1}{j\omega + a}X(\omega) \\\Rightarrow h(t) \iff H(\omega) \\\Rightarrow e^{-at}u(t) \iff \frac{1}{j\omega + a}</script><p>这里用到了 differential property 和 linearity property</p><p>看到$\frac{1}{j\omega + a}$的图像 是减弱高频 保持低频，之前的将图像defocus 就相当于将图像通过这个线性微分方程</p><p>另一个例子：</p><script type="math/tex; mode=display">\frac{dy(t)}{dt} + 2y(t) = e^{-t}u(t) \\j\omega Y(\omega) + 2Y(\omega) = \frac{1}{j\omega + 1} \\Y(\omega) = \frac{1}{j\omega + 2}\frac{1}{j\omega + 1} = \frac{-1}{j\omega + 2} + \frac{1}{j\omega + 1} \\\iff -e^{-2t}u(t) + e^{-t}u(t) = y(t)</script>]]></content>
      
      
      <categories>
          
          <category> 信号与系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信号与系统 </tag>
            
            <tag> 理论知识 </tag>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kernels</title>
      <link href="2021/03/22/cs229%207/"/>
      <url>2021/03/22/cs229%207/</url>
      
        <content type="html"><![CDATA[<h2 id="Lecture-7-Kernels"><a href="#Lecture-7-Kernels" class="headerlink" title="Lecture 7 Kernels"></a>Lecture 7 Kernels</h2><p><a href="https://www.bilibili.com/video/BV1JE411w7Ub?p=10">视频链接</a></p><p><a href="http://cs229.stanford.edu/notes2020fall/notes2020fall/cs229-notes3.pdf">讲义链接</a></p><p><a href="https://link.springer.com/article/10.1007/BF00994018">SVM论文链接</a></p><p>感觉关于SVM的数学对于我来说还是挺硬核的</p><h3 id="视频笔记"><a href="#视频笔记" class="headerlink" title="视频笔记"></a>视频笔记</h3><p>这节课的主要内容是 <strong>optimization problem, representer theorem, kernels, examples of kernel</strong></p><p>optimal margin classifier plus kernels —-&gt; Support Vector Machine</p><p>关于上次课所讲的optimal margin classifer的优化式子为</p><script type="math/tex; mode=display">max_{\gamma, \omega, b} \gamma \\s.t. \frac{y^{(i)}(\omega^Tx^{(i)} + b)}{||\omega||} \ge \gamma \quad i = 1, \cdots, m</script><p><strong>下面的限制 表示 每个训练数据的geometric margin 都要比$\gamma$大</strong></p><p>因为同时对$\omega$和$b$进行常数倍乘，直线$\omega^Tx^{(i)} + b$是不会变的，我们可以设置$||\omega|| = \frac{1}{\gamma}$  六六六，得到</p><script type="math/tex; mode=display">\max \frac{1}{||\omega||} \\s.t. y^{(i)}(\omega^Tx^{(i)} + b)\gamma \ge \gamma</script><p>等价于</p><script type="math/tex; mode=display">min_{\omega,b} \frac{1}{2} ||\omega||^2 \\s.t. y^{(i)}(\omega^Tx^{(i)} + b) \ge 1 \quad i = 1, \cdots, m \tag{1}</script><p><strong>关于Kernels的部分 讲义写的非常好了</strong> $($这个思想贼棒$)$</p><p>假设 $\omega = \sum_{i  = 1}^m \alpha_i y^{(i)}x^{(i)}$ !!! 这个假设能让我们设计出可以有效解决高维特征的算法</p><p><strong>有一个叫做representer的定理 表示做出这个假设 我们不会损失任何性能</strong></p><p>假设成立时，通过$($batch $)$gradient descent来更新$\omega$，无论更新多少次，$\omega$永远都可以被$x^{(i)}$线性表示</p><p>这个可以用数学归纳法证明出来， 具体参考讲义里面的内容</p><p>根据这个假设来改写方程$(1)$</p><script type="math/tex; mode=display">\min_\alpha \frac{1}{2}(\sum_{i = 1}^m\alpha_iy^{(i)}x^{(i)})^T(\sum_{j = 1}^m\alpha_jy^{(j)}x^{(j)}) \\= \min_\alpha \frac{1}{2}\sum_i\sum_j\alpha_i\alpha_jy^{(i)}y^{(j)}(x^{(i)})^Tx^{(j)} \\denote \quad (x^{(i)})^Tx^{(j)} \ as \ \langle x^{(i)},x^{(j)}\rangle \\s.t. \quad y^{(i)}((\sum_j\alpha_jy^{(j)}x^{(j)})^Tx^{(i)} + b) \ge 1 \\y^{(i)}(\sum_j\alpha_jy^{(j)}\langle x^{(j)}, x^{(i)}\rangle + b) \ge 1 \tag2</script><p>如果能计算$\langle x^{(j)}, x^{(i)} \rangle$  那么就能处理高维特征向量的情况</p><p>$(2)$可以继续改写，通过dual optimization，得到 讲义中的方程$(24)$ </p><p>进行预测 就是</p><script type="math/tex; mode=display">h_{\omega, b}(x) = g(\omega^Tx + b) = g((\sum_i\alpha_iy^{(i)}x^{(i)})^Tx + b) \\ = g(\sum_i\alpha_iy^{(i)} \langle x^{(i)}, x^{(j)}\rangle + b)</script><h4 id="Kernel-trick："><a href="#Kernel-trick：" class="headerlink" title="Kernel trick："></a>Kernel trick：</h4><p>1$)$  Write algorithm in terms of $\langle x^{(i)}, x^{(j)} \rangle$ or $\langle x, z \rangle$ x和z表示不同的训练数据</p><p>2$)$ Let there be mapping from $x \rightarrow \phi(x)$</p><p>3$)$ Find way to compute the kernel function $K(x, z) = \phi(x)^T\phi(z)$</p><p>4$)$ Replace $\langle x, z \rangle$ in algorithm with $K(x, z)$</p><p>总结kernel的作用：</p><p>如果训练集的特征是n维向量$x \in \mathcal{R}^n$ 将$x \rightarrow \phi(x)$ 之后维数增大，比如变成了$n^2$ 那么计算</p><p>$\phi(x)^T\phi(z)$的时间复杂度就是$O(n^2)$ <strong>如果用kernel 即用$\langle x, z \rangle$来表示出$\phi(x)^T\phi(z)$ </strong>那么时间复杂度就变成了$O(n)$   用实际的例子来说明 $x = (x_1, x_2, x_3)^T , \phi(x) = (x_1x_1,x_1x_2,x_1x_3,x_2x_1,x_2x_2,x_2x_3,x_3x_1,x_3x_2,x_3x_3)^T$ 那么kernal $\mathcal{K}( x, z ) = \phi(x)^T\phi(z) = (x^Tz)^2$  [41:30] 介绍了另一个kernel $\mathcal{K}(x,z) = (x^Tz + c)^2$</p><p>对于kernel $\mathcal{K}(x, z) = (x^Tz + c)^d$  计算这个kernel的时间复杂度还是$O(n)$，$\phi(x)$ has all  ${n+d\choose d}$ features of monomial up to order d</p><p>[47:30] 开始是SVM with a polynomial Kernel visualization (没看懂 为什么映射到二维平面映射出的是非线性边界线) </p><p>用kernel的作用是 希望能将feature映射到高维空间中，希望在低维线性不可分的数据 在高维中变得线性可分</p><p>常见的几个核： Linear Kernel $\mathcal{K}(x, z) = x^Tz$   Gaussian Kernel</p><p>[64:46] 如果数据有点noisy，想要找到一个复杂的非线性边界线，不希望try so hard to separate every little example that’s defined a really complicated decision boundary. So sometimes either the low-dimensional space or in the high dimensional space $\phi$， you don’t actually want the algorithms to separate out your data perfectly and then sometimes even in hight dimensional space your data may not be linearly separable.</p><p>$L_1$范数soft margin SVM  式子就变成了讲义25页上面的那个式子</p><p>[68:30] 举了soft margin SVM的作用 作用之一是为了解决outliner的情况 和 解决距离边界线非常近的例子</p><h3 id="SVM补充"><a href="#SVM补充" class="headerlink" title="SVM补充"></a>SVM补充</h3><p><a href="https://blog.csdn.net/Gamer_gyt/article/details/51265347">scikit-learn之SVM算法</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cs229 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Support Vector Machine</title>
      <link href="2021/03/22/cs229%206/"/>
      <url>2021/03/22/cs229%206/</url>
      
        <content type="html"><![CDATA[<h2 id="Lecture-6-Support-Vector-Machine"><a href="#Lecture-6-Support-Vector-Machine" class="headerlink" title="Lecture 6 Support Vector Machine"></a>Lecture 6 Support Vector Machine</h2><p><a href="https://www.bilibili.com/video/BV1JE411w7Ub?p=8">视频链接</a></p><p><a href="http://cs229.stanford.edu/notes2020fall/notes2020fall/cs229-notes3.pdf">讲义链接</a></p><p>虽然这课叫support vector machine，但是只有最后半节课讲了support vector machine</p><h3 id="Laplace-Smoothing"><a href="#Laplace-Smoothing" class="headerlink" title="Laplace Smoothing"></a>Laplace Smoothing</h3><p>如果出现了一个单词，这个单词在之前的训练集里面没有出现过，那么按照朴素贝叶斯</p><script type="math/tex; mode=display">\mathcal{P}(x_{6017} = 1 | y = 1) = \frac{0}{\# \{ y = 1\}} = 0 \\\mathcal{P}(x_{6017} = 1 | y = 0) = \frac{0}{\# \{ y = 0\}} = 0</script><p>从统计学上说，说一个没有看见过的事情的出现概率是0 是 一个坏主意</p><p>使朴素贝叶斯崩溃的地方是 如果根据上面的式子得到的参数<script type="math/tex">\phi_{6017| y = 1} = 0</script> 和<script type="math/tex">\phi_{6017|y = 0} = 0</script></p><p>用这个参数进行估计的时候，由于式子是<script type="math/tex">\prod_{i = 1}^{10000} \mathcal{P}(x_i | y)</script> 有一项为0 结果就为0</p><p>进行预测<script type="math/tex">\mathcal{P}(y = 1 | x) = \frac{\mathcal{P(x|y = 1)}\mathcal{P}(y = 1)}{\mathcal{P}(x | y = 1)\mathcal{P}(y = 1) + \mathcal{P}(x | y = 0 )\mathcal{P}(y = 0)} = \frac{0}{0 + 0}</script></p><p><strong>拉普拉斯平滑就是用来解决这个问题</strong></p><p>老师用一个motivation来引入拉普拉斯平滑：</p><p>足球队在9.12 10.10 10.17 11.21 四场球赛都输掉了 预测12.31号的足球比赛</p><p>如果用MLE的方法<script type="math/tex">\mathcal{P}(x = 1) = \frac{\# '1's}{\#'1's + \#'0's} = \frac{0}{0 + 4} = 0</script></p><p>拉普拉斯 就是把<script type="math/tex">\#'1'</script>和<script type="math/tex">\#'0'</script>比原来多1 那么<script type="math/tex">\mathcal{P}(x = 1) = \frac{\# '1's}{\#'1's + \#'0's} = \frac{(0 + 1)}{(0+1) + (4+1)} = \frac{1}{6}</script></p><p><strong>对于more generally的情况</strong></p><p>Estimate <script type="math/tex">\mathcal{P}(x = j) = \frac{\sum_{j = 1}^m1\{x^{(i)} = j\} + 1}{M + k}</script></p><p>对于Naive Bayes：</p><script type="math/tex; mode=display">\phi_{j|y = 0} = \frac{\sum_{i = 1}^m1\{x_j^{(i)} = 1,y^{(i)} = 0\} + 1}{\sum_{i = 1}^m1\{y^{(i)} = 0 \} + 2}</script><p><strong>Tips: 将连续的特征转化为离散的特征:</strong> 将连续的数值划分称若干个区间，然后对每个区间进行标注</p><p>根据经验 一般将连续的feature 分成10个bucket 效果比较好</p><p>用naive bayes来进行text classfication的一个缺点是 naive bayes丢掉了一个单词出现次数的信息</p><p>因为每个特征<script type="math/tex">x_i \in \{0, 1\}</script> <script type="math/tex">(Multi-variate Bernoulli)</script></p><p>有一种另外的表现方式 是专门用于text data的 每个特征<script type="math/tex">x_i \in \{1, \cdots, \#classes \}（Multinomial）</script> </p><p>用第二种模型的出来的式子是<script type="math/tex">\mathcal{P}(x, y) = \mathcal{P}(x | y)\mathcal{P}(y) = \prod_{j = 1}^n \mathcal{P}(x_j|y)\mathcal{P}(y)</script></p><p> <strong>与第一种模型的区别是 这里的n 是邮件里面的字数 而非所有单词的数量</strong></p><p>参数<script type="math/tex">\phi_{k|y = 0} = \mathcal{P}(x_j = k | y = 0)</script> 其中<script type="math/tex">\mathcal{P}(x_j = k|y = 0)</script>的表示的是 如果<script type="math/tex">y = 0</script> 那么第j个单词为k的概率为<script type="math/tex">\mathcal{P}(x_j = k | y = 0)</script></p><p>值得注意的是参数<script type="math/tex">\phi_{k|y=0}</script>中j并没有出现，原因是对于邮件中每个位置 第一个单词出现drugs的机会和第二个单词出现drugs的机会相同 $($drugs是随便一个单词$)$</p><p>根据MLE 求得的结果为:</p><script type="math/tex; mode=display">\phi_{k|y = 0} =  \frac{\sum_{i = 1}^m1\{y^{(i)} = 0\}\sum_{j = 1}^n1\{x_j^{(i)} = k\} + 1}{\sum_{i = 1}^m1\{y^{(i)} = 0\}n_i + \# words}</script><p><strong>这个公式 分母是训练集中所有non-spam的单词和，<script type="math/tex">n_i</script>是第<script type="math/tex">i</script>个non-spam文档的单词数目, 分子是训练集中non-spam中k单词出现的个数</strong></p><p>如果遇见不在words里面的单词，一种方法是直接丢弃，另一种方法是take the rare words and map them to a special token which traditionally is denoted UNK for unknown words.</p><p><strong>Tips: 如果要写一个包含10000行代码的程序，一种方法是先写10000行代码 然后进行第一次编译，另一种方法是编写小模块，运行小模块然后进行测试，最后构建出程序，然后开始看看第一次遇到什么语法错误；对于机器学习也是一样 一开始建立简单模型 测试 然后看问题出在哪 然后进行改进</strong></p><h3 id="Support-Vector-Machine"><a href="#Support-Vector-Machine" class="headerlink" title="Support Vector Machine"></a>Support Vector Machine</h3><p>如果要找一个非线性的边界线，支持向量机可以帮助我们找到潜在的非线性的决策边界</p><p>如果用logistc regression来得到一个非线性的边界，一般用的方法是对feature进行扩展</p><p>比如<script type="math/tex">x_1,x_2</script>变为<script type="math/tex">x_1,x_2,x_1^2,x_2^2,x_1x_2</script>  即原来的向量<script type="math/tex">(x_1,x_2)^T</script>变成了<script type="math/tex">\phi(x) = (x_1,x_2,x_1^2,x_2^2,x_1x_2)^T</script></p><p>high dimensional features 选择这些featrues是很痛苦的一件事情</p><p>如果是support vector machine的话，就能够推导出输入是特征<script type="math/tex">x_1,x_2</script>的算法，把它们映射到更高维度的features</p><p>老师说 support vector machines are not as effective as neural networks for many problems, but one great property of support vector machine is turn key. You kind of just turn the key and it works and there isn’t as many parameters like the learning rate and other things that you had to fiddle with</p><h4 id="Optimal-margin-classfier-separable-case"><a href="#Optimal-margin-classfier-separable-case" class="headerlink" title="Optimal margin classfier(separable case)"></a>Optimal margin classfier(separable case)</h4><p>Defn: Functional margin 对于logistic function <script type="math/tex">h_\theta(x) = g(\theta^Tx)</script> 输出的是0和1 而不是概率</p><p>logistic regression的预测是</p><p>if <script type="math/tex">\theta^Tx \ge 0 ( h_\theta(x) = g(\theta^Tx) \ge 0.5)</script> predict 1 otherwise predict 0</p><p>If <script type="math/tex">y^{(i)} = 1</script>, hope that <script type="math/tex">\theta^Tx^{(i)} \gg 0</script>   If <script type="math/tex">y^{(i)} = 0</script>, hope that <script type="math/tex">\theta^Tx^{(i)} \ll 0</script>  这就是functional margin（没懂啊）</p><p>Defn: Geometric margin</p><p>就是边界线离训练数据的距离</p><p>[60:00]的图 告诉我们对于线性可分的数据集，我们可以得到多个分界线 比如红色的和绿色的，SVM就是帮助我们找到绿色的分界线</p><h5 id="下面是正式的定义"><a href="#下面是正式的定义" class="headerlink" title="下面是正式的定义"></a>下面是正式的定义</h5><p>Notation: labels $y\in\{-1, +1\}$ have h output value in $\{-1, +1\}$</p><script type="math/tex; mode=display">g(z) = \begin{cases}1& if \ z \ge 0 \\-1& otherwise\end{cases}</script><p>Previously $h_\theta(x) = g(\theta^Tx)$ 其中$x \in \mathcal{R}^{n + 1}, x_0 = 1$</p><p>在SVM中 $h_{\omega, b}(x) = g(\omega^Tx + b )$  其中$x \in \mathcal{R}^n, b \in \mathcal{R}$ drop convetions $x_0 = 1$</p><p>Functional margin of hyperplane defined by $(\omega, b)$ w.r.t. $(x^{(i)}, y^{(i)})$</p><script type="math/tex; mode=display">\hat{\gamma}^{(i)} = y^{(i)}(\omega^Tx^{(i)} + b) \tag{1}</script><p>为了要large functional margin 即 如果$y^{(i)} = $1 我们想要$\omega^Tx^{(i)} + b \gg 0 $ 如果$y^{(i)} = -1$ 我们想要 $\omega^Tx^{(i)} + b \ll 0$， 由式子$(1)$ 等价于要$\gamma$非常的大</p><p>functional margin w.r.t. training set $\hat{\gamma} = \min_i\hat{\gamma}^{(i)} \ i = 1,\cdots, m$</p><p><strong>观察到如果将$\omega$和b 加倍 那么function margin也会加倍</strong>  所以我们要规范化长度即$||\omega|| = 1$</p><p>那么$(\omega, b) \rightarrow (\frac{\omega}{||\omega||}, \frac{b}{||b||})$ 实际上 分母可以取其他的值</p><h5 id="Geometric-margin："><a href="#Geometric-margin：" class="headerlink" title="Geometric margin："></a>Geometric margin：</h5><p>[73:44]的图 那张图清晰的定义了geometric margin</p><p>Geometric margin of hyperplane $(\omega, b)$ w.r.t. $(x^{(i)}, y^{(i)})$ is </p><script type="math/tex; mode=display">\gamma^{(i)} = \frac{y^{(i)}(\omega^Tx^{(i)} + b)}{||\omega||} \\\gamma^{(i)} = \frac{\hat{\gamma}^{(i)}}{||\omega||}</script><p>geometric margin w.r.t. training set $\gamma = \min_i\gamma^{(i)}$</p><p><strong>那么 optimal margin classifier 就是choose $\omega, b$ to maximize $\gamma$</strong></p><p>解决这个问题的方法之一是 </p><script type="math/tex; mode=display">max_{\gamma, \omega, b} \gamma \\s.t. \frac{y^{(i)}(\omega^Tx^{(i)} + b)}{||\omega||} \ge \gamma \quad i = 1, \cdots, m</script><p>这不是一个凸优化问题 所以很难用梯度下降来解决</p><p>我们把这个式子 改变一下，改成一个凸优化问题</p><script type="math/tex; mode=display">\min_{\omega, b} ||\omega||^2 \\s.t. y^{(i)}(\omega^T x^{(i)} + b) \ge 1</script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cs229 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Continuous-Time Fourier Series</title>
      <link href="2021/03/22/signal%20and%20system%207/"/>
      <url>2021/03/22/signal%20and%20system%207/</url>
      
        <content type="html"><![CDATA[<h2 id="Lecture-7-Continuous-Time-Fourier-Series"><a href="#Lecture-7-Continuous-Time-Fourier-Series" class="headerlink" title="Lecture 7 Continuous-Time Fourier Series"></a>Lecture 7 Continuous-Time Fourier Series</h2><p>在一个线性系统中如果输入可被分解为a linear combination of basic input，with each of these basic inputs generating an associated output</p><script type="math/tex; mode=display">x(t) = a_1\phi_1(t) + a_2\phi_2(t) + \cdots \\\phi_k(t) \rightarrow \psi_k(t) \quad and \ system\ is \ linear \\Then:y(t) = a_1\psi_1(t) + a_2\psi_2(t) + \cdots</script><p><strong>对于基本信号$\phi_k(t)$的选择 首先是a broad class of signals could be represented in terms of these basic inputs 其次是 the response to these basic inputs is easy to compute.</strong></p><p><strong>核心的两个性质</strong></p><p>在LTI系统中我们的选择是</p><p>C-T: $\phi_k(t) = \delta(t - k\Delta)$  和 $\psi_k(t) = h(t - k\Delta) \Rightarrow$ Convolution Integral</p><p>D-T: $\phi_k[n] = \delta[n - k]$ 和$\psi_k[n] = h[n - k] \Rightarrow$ Convolution Sum</p><p>新的building blocks是complex exponentials$($ 拥有上述两个性质 $)$ </p><p>$\phi_k(t) = e^{s_kt}$  $s_k$ 是complex， $\phi_k[n]$ = $z_k^n$  $z_k$ 是complex</p><p><strong>Fourier Analysis:</strong></p><p>C-T: $s_k = j\omega_k$      $\phi_k(t) = e^{j\omega_kt}$  </p><p>D-T: $|z_k| = 1$        $\phi_k[n] = e^{j\Omega_kn}$</p><p>这里对于$s_k$ 和 $z_k$ 是复数的特殊情况</p><p><strong>一般性的化 $s_k$ complex $\Rightarrow$ Laplace transforms   $z_k$ complex $\Rightarrow$ z-transforms</strong></p><h3 id="Eigenfunction-property-of-this-particular-set-of-building-blocks"><a href="#Eigenfunction-property-of-this-particular-set-of-building-blocks" class="headerlink" title="Eigenfunction property of this particular set of building blocks"></a>Eigenfunction property of this particular set of building blocks</h3><script type="math/tex; mode=display">e^{j\omega_kt} \rightarrow H(\omega_k)e^{j\omega_kt} \\e^{j\omega_kt} \rightarrow \int_{-\infty}^{+\infty}h(\tau)e^{j\omega_k(t - \tau)}d\tau \\=e^{j\omega_kt}\int_{-\infty}^{+\infty}h(\tau)e^{-j\omega_k\tau}d\tau \\= e^{j\omega_kt}H(\omega_k)</script><p>we put in a complex exponential, we get out a complex exponential of the same frequency, multiplied by a complex constant. <strong>这就是所谓的eigenfunction property</strong></p><p>即输入和输出看起来除了振幅变化之外 其余完全一样，the change amplitude being the eigenvalue</p><p>称$e^{j\omega_kt}$为eigenfunction  称$H(w_k)$为eigenvalue</p><h3 id="Periodic-Signals-Fourier-Series"><a href="#Periodic-Signals-Fourier-Series" class="headerlink" title="Periodic Signals: Fourier Series"></a>Periodic Signals: Fourier Series</h3><script type="math/tex; mode=display">x(t) = x(t + T_0) \quad T_0 \ is \ period \\w_0 = \frac{2\pi}{T_0} = 2\pi f_0</script><p>对于$e^{j\omega_0t}$ 的基本周期就是$T_0$，谐波相关的复指数是(虽然$T_0$也是周期，但是它们的基本周期更短) 如$e^{jk\omega_0t}$ 其周期为$\frac{T_0}{k} = \frac{2\pi}{k\omega_0}$  随着k的变化 这些complex exponentials 称作为harmonically related </p><p>傅里叶级数（一个非常普通的周期函数可以表示成谐波相关的复指数信号的线性组合）</p><script type="math/tex; mode=display">x(t) = \sum_{k = -\infty}^{+\infty}a_ke^{jk\omega_0t} \tag{1}</script><p> 对于这个级数我们有两个问题</p><ul><li>我们如何确定傅里叶级数的系数$a_k$</li><li>how broad a class of signals can be represented this way</li></ul><p>傅里叶级数也有其他的表现形式 trigonometric form:</p><script type="math/tex; mode=display">a_k = A_ke^{j\theta_k} = B_k + jC_k \\e^{jk\omega_0t} = cosk\omega_0t + jsink\omega_0t \\</script><p>然后老师写了下面的式子，至于怎么从$(1)$得到下面的式子 我没弄明白</p><script type="math/tex; mode=display">x(t) = a_0 + 2\sum_{k = 1}^\infty A_kcos(k\omega_0t + \theta_k) \\= a_0 + 2\sum_{k = 1}^\infty [B_kcosk\omega_0t -C_ksink\omega_0t]</script><p>注意到：</p><script type="math/tex; mode=display">\int_{T_0}e^{jm\omega_0t}dt = \begin{cases}T_0& m = 0 \\0& m \ne 0\end{cases} \\\because \int_{T_0}e^{jm\omega_0t}dt = \int_{T_0}cosm\omega_0tdt + j\int_{T_0}sinm\omega_0tdt = 0 + 0j = 0 \ for \ m\ne0</script><p>根据这个性质：</p><script type="math/tex; mode=display">\int_{T_0}x(t)e^{jn\omega_0t}dt = \int_{T_0}e^{-jn\omega_0t}\sum_{k=-\infty}^{+\infty}a_ke^{jk\omega_0t}dt \\= \sum_{k = -\infty}^{+\infty}a_k\int_{T_0}e^{-j(k - n)\omega_0t}dt \\= \begin{cases}T_0& if \ k = n \\0& if \ k \ne n\end{cases} \\\therefore \frac{1}{T_0}\int_{T_0}x(t)e^{-jn\omega_0t} = a_n \quad analysis \ equation</script><p>我们称方程$(1)$ 为synthesis equation</p><p>例子[25:00] antisymmetric periodic square wave</p><p>得到的傅里叶系数$a_0 = 0, a_k = \frac{1}{j\pi k}(1 - (-1)^k)$ 是纯虚数 和 odd sequence 即$a_k = -a_{-k}$</p><p>表示成三角级数: **注意因为$a_k$是纯虚数，乘上$j$之后就变成实数</p><script type="math/tex; mode=display">x(t) = a_0 + \sum_{k = 1}^{+\infty} 2ja_ksink\omega_0t</script><p>例子 [30:40]  symmetric periodic square wave</p><p>[34:00] 展示了级数是如何还原出方波函数的 利用部分和$x_N(t) = \frac{1}{2} + \sum_{k = 1}^N2a_kcosk\omega_0t$ 不断增加N的大小 来看图像是如何的</p><p><strong>the low frequency terms that represent the broad time behavior, and it’s the high frequency terms that are used to build up the sharp transitions in the time domain.</strong></p><p>[43:00]讲的是傅里叶级数收敛的条件</p><p>[47:00] 显示了部分和随N增加，原函数与傅里叶级数部分和的误差的能量值 随N增大的变化，当N是奇数时误差能量不变，N是偶数时误差能量减小</p>]]></content>
      
      
      <categories>
          
          <category> 信号与系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信号与系统 </tag>
            
            <tag> 理论知识 </tag>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Systems Represented by Differential and Difference Equations</title>
      <link href="2021/03/14/signal%20and%20system%206/"/>
      <url>2021/03/14/signal%20and%20system%206/</url>
      
        <content type="html"><![CDATA[<h2 id="Lecture-6-System-Represented-by-Differential-and-Difference-Equations"><a href="#Lecture-6-System-Represented-by-Differential-and-Difference-Equations" class="headerlink" title="Lecture 6 System Represented by Differential and Difference Equations"></a>Lecture 6 System Represented by Differential and Difference Equations</h2><p><a href="https://www.bilibili.com/video/BV1xy4y167DD?p=6">视频链接</a> 对应于书上的2.4的内容</p><p>A particularly important set of systems, which are linear and time-invariant, are those that are represented by linear constant-coefficient differential equations in continuous time or linear constant-coefficient difference equations in discrete time</p><h3 id="n阶线性常系数微分方程的定义："><a href="#n阶线性常系数微分方程的定义：" class="headerlink" title="n阶线性常系数微分方程的定义："></a>n阶线性常系数微分方程的定义：</h3><script type="math/tex; mode=display">\sum_{k = 0}^Na_k\frac{d^ky(t)}{dt^k} = \sum_{k = 0}^Mb_k\frac{d^kx(t)}{dt^k}  \tag{1}</script><p> 常系数表示系数都是常数（不随时间变化），被称为线性是因为对应于linear combination of these derivatives, not because it corresponds to a linear system</p><p><strong>这个方程可能会也可能不会对应于线性系统</strong></p><h3 id="n阶线性常系数差分方程的定义："><a href="#n阶线性常系数差分方程的定义：" class="headerlink" title="n阶线性常系数差分方程的定义："></a>n阶线性常系数差分方程的定义：</h3><script type="math/tex; mode=display">\sum_{k=0}^Na_ky[n-k] = \sum_{k=0}^Mb_kx[n-k] \tag{2}</script><h3 id="n阶线性常系数微分方程的解法："><a href="#n阶线性常系数微分方程的解法：" class="headerlink" title="n阶线性常系数微分方程的解法："></a>n阶线性常系数微分方程的解法：</h3><p><strong>方程相对应的Homogeneous Equation定义如下，其解为$y_h(t)$</strong></p><script type="math/tex; mode=display">\sum_{k = 0}^Na_k\frac{d^ky_h(t)}{dt^k} = 0 \tag{3}</script><p>给定输入$x(t)$，如果$y_p(t)$满足方程$(1)$ 那么$y_p(t) + y_h(t)$也会满足方程$(1)$ </p><p>通常称$y_p(t)$为Particular solution，$y_h(t)$为Homogeneous solution</p><p>所以方程$(1)$并非是a unique specification of the system.</p><h3 id="n阶线性齐次常系数微分方程的解法："><a href="#n阶线性齐次常系数微分方程的解法：" class="headerlink" title="n阶线性齐次常系数微分方程的解法："></a>n阶线性齐次常系数微分方程的解法：</h3><p>“guess” solution of the form $y_h(t) = Ae^{st}$ 把这个代入到$(3)$中得</p><script type="math/tex; mode=display">\sum_{k=0}^Na_kAs^ke^{st} = 0 \label{4}\tag{4} \\</script><script type="math/tex; mode=display">\because e^{st} \ne 0, A \ne 0 \quad \therefore \sum_{k=0}^Na_ks^k = 0 \quad N \ roots \ s_i \quad i = 1,\cdots,N \tag{5}</script><script type="math/tex; mode=display">y_h(t) = A_1e^{s_1t} + A_2e^{s_2t} + \cdots + A_Ne^{s_Nt} \tag{6}</script><p>通过方程$(5)$能得到得是N个s得值 但是常数$N$以及$A_1,\cdots,A_N$是不确定的</p><p>我们要解出这些常数 就需要N auxiliary conditions, 例如</p><script type="math/tex; mode=display">y(t), \frac{dy(t)}{dt},\cdots,\frac{d^{N - 1}y(t)}{dt^{N-1}} \ at \ t = t_0</script><p>取决于这些auxiliary conditions，the system may or may not correspond to a linear system</p><ul><li>Linear system $\iff$ auxiliary conditions = 0</li><li>Causal LTI $\iff$ initial rest： if $x(t) = 0$ for $t &lt; t_0$ then $y(t) = 0$ for $t &lt; t_0$</li></ul><p>例：$\frac{dy(t)}{dt} + ay(t) = x(t)$ 其对应的齐次方程为$\frac{dy_h(t)}{dt} + ay_h(t) = 0 \tag{7}$</p><p>猜测解为$y_h(t)  = Ae^{st}$ 代入得 $Ase^{st} + aAe^{st} = 0$ 化简得$s + a = 0$</p><p>得$y_h(t) = Ae^{-at}$</p><p>假设给定特定得输入为$x(t) = ku(t)$ 则$x(1) = k$ 代入微分方程得$\frac{dy(t)}{dt} + ay(t) = ku(t)$</p><p>解得相应的特解为$y_p = \frac{k}{a}[1 - e^{-at}]u(t)$</p><p>对于该微分方程的a family of solutions 为$y(t) = \frac{k}{a}[1 - e^{-at}]u(t) + Ae^{-at}$</p><p>求出A的值要auxiliary conditions，对于initial rest的条件 $\Rightarrow$ Causal, LTI $\Rightarrow$ $y(t) = \frac{k}{a}[1 - e^{-at}]u(t)$</p><p><strong>求冲激响应 这个知识点重要</strong></p><p>对于LTI系统 级联的顺序无关紧要</p><script type="math/tex; mode=display">u(t) \rightarrow \boxed{\frac{d}{dt}} \rightarrow \boxed{h(t)} \rightarrow h(t)</script><p>上面的系统与下面等效</p><script type="math/tex; mode=display">u(t) \rightarrow \boxed{h(t)}  \rightarrow \boxed{\frac{d}{dt}}  \rightarrow h(t)</script><p>上面的中间结果为$\delta(t)$，下面的中间结果为$s(t) = \frac{1}{a}[1 - e^{-at}]u(t)$ 所以求$h(t)$ 就可以直接对$s(t)$求导</p><p>解得$h(t) = \frac{s(t)}{dt} = u(t)\frac{d}{dt}\frac{1}{a}[1 - e^{-at}] + \frac{1}{a}[1 - e^{-at}]\frac{d}{dt}u(t) = e^{-at}u(t) + \frac{1}{a}[1 - e^{-at}]\delta(t)$</p><p>当$t \ne 0$时 $\delta(t)$为0， 得$h(t) = e^{-at}u(t)$  当$t = 0时$ $1 - e^{-at} = 0$ 所以无论$t$取什么值，右边的都为0</p><p>由之前的知识知 如果该系统是稳定的， 那么$a &gt; 0$</p><h3 id="n阶线性常系数差分方程的解法："><a href="#n阶线性常系数差分方程的解法：" class="headerlink" title="n阶线性常系数差分方程的解法："></a>n阶线性常系数差分方程的解法：</h3><p>与连续的情况类似 齐次方程为</p><script type="math/tex; mode=display">\sum_{k = 0}^N a_ky_h[n - k] = 0 \quad (Homogeneous \ Equation) \tag{8}</script><p>给定输入$x[n]$，如果$y_p[n]$满足方程$(8)$ 那么$y_p[n] + y_h[n]$也会满足方程$(1)$ </p><p>通常称$y_p[n]$为Particular solution，$y_h[n]$为Homogeneous solution</p><h3 id="n阶线性齐次常系数微分方程的解法：-1"><a href="#n阶线性齐次常系数微分方程的解法：-1" class="headerlink" title="n阶线性齐次常系数微分方程的解法："></a>n阶线性齐次常系数微分方程的解法：</h3><p>“guess” solution of the form $y[n] = Az^n$ 代入到方程$(8)$得$\sum_{k = 0}^Na_kAz^nz^{-k} = 0$</p><p>同样$\because A \ne 0，z \ne 0$ 我们得到$\sum_{k = 0}^Na_kz^{-k} = 0$ N roots $z_1, z_2, \cdots, z_N$</p><p>最终的解是$y_h[n] = A_1z_1^n + \cdots + A_Nz_N^n$</p><p>我们要解出这些常数 就需要N auxiliary conditions, 例如</p><script type="math/tex; mode=display">y[n_o], y[n_o - 1], y[n_o - 2],\cdots,y[n_o - N + 1]</script><p>取决于这些auxiliary conditions，the system may or may not correspond to a linear system</p><ul><li>Linear system $\iff$ auxiliary conditions = 0</li><li>Causal LTI $\iff$ initial rest： if $x[n] = 0$ for $n &lt; n_o$ then $y[t] = 0$ for $n &lt; n_o$</li></ul><p>微分方程和差分方程很类似， 某些情况下，差分方程更容易处理</p><p>假设系统是causal的：</p><p>对于方程$(2)$的解，$y[n] = \frac{1}{a_o} \{  \sum_{k = 0}^Mb_kx[n - k] - \sum_{k = 1}^Na_ky[n - k] \}$</p><p>如果我们知道$x[n]$和$y[n_o - 1], y[n_o - 2], \cdots, y[n_o - N]$ 那么我可以求得$y[n_o]$继而可以求$y[n_o + 1]$</p><p>例 $y[n] - ay[n - 1] = x[n]$ $\Rightarrow$ $y[n] = x[n] + ay[n - 1] \tag{9}$</p><p>causal LTI $\iff$ Initial Rest  假设输入$x[n] = \delta[n]$ 代入得$h[n] = \delta[n] + ah[n - 1]$</p><p>$h[n] = 0$ 对于$n &lt; 0$ 然后$n = 0$ 代入得$h[0] = 0$ 继续得$h[1] = a, h[2] = a^2$</p><p>如果是这个系统是稳定话 $\iff |a| &lt; 1$</p><p>求解齐次方程的解 $y_h[n]$  令$y_h[n] = Az^n$ 代入得$Az^n - aAz^{n - 1} \Rightarrow 1 - az^{-1} = 0 \Rightarrow a = z$</p><p>$\Rightarrow y_h[n] = Aa^n$  所以对与这个系统$\delta[n] \rightarrow a^nu[n] + Aa^n$</p><p>如果系统是causal的LTI 那么$A = 0$</p><p>[32:04] 将方程$(9)$画成图，这个图是一个反馈系统 [33:49] 画的是方程$(2)$对应的图</p><p>接下来的是将连续的情况画成图</p>]]></content>
      
      
      <categories>
          
          <category> 信号与系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信号与系统 </tag>
            
            <tag> 理论知识 </tag>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Perceptron Generalized Linear Model</title>
      <link href="2021/03/13/cs229%204/"/>
      <url>2021/03/13/cs229%204/</url>
      
        <content type="html"><![CDATA[<h2 id="Lecture-4-Perceptron-Generalized-Linear-Model"><a href="#Lecture-4-Perceptron-Generalized-Linear-Model" class="headerlink" title="Lecture 4 Perceptron Generalized Linear Model"></a>Lecture 4 Perceptron Generalized Linear Model</h2><p><a href="https://www.bilibili.com/video/BV1JE411w7Ub?p=5">视频链接</a></p><p><a href="http://cs229.stanford.edu/notes2020fall/notes2020fall/cs229-notes1.pdf">讲义链接</a></p><h3 id="Perceptron"><a href="#Perceptron" class="headerlink" title="Perceptron"></a>Perceptron</h3><p>感知机现实不怎么会用到，学这个主要是出于历史原因</p><p>logistic regression用的函数是sigmoid函数 $g(z) = \frac{1}{1 + e^{-z}}$</p><p>而percetron用的是$g(z) = \begin{cases} 1&amp; z \ge 0 \\0&amp;  z &lt; 0 \end{cases}$</p><p>两者的更新公式都是$\theta_j := \theta_j + \alpha(y^{(i)} - h_\theta(x^{(i)}))x_j^{(i)}$</p><p>其中$y^{(i)} - h_\theta(x^{(i)})$的值只可能是1或者0或者-1</p><p>翻翻李航的书(第二版) P39  $y$的取值是$\{-1,1\}$，更新标准是 如果错误分类，则</p><script type="math/tex; mode=display">\omega \leftarrow \omega + \eta y_i x_i \\b \leftarrow b + \eta y_i</script><p>[9:00] 左右的视频讲的非常清楚 图画的很好</p><p>感知机一般不用于实际的原因之一是这个模型没有概率解释，而且感知机无法对XOR进行分类</p><h3 id="exponential-family"><a href="#exponential-family" class="headerlink" title="exponential family"></a>exponential family</h3><p>这是一类概率分布 probability density function为：</p><script type="math/tex; mode=display">p(y;\eta) = b(y)exp(\eta^TT(y) - a(\eta))</script><p>这个公式里面$y$是数据，$\eta$是natural parameter，$T(y)$是充分统计量，$b(y)$是base measure，$a(\eta)$是log-partition（为了让这个式子积分结果为1）</p><p>关于充分统计量的知识<a href="https://www.zhihu.com/question/41367707/answer/572628701">链接</a>  在数理统计书上的定义是 设$\theta$是总体分布中的参数，$X_1,X_2,\cdots,X_n$是来自此总体的样本，$T = T(X_1, X_2, \cdots,X_n)$是统计量，若在已知$T = t$的条件下，样本的条件分布于$\theta$无关，则称$T$为$\theta$的充分统计量</p><p>Bernoulli(Binary data)  $\phi = $ probability of event</p><p>其PDF为$p(y;\phi) = \phi^y(1-\phi)^{(1 - y)}$ 我们要把这个PDF massage 成exponential family的形式</p><script type="math/tex; mode=display">\begin{aligned}p(y;\phi) &= exp(log(\phi^y(1-\phi)^{(1-y)})) \\&= exp[log(\frac{\phi}{1-\phi})y + log(1 - \phi)]\end{aligned}</script><p>massage: $b(y) = 1, T(y) = y,\eta = log(\frac{\phi}{1 - \phi}) + log(1 - \phi),a(\eta) = -log(1 - \phi)$</p><p>由$\eta = log(\frac{\phi}{1 - \phi})$可得$\phi = \frac{1}{1 + e^{-\eta}}$代入道$a(\eta)$中可得$a(\eta) = log(1 + e^\eta)$</p><p>由上面的massage 可知Bernoulli分布是exponential 分布</p><p>Gaussian（假设方差为1）</p><p>其PDF为$p(y;\mu) = \frac{1}{\sqrt{2\pi}}exp(-\frac{(y - \mu)^2}{2})$把这个PDF massage成 exponential family的形式</p><script type="math/tex; mode=display">p(y;\mu) = \frac{1}{\sqrt{2\pi}}e^{-\frac{y^2}{2}}exp(\mu y - \frac{1}{2}\mu^2)</script><p>其中$b(y) = \frac{1}{\sqrt{2\pi}}exp{-\frac{y^2}{2}}, T(y) = y, \eta = \mu, a(\eta) = \frac{\mu^2}{2} = \frac{\eta^2}{2}$</p><p><strong>exponential family的性质</strong></p><ul><li>如果我们对exponential family进行MLE w.r.t. $\eta$，那么the optimization problem is concave</li><li>$E[y;\eta] = \frac{\partial}{\partial\eta}a(\eta)$</li><li>$Var[y;\eta] = \frac{\partial^2}{\partial \eta^2}a(\eta)$</li></ul><h3 id="Generalized-Linear-Models"><a href="#Generalized-Linear-Models" class="headerlink" title="Generalized Linear Models"></a>Generalized Linear Models</h3><p><strong>we can build many powerful models by choosing an appropriate family in the exponential family and kind of plugging it onto a linear model</strong></p><p>对于GLM的假设</p><ul><li><p>$y | x;\theta \sim$ Exponential Family$(\eta)$ 对于不同的数据类型可以用不同的模型Real - Gaussian，Binary - Bernoulli，Count - Poisson，$R^+$ - Gamma, exponential，Distribution - Beta，Dirichlet 后面两个一般用于贝叶斯统计学习</p></li><li><p>$\eta = \theta^Tx \ \theta \in \mathrm{R}^n \ x \in \mathrm{R}^n$</p></li><li><p>Test Time: Output为$E[y|x;\theta] \Rightarrow h_\theta(x) = E[y|x;\theta]$</p><p>Train Time: $\max_\theta log p(y^{(i)}, \theta^Tx^{(i)})$ 用gradient ascent</p></li></ul><p><strong>GLMs Training</strong></p><p>Learning Update Rule(所有GLMs都一样) $\theta_j := \theta_j + \alpha(y^{(i)} - h_\theta(x{(i)}))x_j^{(i)}$</p><p>[52:12] 一些术语 $\eta$ - natural parameter </p><p>$\mu = E[y;\eta] = g(\eta)$ Canonical Response function</p><p>$\eta = g^{-1}(\mu)$ Canonical Link function</p><p>[53:50] 开始讲述了three different kinds of parameterizations we have</p><p>model parameters       natural parameters     canonical parameters</p><p>[58:40] 有人问到如何对于输出来选择分布</p><p>老师的Answer: the choice of what distribution you are going to choose is really dependent on the task that you have. So if  your task is regression where you want to output real valued numbers like price of the house then you choose a distribution over the real numbers like a Gaussian. If your task is classification, where your output is binary 0, or 1, you choose a distribution that models binary data</p><h3 id="Softmax-Regression"><a href="#Softmax-Regression" class="headerlink" title="Softmax Regression"></a>Softmax Regression</h3><p>用于多个类别的分类，输出是一个one-hot vector，就是一个只有0和1构成的向量，向量里面每个位置代表着一个类，一个向量里面只有一个1其余的都是0，1所在的位置就表示输出是相应的类</p><p>这部分讲义里面写的挺好</p><p>softmax 输出的是所有类的一个概率分布</p><h4 id="666-one-hot-vector-可以看作是一个概率分布"><a href="#666-one-hot-vector-可以看作是一个概率分布" class="headerlink" title="666 one-hot vector 可以看作是一个概率分布"></a>666 one-hot vector 可以看作是一个概率分布</h4><p><strong>真实标签 也可以看作是一个概率分布，对于标签的类概率是1，其余类概率是0</strong> </p><p>我们希望两个distribution变得相近，the term for that is to minimize the cross entropy between the two distributions</p><h3 id="Gaussian-Distribution"><a href="#Gaussian-Distribution" class="headerlink" title="Gaussian Distribution"></a>Gaussian Distribution</h3><p>这是官网上面关于高斯分布的材料的学习笔记，<a href="http://cs229.stanford.edu/section/gaussians.pdf">链接part1</a>  以及 <a href="http://cs229.stanford.edu/notes2020fall/notes2020fall/more_on_gaussians.pdf">链接part2</a></p><p>对于univariate normal distribution，the coefficient $\frac{1}{\sqrt{2\pi}\sigma}$ is a constant that does not depend  on x; <strong>我们可以把它看作是为了让下面的积分为1 所存在的一个”normalization factor”</strong></p><script type="math/tex; mode=display">\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{\infty}exp(-\frac{1}{2\sigma^2}(x - \mu)^2) = 1</script><p>Proposition 1的证明在下面的Appendix A.1</p><script type="math/tex; mode=display">\Sigma = E[(X - \mu)(X - \mu)^T] = E[XX^T] - \mu\mu^T</script><p>Proposition 2证明$\Sigma$是半正定的（这里$\Sigma$的定义是the covariance matrix corresponding to some random vector X）证明中有个等式引起了我的注意：</p><script type="math/tex; mode=display">\sum_i\sum_jx_ix_jz_iz_j = (x^Tz)^2</script><p>x的维数要和z的维数相同</p><p>假如维数为1 则$\sum_i\sum_jx_ix_jz_iz_j = x_1^2z_1^2 = (x^Tz)^2$</p><p>假如维数为2 则$\sum_i\sum_jx_ix_jz_iz_j = x_1^2z_1^2 + 2x_1x_2z_1z_2 + x_2^2z_2^2 = (x1z_1 + x_2z_2)^2 = (x^Tz)^2$</p><p>假如维数为k成立，那么维数为k + 1时</p><script type="math/tex; mode=display">\begin{aligned}\sum_{i = 1}^{k + 1}\sum_{j = 1}^{k + 1}x_ix_jz_iz_j  &= x_{k+1}z_{k+1}\sum_{j= 1}^{k + 1}x_jz_j +\sum_{i = 1}^k\sum_{j = 1}^{k + 1}x_ix_jz_iz_j \\&= x_{k+1}z_{k+1}\sum_{j= 1}^{k + 1}x_jz_j + x_{k + 1}z_{k + 1}\sum_{i = 1}^kx_iz_i + \sum_{i = 1}^k\sum_{j = 1}^kx_ix_jz_iz_j\\&= (x^Tz)_{k \ dimension}^2 + x_{k + 1}^2z_{k + 1}^2 + 2x_{k+1}z_{k+1}\sum_{i = 1}^kx_iz_i \\&= (x^Tz)_{k \ dimension}^2 + 2x_{k + 1}z_{k + 1}(x^Tz)_{k \ dimension} +  x_{k + 1}^2z_{k + 1}^2 \\&= ((x^Tz)_{k \ dimension}^2 + x_{k + 1}z_{k + 1})^2 \\&= (x^Tz)^2_{k+1 \ dimension} \quad \quad  \quad \quad \quad \quad q.e.d.\end{aligned}</script><p><strong>讲义里面的Shape of isocontours写的非常具有启发性</strong></p><p>对于$\Sigma$是对角阵的情况：</p><script type="math/tex; mode=display">c = \frac{1}{2\pi\sigma_1\sigma_2}exp(-\frac{1}{2\sigma_1^2(x_1 - \mu_1)^2} - \frac{1}{2\sigma_2^2}(x_2 - \mu_2)^2) \\log(\frac{1}{2\pi c\sigma_1\sigma_2}) = \frac{1}{2\sigma_1^2}(x_1 - \mu_1)^2 + \frac{1}{2\sigma_2^2}(x_2 - \mu_2)^2 \\1 = \frac{(x_1 - \mu_1)^2}{2\sigma_1^2log(\frac{1}{2\pi c\sigma_1\sigma_2})} + \frac{(x_2 - \mu_2)^2}{2\sigma_2^2log(\frac{1}{2\pi c\sigma_2\sigma_2})}</script><p><strong>等高线是一个axis-aligned ellipse</strong></p><p>对于$\Sigma$不是对角阵的情况：等高线是一个rotated ellipse</p><p>扩展到n维的情况 图形称作为ellipsoids</p><p><strong>Appendix A.2非常棒</strong></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cs229 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Locally Weighted Linear Regression</title>
      <link href="2021/03/08/cs229%203/"/>
      <url>2021/03/08/cs229%203/</url>
      
        <content type="html"><![CDATA[<h3 id="Lecture-3-Locally-Weighted-Linear-Regression"><a href="#Lecture-3-Locally-Weighted-Linear-Regression" class="headerlink" title="Lecture 3 Locally Weighted Linear Regression"></a>Lecture 3 Locally Weighted Linear Regression</h3><p>这是根据<a href="https://www.bilibili.com/video/BV1JE411w7Ub?p=2">吴恩达CS229课程视频</a>的笔记</p><p>官方有一个notes，<a href="http://cs229.stanford.edu/notes2020fall/notes2020fall/cs229-notes1.pdf">链接</a></p><p>对于一个比较复杂形状的函数，自己定义函数的形式$y=f(x)$比较困难，这时可以用locally weighted linear regression</p><ul><li><p>”Parametric” learning algorithm:</p><p>Fit fixed set of parameters $\theta_i$ to data</p></li><li><p>“Non-Parameteric” learning algorithm</p><p>Amount of data/parameters you need to keep grows(linearly) with the size of data</p><p>LWR，KNN就是Non-Parameteric的</p></li></ul><p><strong>LWR通常不外推，意思是对于在训练集两端外的预测 效果可能会不好</strong></p><p><strong>老师更倾向对于相对低维的数据集使用LWR(比如n = 2或3，有很多数据的情况)</strong></p><h4 id="Probabilistic-interpretation"><a href="#Probabilistic-interpretation" class="headerlink" title="Probabilistic interpretation"></a>Probabilistic interpretation</h4><p>这个部分是说明cost function的由来，基于一个重要假设是$y^{(i)} = \theta^\mathrm{T}x^{(i)} + \epsilon^{(i)}$ 其中$\epsilon^{(i)}$是独立同分布且服从$\mathcal{N}(0, \sigma^2)$，$\epsilon^{(i)}$代表着随机误差</p><p><strong>注意，这个假设就表示训练集中的每个数据是IID的，如果现实中数据不是IID的，那么用这个方法就不合理，可以去构建一个更复杂的模型</strong></p><p>讲义当中的公式$\mathcal{P}(y^{(i)}|x^{(i)};\theta)$里面$x^{(i)}$和$\theta$中间的分号表示$\theta$是一个参数，如果是逗号，那么说明$\theta$是一个随机变量</p><p><strong>likelihood和probability的区别</strong></p><p>视频里面是这么说的：</p><p>the likelihood of the parameters is exactly the same thing as the probability of the data就是函数形式相同，if you view this thing as a function of the parameters holding the data fixed, then we call that likelihood</p><h4 id="Classification-Problem"><a href="#Classification-Problem" class="headerlink" title="Classification Problem"></a>Classification Problem</h4><p>视频44分钟里面画了一张图，用之前的线性回归来应用于这个数据集效果是不好的，线性回归的方法是回归出一条直线，然后设置一个阈值，通过阈值进行分类(大于阈值的一类，小于阈值的另一类)</p><p>这个方法的缺陷在于，45分钟的图，如果有一个稍微偏远的数据，可能会明显改变直线，因而改变决策边界，效果不好。</p><p>我们想要一个$h_\theta(x) \in [0, 1]$  sigmoid函数 $g(x) = \frac{1}{1 + e^{-z}}$ 代入得 $h_\theta(x) = g(\theta^{\mathrm{T}}x) = \frac{1}{1 + e^{-\theta^{\mathrm{T}}x}}$</p><p><em>这里有一个假设$\mathcal{P}(y = 1 | x ; \theta) = h_\theta(x)$</em> 由于是二分类的 所以$\mathcal{P}(y = 0 | x ; \theta) = 1 - h_\theta(x)$</p><p>将这两个式子写成一个式子 $\because y \in \{0 , 1\}$</p><script type="math/tex; mode=display">\mathcal{P}(y | x ; \theta) = h(x)^y(1-h(x))^{1-y}    \quad 666</script><p>对这个概率分布，we can write down the likelihood of the parameters as:</p><script type="math/tex; mode=display">\begin{aligned}L(\theta) &= p(\vec{y}|X,\theta) \\&= \prod_{i = 1}^n p(y^{(i)}|x^{(i)};\theta) \\&= \prod_{i = 1}^n (h_\theta(x^{(i)}))^{y^{(i)}}(1 - h_\theta(x^{(i)}))^{(1 - y^{(i)})}\end{aligned}</script><p>maximize the log likelihood:</p><script type="math/tex; mode=display">\begin{aligned}\ell(\theta) &= logL(\theta) \\&=  \sum_{i = 1}^n y^{(i)}logh(x^{(i)}) + (1 - y^{(i)})log(1 - h(x^{(i)}))\end{aligned}</script><p><strong>要注意的是</strong> 训练的时候是用梯度上升 而不是梯度下降！</p><p><strong>选择$h_\theta(x)$的原因之一是保证likelihood function只有一个全局最大值（concave function)</strong></p><p>对于logistics regression的常见问题</p><p><a href="https://towardsdatascience.com/why-not-mse-as-a-loss-function-for-logistic-regression-589816b5e03c">为什么logistics regression不采用MSE作为Loss Function</a></p><p>总结一下就是<strong>MSE doesn’t strongly penalize misclassifications</strong>和<strong>MSE loss function for logistic regression is non-convex</strong></p><h4 id="Newton’s-method"><a href="#Newton’s-method" class="headerlink" title="Newton’s method"></a>Newton’s method</h4><p>这个方法和gradient descent的区别是 这个方法一次更新的跨度更大(视频66: 12)，视频中举例 如果用1000次gradient descent得到好的$\theta$，那么用Newton’s method 经过10次迭代就能得到好的$\theta$，不过每次迭代的代价会比较昂贵</p><p>牛顿方法旨在解决的问题是， 我们有一个函数$f$，我们想要找到一个$\theta$ 使得$f(\theta) = 0$</p><p>将牛顿方法应用到机器学习中就是用牛顿方法来找导数为0的点</p><p>视频69分钟开始 演示牛顿方法的过程，更新算法如下：</p><script type="math/tex; mode=display">\theta^{(t + 1)} := \theta^{(t)} - \frac{f(\theta^{(t)})}{f^\prime(\theta^{(t)})}</script><p>当$\theta$是一个向量的时候，$\theta \in \mathcal{R}^{n + 1}$</p><script type="math/tex; mode=display">\theta^{(t + 1)} := \theta^{(t)} - H^{-1}\nabla_\theta\mathcal{l}(\theta)</script><p>其中H是Hessian matrix $H_{ij} = \frac{\partial^2\mathcal{l}(\theta)}{\partial\theta_i\partial\theta_j}$， 这个算法的耗时地方在于对hessian matrix求逆耗时，如果拥有的参数数量10个或50个 老师推荐有这个方法</p><p>Newton’s method enjoys a property called quadratic convergence(意思是如果某一次迭代后$\theta$的误差是0.01error 再经过一次迭代之后 误差变为0.0001error) —&gt; 我没懂他说的0.01error是什么意思，emmm… 反正就是很快的</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cs229 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Convolution</title>
      <link href="2021/03/08/signal%20and%20system%204/"/>
      <url>2021/03/08/signal%20and%20system%204/</url>
      
        <content type="html"><![CDATA[<h3 id="Lecture-4-Convolution"><a href="#Lecture-4-Convolution" class="headerlink" title="Lecture 4 Convolution"></a>Lecture 4 Convolution</h3><p><strong>这个笔记是根据</strong><a href="https://www.bilibili.com/video/BV1xy4y167DD?p=4">奥本海姆信号与系统的视频课来写的</a></p><p>如何利用time invariant 和linear属性—&gt;将一个信号分解为一组基本信号</p><p>对于基本信号的选择，目的是为了能够轻松地产生输出信号</p><ul><li>delayed impulses  &lt;—-&gt;  Convolution</li><li>complex exponential &lt;—-&gt;  Fourier analysis</li></ul><h4 id="将离散信号表示为冲激信号的线性组合"><a href="#将离散信号表示为冲激信号的线性组合" class="headerlink" title="将离散信号表示为冲激信号的线性组合"></a>将离散信号表示为冲激信号的线性组合</h4><script type="math/tex; mode=display">x[n] = \begin{cases}c& n = 0 \\0& n \neq 0\end{cases}\\其中c \neq 0</script><p>对于这个信号 可以表示为$x[0] \times \delta[n]$</p><p>同样可得$x[1] = x[1] \times \delta[n - 1]$还有$x[-1] = x[-1] \times \delta[n + 1]$</p><p>对于任意的一个信号$x[n]$ 就可以分解为$x[n] = \sum_{k=-\infty}^{+\infty}x[k]\delta[n-k]$</p><p><strong>这样表示的作用是什么？</strong></p><p>如果我们是在线性系统中，那么响应是线性组合的形式（假如$\delta[n-k]$的响应是$h_k[n]$），那么</p><script type="math/tex; mode=display">y[n] = \sum_{k=-\infty}^{+\infty}x[k]h_k[n]</script><p>如果系统是time-invariant 那么$h_k[n] = h_0[n - k]$ 将$h_0[n]$记为$h[n]$ 即为unit impulse</p><p>对于LTI系统                                       $y[n] = \sum_{k=-\infty}^{+\infty}x[k]h[n-k]$</p><h4 id="将连续信号表示为冲激信号的线性组合"><a href="#将连续信号表示为冲激信号的线性组合" class="headerlink" title="将连续信号表示为冲激信号的线性组合"></a>将连续信号表示为冲激信号的线性组合</h4><p>首先将连续时间信号分解为连续任意狭窄的矩形，当这些矩形的宽度变为0，会越近似于原信号，<strong>要注意的是 当每个矩形变得越来越窄就越来越多地与冲激信号对应</strong></p><script type="math/tex; mode=display">x(t) = \begin{cases}x(0) \times \delta_{\Delta}(t)\times\Delta& 0 \le t \le \Delta \\0& otherwise\end{cases}</script><script type="math/tex; mode=display">x(t) \approx x(0)\delta_{\Delta}(t)\Delta + x(\Delta)\delta_{\Delta}(t - \Delta)\Delta + x(-\Delta)\delta_{\Delta}(t + \Delta)\Delta + ... \\x(t) \approx \sum_{k=-\infty}^{+\infty}x(k\Delta)\delta_{\Delta}(t - k\Delta)\Delta \\x(t) = \lim_{\Delta \to 0}\sum_{k=-\infty}^{+\infty}x(k\Delta)\delta_{\Delta}(t - k\Delta)\Delta \\= \int_{-\infty}^{+\infty}x(\tau)\delta(t - \tau)d\tau  \quad sifting \ integral</script><p>对于线性系统输出为：</p><script type="math/tex; mode=display">y(t) = \lim_{\Delta \to 0}\sum_{k = -\infty}^{+\infty}x(k\Delta)h_{k\Delta}(t)\Delta \\=\int_{-\infty}^{\infty}x(\tau)h_{\tau}(t)d\tau</script><p>同样 如果系统是time invariant $h_{k\Delta} = h_0(t - k\Delta)$ 和 $h_{\tau}(t) = h_0(t - \tau)$ 可得：</p><script type="math/tex; mode=display">y(t) = \int_{-\infty}^{+\infty}x(\tau)h(t - \tau)d\tau</script><p>由上述可知 <strong>如果我们知道了对应于t=0或者n=0的冲激响应，那么通过卷积我们能得到任意输入的输出</strong></p><p><strong>我们将*符号表示卷积</strong></p><script type="math/tex; mode=display">y[n] = \sum_{k = -\infty}^{+\infty}x[k]h[n - k] = x[n] * h[n] \\y(t) = \int_{-\infty}^{+\infty}x(\tau)h(t - \tau)d\tau = x(t) * h(t)</script><p>从23分钟后就是介绍离散的例子 求$x[n] = u[n]$和$h[n] = \alpha^nu[n]$的响应，将$x[n] 变为截取的u[n]$</p><p>29分钟后是介绍连续的例子 $x(t) = u(t)$ 和 $h(t) = e^{-at}u(t)$ 同样也有$u(t)$的截取形式</p><p>视频里面的动画来显示卷积的过程挺不错</p><p>47分钟开始分析了一个连续时间卷积的例子</p><script type="math/tex; mode=display">y(t) = \int_{-\infty}^{\infty}x(\tau)h(t - \tau)d\tau \\= \int_{-\infty}^{\infty}u(\tau)e^{-a(t - \tau)}u(t - \tau)d\tau</script><p>考虑区间$t &lt; 0$， 因为$u(\tau)$在$\tau$小于0时值为0 当$\tau$大于等于0时$u(t - \tau)$为0 所以积分的值为0</p><p>考虑区间$t &gt; 0$ <strong>注意视频中$t = 0$的情况被忽略了，我觉得是因为重点不在$t = 0$</strong></p><p>当$\tau &lt; 0$时$u(\tau)$为0， 当$\tau &gt; t$时$u(t - \tau)$为0，也就是在区间$(-\infty, 0)$ 和$(t, +\infty)$积分的值为0</p><script type="math/tex; mode=display">\therefore \int_{-\infty}^{\infty}u(\tau)e^{-a(t - \tau)}u(t - \tau)d\tau \\= \int_{0}^{t}u(\tau)e^{-a(t - \tau)}u(t - \tau)d\tau  \\ = \int_{0}^{t}e^{-a(t - \tau)}d\tau \\= \frac{1}{a}[e^{at} - 1] \\\therefore y(t) = \begin{cases}0& t < 0 \\\frac{1}{a}{e^{at} - 1}& t > 0\end{cases}</script>]]></content>
      
      
      <categories>
          
          <category> 信号与系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信号与系统 </tag>
            
            <tag> 理论知识 </tag>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Signals and Systems Part II</title>
      <link href="2021/03/08/signal%20and%20system%203/"/>
      <url>2021/03/08/signal%20and%20system%203/</url>
      
        <content type="html"><![CDATA[<h3 id="Lecture-3-Signals-and-Systems-Part-II"><a href="#Lecture-3-Signals-and-Systems-Part-II" class="headerlink" title="Lecture 3 Signals and Systems: Part II"></a>Lecture 3 Signals and Systems: Part II</h3><p>这是根据公开课视频写的笔记<a href="https://www.bilibili.com/video/BV1xy4y167DD?p=3">链接</a></p><h3 id="几个重要的函数"><a href="#几个重要的函数" class="headerlink" title="几个重要的函数"></a>几个重要的函数</h3><h5 id="离散的unit-step函数"><a href="#离散的unit-step函数" class="headerlink" title="离散的unit step函数"></a>离散的unit step函数</h5><script type="math/tex; mode=display">\begin{equation}u[n] = \begin{cases}1& n \ge 0 \\0& n < 0\end{cases}\end{equation}</script><h5 id="离散的unit-impulse-函数"><a href="#离散的unit-impulse-函数" class="headerlink" title="离散的unit impulse 函数"></a>离散的unit impulse 函数</h5><script type="math/tex; mode=display">\begin{equation}\delta[n] = \begin{cases}1& n = 0 \\0& otherwise\end{cases}\end{equation}</script><p>两者之间的关系是</p><script type="math/tex; mode=display">\delta[n] = u[n] - u[n - 1] \quad (first \quad difference) \\ u[n] = \sum_{m = -\infty}^{n}\delta[m] \quad (running \quad sum)</script><p>unit step sequence can be thought of as a succession of unit impulses one following another</p><p><strong>这个知识点重要</strong></p><script type="math/tex; mode=display">u[n] = \delta[n] + \delta[n - 1] + \delta[n - 2] + ... \\u[n] = \sum_{k = 0}^{\infty}\delta[n - k]</script><h5 id="连续的unit-step函数"><a href="#连续的unit-step函数" class="headerlink" title="连续的unit step函数"></a>连续的unit step函数</h5><script type="math/tex; mode=display">\begin{equation}u(t) = \begin{cases}1& t > 0 \\0& t < 0\end{cases}\end{equation}</script><p>关于unit step函数在t = 0的定义有多种。t = 0处的定义不是重点，重点是这个函数的关键在于t = 0时 这个函数是不连续的</p><p>unit step可以看作是一个approximation unit step函数取极限得到</p><script type="math/tex; mode=display">\begin{equation}u_{\Delta}(t) = \begin{cases}1& t > \Delta \\\frac{1}{\Delta}& 0 \le t \le \Delta \\0& t < 0\end{cases}\end{equation} \\u(t) = \lim_{\Delta \to 0}u_{\Delta}(t)</script><h5 id="连续的unit-impulse函数"><a href="#连续的unit-impulse函数" class="headerlink" title="连续的unit impulse函数"></a>连续的unit impulse函数</h5><p>类比unit step和unit impulse之间的关系 来定义连续的unit impulse函数</p><p>unit impulse 就是 unit step的导数，由approximation unit step函数的定义来得到</p><script type="math/tex; mode=display">\delta(t) = \frac{du(t)}{dt} \\\delta_{\Delta}(t) = \frac{du_{\Delta}(t)}{dt} \\\begin{equation}\delta_{\Delta}(t) = \begin{cases}\frac{1}{\Delta}& 0 \le t \le \Delta \\0& otherwise\end{cases}\end{equation} \\no \ matter \ what \ the \ value \ of \ \Delta \ is\ , \ the \ area \ is \ always \ equal \ to \ 1 \\\delta(t) = \delta_{\Delta}(t) \quad as \quad \Delta \to 0</script><p>连续时间下，unit step函数和unit impulse函数之间的关系</p><script type="math/tex; mode=display">\delta = \frac{du(t)}{dt} \\u(t) = \int_{-\infty}^{t}\delta(\tau)d\tau</script><h3 id="系统"><a href="#系统" class="headerlink" title="系统"></a>系统</h3><p><strong>定义：a transformation from an input signal to an output signal </strong></p><ul><li>cascade system</li><li>parallel system</li><li>feedback system</li></ul><p>对于LTI系统，the overall system transformation is independet of the order in which the systems are cascaded</p><h5 id="系统属性"><a href="#系统属性" class="headerlink" title="系统属性"></a>系统属性</h5><ul><li><p>memoryless:  $y(t_0) \quad depends \ only \ on \quad x(t_0)$</p><p>例如 $y(t) = x^2(t)$  和 $y[n] = x^2[n]$ 是memoryless</p><p>​        $y(t) = \int_{-\infty}^{t}x^2(\tau)d\tau$ 和$y[n] = x[n - 1] \quad unit \ delay$  不是memoryless</p></li><li><p>invertibility(可逆性)： given the output, there is only one input</p></li><li><p>Causality: its response at any time only depends on values of the input prior to that time</p><p>例如$y[n] = \frac{1}{3}(x[n - 1] + x[n] + x[n + 1]) $ 不是causality</p><p>​        $y[n] = \frac{1}{3}(x[n - 2] + x[n - 1] + x[n])$ 是causality</p></li><li><p>Stability： for every bounded input the output is bounded</p><p>​    feedback system的一个重要的应用是stablize unstable systems</p><p>​    例如$y(t) = \int_{-\infty}^{t}u(\tau)d\tau$  输出$y(t)$ 是ramp function， ramp is unbounded because if you try to establish any bound on it,  you can always go out far enough in time</p></li><li><p>Time invariance: 系统 if $x(t) -&gt; y(t)$ then  $x(t - t_0) -&gt; y(t - t_0)$</p><p>例如 $y(t) = sint \times x(t)$ 不是time invariance 因为当输入是$x(t-t_0)$时 输出时$sint \times x(t-t_0)$</p></li><li><p>Linearity: </p></li></ul><script type="math/tex; mode=display">if \quad x_1(t) -> y_1(t) \quad and \quad x_2(t) -> y_2(t) \\then \quad ax_t(t) + bx_2(t) -> ay_1(t) + by_2(t)</script>]]></content>
      
      
      <categories>
          
          <category> 信号与系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信号与系统 </tag>
            
            <tag> 理论知识 </tag>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Properties of Linear Time-invariant Systems</title>
      <link href="2021/03/08/signal%20and%20system%205/"/>
      <url>2021/03/08/signal%20and%20system%205/</url>
      
        <content type="html"><![CDATA[<h3 id="Lecture-5-Properties-of-Linear-Time-invariant-Systems"><a href="#Lecture-5-Properties-of-Linear-Time-invariant-Systems" class="headerlink" title="Lecture 5 Properties of Linear Time-invariant Systems"></a>Lecture 5 Properties of Linear Time-invariant Systems</h3><p>这是根据公开课视频写的笔记<a href="https://www.bilibili.com/video/BV1xy4y167DD?p=5">链接</a></p><h5 id="Commutative"><a href="#Commutative" class="headerlink" title="Commutative"></a>Commutative</h5><script type="math/tex; mode=display">x[n] * h[n] = h[n] * x[n] \\x(t) * h(t) = h(t) * x(t)</script><h5 id="Associative"><a href="#Associative" class="headerlink" title="Associative"></a>Associative</h5><script type="math/tex; mode=display">x * \{h_1 * h_2\} = \{x * h_1 \} * h_2</script><h5 id="Distributive"><a href="#Distributive" class="headerlink" title="Distributive"></a>Distributive</h5><script type="math/tex; mode=display">x * \{ h_1 + h_2 \} = x * h_1 + x * h_2</script><p>视频9分40秒的例子 解释了在LTI系统中commutative性质的作用</p><p>We can interchange the role of input and impulse response, and from an output point of view, the output doesn’t care.</p><p>视频11分钟40秒的例子 解释了在LTI系统中Associative性质的作用</p><p><strong>如果我们有两个级联的LTI系统，任意方式的级联结果是一样的</strong></p><p>对于非LTI系统的级联 比如—&gt;平方根—&gt;加倍—&gt; 和 —&gt;加倍—&gt;平方根—&gt; 是不一样的</p><p>视频15分11秒的例子 解释了在LTI系统中Distributive性质的作用</p><p><strong>总结一下 这块讲的是从卷积的性质来看LTI系统互联时的性质</strong></p><h4 id="LTI系统中，其他系统属性可以关联具有系统的特定属性冲激响应"><a href="#LTI系统中，其他系统属性可以关联具有系统的特定属性冲激响应" class="headerlink" title="LTI系统中，其他系统属性可以关联具有系统的特定属性冲激响应"></a>LTI系统中，其他系统属性可以关联具有系统的特定属性冲激响应</h4><ul><li><p>Memoryless</p><p>$h(t - \tau)$ nonzero only at $\tau = t$  which implys $h(t) = K\delta(t)$ 和 $h[n] = K\delta[n]$</p><p>视频19分22秒有图 由于我们想让冲激响应contribute something after we multiply and go through an integral, and what that says is the only thing that it can be and meet all those conditions is a scaled impulse</p></li><li><p>Invertibility</p><p>视频21分钟有图 $y = x <em> (h </em> h^{-1}) = x$ 我觉得视频上的图有问题，$h$和$h^{-1}$之间应该是卷积符号</p></li><li><p>Stability</p><script type="math/tex; mode=display">\sum_{-\infty}^{+\infty}|h[k]| < \infty \\\int_{-\infty}^{+\infty}|h(\tau)|d\tau < \infty</script></li><li><p>Causality</p><p>引入概念 zero input response of a linear system(无论是否是time invariant 结论都成立)</p><p>if you put nothing into it you get nothing out of it</p><p>意思是如果$x(t) = 0$对于任意t成立， 则$y(t) = 0$对于任意t成立；如果$x[n] = 0$对于任意t成立， 则$y[n] = 0$对于任意t成立 原因是对于线性系统 如果$x(t) -&gt;y(t)$ 那么$ax(t) -&gt;ay(t)$ 令$a$为0 就可以得到这个情况</p><p><strong>causality这个性质说明的是系统无法预测输入（视频27分45秒）</strong></p><p>对于线性系统</p><p>if $x(t) = 0$ 对任意$t &lt; t_0$成立，那么$y(t) = 0$对任意$t &lt; t_0$成立， 称作initial rest</p><p>对于LTI系统</p><p>causality意味着$h(t) = 0$对任意$t&lt;0$成立，$h[n] = 0$对于任意$n &lt; 0$成立 因为相应的输入是$\delta(t)$和$\delta[n]$这两个在$t&lt;0$的时候 值均为0</p><p>视频33分8秒 示意了 如果$h(t) = 0$对任意$t &lt; 0$成立 则系统是causality的推导</p></li></ul><p>34分钟 举了一个例子</p><p>Accumulator: $y[n] = \sum_{k = -\infty}^nx[k]$， Accumulator是一个LTI系统中$h[n] = u[n]$的例子，下面分析</p><p>$\because h[n] \neq k\delta[n]$   我们可知系统是memory的</p><p>$\because h[n] = 0$对于任意n &lt; 0成立   我们可知系统是causal的</p><p>$\because \sum_{n = -\infty}^{+\infty}|h[n]| = \infty$ 我们可知系统是not stable的</p><p>38分钟关于Accumulator的求逆 没有看懂</p><p>40分钟的例子 视频里面写着 initial rest $\Rightarrow$ LTI 有点没懂</p><p>视频最后的部分讲的是</p><p>$\delta (t) * \delta (t) = \delta (t) $ 和</p><p> $ \delta[n] *\delta[n] = \delta[n]$</p><p>后者可以画图推理得到，但是前者比较tricky</p><p>因为考虑到$\delta(t) = \lim_{\Delta \to 0}\delta_{\Delta}(t)$ 如果对$\delta_{\Delta}(t) * \delta_{\Delta}(t)$得到的是一个$r_{\Delta}(t)$</p><script type="math/tex; mode=display">\begin{equation}r_{\Delta}(t) = \begin{cases}\frac{1}{\Delta^2}t& 0 < t < \Delta \\\frac{1}{\Delta} - (t - \Delta) * \frac{1}{\Delta^2}& \Delta < t < 2\Delta \\0& otherwise\end{cases}\end{equation}</script><p>那么$\delta(t) = \lim_{\Delta \to 0}r_{\Delta}(t)$</p><p>再考虑对于$\delta(t)$求导，会发现比较麻烦，老师说正确的解决方法是through a set of mathematics referred to as generalized functions</p><p><strong>当我们讨论一个函数时，我们讨论的是what the value of the function is at any instant of time，当面对冲激函数的时候就出现麻烦，那么就从另一种定义operational  definition来对待函数，即not related to what the impulse is, but to what the impulse does under the operation of convolution</strong></p><p><strong>SO WHAT IS IMPULSE?</strong></p><p>An impulse in something which under convolution retains the function !   666</p><p>意思就是impulse这个函数的定义是通过卷积来定义的，对于任意的函数，如果有一个函数和这个任意的函数卷积出来的结果不变，那么这个函数就是impulse函数</p><script type="math/tex; mode=display">x(t) * \delta(t) = x(t) \\\therefore \frac{d\delta(t)}{dt} = u_1(t) \\x(t) * u_1(t) = \frac{dx(t)}{dt} \\u_2(t) = u_1(t) * u_1(t) \\x(t) * u_2(t) = \frac{d^2x(t)}{dt}u_k(t) = u_1(t) * u_1(t) * ... \quad k \ times \\x(t) * u_k(t) = \frac{d^kx(t)}{dt} \\u_0(t) = \delta(t)</script><p>同理 对积分器引入$u_{-m}(t)$的定义 mth running integral</p><script type="math/tex; mode=display">u_k(t) * u_p(t) = u_{k + p}(t)</script>]]></content>
      
      
      <categories>
          
          <category> 信号与系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信号与系统 </tag>
            
            <tag> 理论知识 </tag>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何建站</title>
      <link href="2021/02/18/%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%99/"/>
      <url>2021/02/18/%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%99/</url>
      
        <content type="html"><![CDATA[<h4 id="如何建站"><a href="#如何建站" class="headerlink" title="如何建站"></a>如何建站</h4><p>本站是在github上面建的静态网站，用的是hexo模板(这个资料很多)</p><p>主题是<a href="https://github.com/blinkfox/hexo-theme-matery">闪烁之狐</a></p><p>对于mathjax渲染问题，可能需要参考一下这篇博客<a href="https://www.cnblogs.com/Ai-heng/p/7282110.html">链接</a></p><p>对于发生spawn failed的错误 可以参考一下这篇博客<a href="https://1187100546.github.io/2019/11/24/spawn-failed/">链接</a></p><p>有问题欢迎留言</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
